{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ñ Desvendando o Mist√©rio dos LLMs: Seu Guia Completo para Entender os Gigantes da IA\n\n## M√≥dulo 2 - Introdu√ß√£o √† LLMs\n\n**Instrutor:** Pedro Nunes Guth  \n**N√≠vel:** Iniciante a Intermedi√°rio  \n**Tempo estimado:** 2-3 horas\n\n---\n\nFala pessoal! üëã Bora mergulhar no universo fascinante dos **Large Language Models (LLMs)**!\n\nSe voc√™ chegou at√© aqui, j√° deve ter ouvido falar do ChatGPT, Claude, Gemini... Mas t√°, **o que diabos s√£o esses LLMs mesmo?** \n\nHoje vamos desvendar esse mist√©rio de uma vez por todas, com explica√ß√µes que at√© sua v√≥ vai entender! üöÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö O que vamos aprender hoje?\n\n1. **Defini√ß√£o e conceitos fundamentais**\n2. **Como os LLMs funcionam por baixo dos panos**\n3. **Evolu√ß√£o hist√≥rica - de onde viemos**\n4. **Principais caracter√≠sticas e capacidades**\n5. **Exemplos pr√°ticos e casos de uso**\n6. **Prepara√ß√£o para os pr√≥ximos m√≥dulos**\n\n**üí° Dica do Pedro:** Este m√≥dulo √© a base de tudo! Se voc√™ entender bem o que s√£o LLMs aqui, os pr√≥ximos m√≥dulos sobre Transformers, tokens e embeddings v√£o fazer muito mais sentido!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup inicial - vamos preparar nosso ambiente!\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configura√ß√µes para visualiza√ß√£o\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"üöÄ Ambiente configurado! Bora come√ßar nossa jornada pelos LLMs!\")\n",
        "print(f\"üìÖ Data: {datetime.now().strftime('%d/%m/%Y %H:%M')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Definindo LLMs: O que s√£o afinal?\n\nT√°, vamos come√ßar pelo b√°sico. **LLM** significa **Large Language Model** (Modelo de Linguagem Grande).\n\nMas o que isso significa na pr√°tica? Pensa assim:\n\n### üß† Analogia do \"C√©rebro Estat√≠stico\"\n\nImagine que voc√™ tem um amigo que:\n- Leu TODOS os livros da biblioteca nacional\n- Decorou toda a Wikipedia\n- Estudou milh√µes de conversas no WhatsApp\n- Analisou todos os artigos cient√≠ficos j√° escritos\n\nE agora, quando voc√™ faz uma pergunta, ele usa toda essa informa√ß√£o para te dar a resposta mais prov√°vel baseada em padr√µes que ele aprendeu.\n\n**Isso √© um LLM!** ü§Ø\n\n### üîç Defini√ß√£o T√©cnica\n\nUm **Large Language Model** √©:\n- Um modelo de rede neural com **milh√µes ou bilh√µes** de par√¢metros\n- Treinado em **enormes quantidades** de texto\n- Capaz de **gerar, compreender e manipular** linguagem natural\n- Baseado na arquitetura **Transformer** (veremos no M√≥dulo 3!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introdu√ß√£o-√†-llms-modulo-02_img_01.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos visualizar o conceito de \"Large\" em LLMs\n",
        "# Comparando tamanhos de diferentes modelos\n",
        "\n",
        "modelos = {\n",
        "    'BERT-base': 110,           # milh√µes de par√¢metros\n",
        "    'GPT-2': 1500,             # milh√µes  \n",
        "    'GPT-3': 175000,           # milh√µes (175 bilh√µes)\n",
        "    'GPT-4': 1800000,          # estimativa (1.8 trilh√µes)\n",
        "    'PaLM': 540000             # milh√µes (540 bilh√µes)\n",
        "}\n",
        "\n",
        "nomes = list(modelos.keys())\n",
        "tamanhos = list(modelos.values())\n",
        "\n",
        "# Criando o gr√°fico\n",
        "plt.figure(figsize=(12, 8))\n",
        "bars = plt.bar(nomes, tamanhos, \n",
        "               color=['#3498db', '#e74c3c', '#f39c12', '#2ecc71', '#9b59b6'],\n",
        "               alpha=0.8)\n",
        "\n",
        "plt.yscale('log')  # Escala logar√≠tmica porque os n√∫meros s√£o muito grandes!\n",
        "plt.title('üìä Tamanho dos LLMs: A Evolu√ß√£o dos \"Gigantes\"', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Modelos', fontsize=12)\n",
        "plt.ylabel('Par√¢metros (Milh√µes)', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for bar, tamanho in zip(bars, tamanhos):\n",
        "    height = bar.get_height()\n",
        "    if tamanho >= 1000:\n",
        "        label = f'{tamanho/1000:.1f}B'  # Bilh√µes\n",
        "    else:\n",
        "        label = f'{tamanho}M'  # Milh√µes\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             label, ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ü§Ø Olha s√≥ essa evolu√ß√£o! De 110 milh√µes para 1.8 TRILH√ÉO de par√¢metros!\")\n",
        "print(\"üí° Por isso se chamam 'LARGE' Language Models - s√£o GIGANTESCOS!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéõÔ∏è Como os LLMs Funcionam: A M√°gica por Tr√°s das Cortinas\n\nBora entender como essa m√°gica acontece! \n\n### üîÑ O Processo B√°sico\n\n```mermaid\ngraph LR\n    A[Texto de Entrada] --> B[Tokeniza√ß√£o]\n    B --> C[Embeddings]\n    C --> D[Camadas Transformer]\n    D --> E[Predi√ß√£o]\n    E --> F[Texto de Sa√≠da]\n```\n\n### üßÆ A Matem√°tica Simplificada\n\nNa ess√™ncia, um LLM faz uma coisa bem simples (mas bilh√µes de vezes):\n\n**\"Dadas essas palavras, qual √© a pr√≥xima palavra mais prov√°vel?\"**\n\n### üéØ Analogia do Corretor do WhatsApp\n\nSabe quando voc√™ digita no WhatsApp e ele sugere a pr√≥xima palavra? \n\n- Voc√™: \"Oi, tudo bem? Vamos nos encontrar...\"\n- WhatsApp sugere: \"hoje\", \"amanh√£\", \"na\"\n\nUm LLM faz EXATAMENTE isso, mas com muito mais contexto e intelig√™ncia!\n\n**üí° Dica do Pedro:** Nos pr√≥ximos m√≥dulos vamos mergulhar fundo em cada etapa: tokens (M√≥dulo 4), embeddings (M√≥dulo 5) e a arquitetura Transformer (M√≥dulo 3). Por agora, foca no conceito geral!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulando como um LLM \"pensa\" sobre a pr√≥xima palavra\n",
        "# Vamos criar um exemplo bem simples!\n",
        "\n",
        "def simular_predicao_llm(contexto, candidatos):\n",
        "    \"\"\"Simula como um LLM calcula probabilidades para pr√≥xima palavra\"\"\"\n",
        "    \n",
        "    # Simulando probabilidades baseadas no contexto\n",
        "    # (Na vida real, isso envolve bilh√µes de c√°lculos!)\n",
        "    probabilidades = {\n",
        "        'hoje': 0.45 if 'encontrar' in contexto else 0.1,\n",
        "        'amanh√£': 0.35 if 'encontrar' in contexto else 0.1, \n",
        "        'na': 0.15 if 'encontrar' in contexto else 0.2,\n",
        "        'para': 0.05 if 'encontrar' in contexto else 0.6\n",
        "    }\n",
        "    \n",
        "    return probabilidades\n",
        "\n",
        "# Testando nossa simula√ß√£o\n",
        "contexto = \"Oi, tudo bem? Vamos nos encontrar\"\n",
        "candidatos = ['hoje', 'amanh√£', 'na', 'para']\n",
        "\n",
        "probs = simular_predicao_llm(contexto, candidatos)\n",
        "\n",
        "# Visualizando as probabilidades\n",
        "plt.figure(figsize=(10, 6))\n",
        "palavras = list(probs.keys())\n",
        "valores = list(probs.values())\n",
        "\n",
        "bars = plt.bar(palavras, valores, \n",
        "               color=['#e74c3c', '#3498db', '#f39c12', '#2ecc71'],\n",
        "               alpha=0.8)\n",
        "\n",
        "plt.title('üß† Como um LLM \"Pensa\": Probabilidades para Pr√≥xima Palavra', \n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Palavras Candidatas', fontsize=12)\n",
        "plt.ylabel('Probabilidade', fontsize=12)\n",
        "plt.ylim(0, 0.5)\n",
        "\n",
        "# Adicionando percentuais nas barras\n",
        "for bar, valor in zip(bars, valores):\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "             f'{valor*100:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"üìù Contexto: '{contexto}'\")\n",
        "print(f\"üèÜ Palavra mais prov√°vel: '{max(probs, key=probs.get)}' ({max(probs.values())*100:.1f}%)\")\n",
        "print(\"\\nüí° √â assim que LLMs funcionam: calculando probabilidades para CADA palavra poss√≠vel!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Evolu√ß√£o Hist√≥rica: De Onde Viemos\n\nVamos fazer uma viagem no tempo para entender como chegamos aqui!\n\n### üï∞Ô∏è Linha do Tempo dos LLMs\n\n```mermaid\ntimeline\n    title Evolu√ß√£o dos LLMs\n    \n    2017 : Transformer\n         : \"Attention is All You Need\"\n         \n    2018 : BERT\n         : GPT-1\n         \n    2019 : GPT-2\n         : \"Muito perigoso para liberar\"\n         \n    2020 : GPT-3\n         : 175B par√¢metros\n         \n    2022 : ChatGPT\n         : Revolu√ß√£o p√∫blica\n         \n    2023 : GPT-4\n         : Claude 2\n         : Era multimodal\n```\n\n### üåü Marcos Importantes\n\n1. **2017 - Paper Transformer**: A revolu√ß√£o come√ßou!\n2. **2018 - BERT e GPT-1**: Primeiros sucessos\n3. **2019 - GPT-2**: OpenAI achou \"perigoso demais\" para liberar\n4. **2020 - GPT-3**: O mundo percebeu o potencial\n5. **2022 - ChatGPT**: Explos√£o p√∫blica - todo mundo usando\n6. **2023 - GPT-4**: Multimodal, mais inteligente\n\n**üí° Dica do Pedro:** Cada modelo trouxe inova√ß√µes que estudaremos nos pr√≥ximos m√≥dulos!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introdu√ß√£o-√†-llms-modulo-02_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos visualizar a evolu√ß√£o do interesse p√∫blico nos LLMs\n",
        "# Simulando dados de busca e ado√ß√£o\n",
        "\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Criando dados simulados da evolu√ß√£o\n",
        "datas = pd.date_range(start='2017-01-01', end='2024-01-01', freq='M')\n",
        "interesse = []\n",
        "\n",
        "for data in datas:\n",
        "    if data.year <= 2018:\n",
        "        score = np.random.normal(10, 3)  # Baixo interesse acad√™mico\n",
        "    elif data.year <= 2020:\n",
        "        score = np.random.normal(25, 5)  # Crescimento gradual\n",
        "    elif data.year <= 2021:\n",
        "        score = np.random.normal(40, 8)  # GPT-3 desperta interesse\n",
        "    elif data.year == 2022 and data.month >= 11:  # ChatGPT lan√ßado\n",
        "        score = np.random.normal(85, 10)\n",
        "    elif data.year >= 2023:\n",
        "        score = np.random.normal(90, 5)  # Explos√£o total\n",
        "    else:\n",
        "        score = np.random.normal(45, 10)\n",
        "    \n",
        "    interesse.append(max(0, min(100, score)))\n",
        "\n",
        "# Criando DataFrame\n",
        "df_evolucao = pd.DataFrame({\n",
        "    'Data': datas,\n",
        "    'Interesse_Publico': interesse\n",
        "})\n",
        "\n",
        "# Plotando a evolu√ß√£o\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.plot(df_evolucao['Data'], df_evolucao['Interesse_Publico'], \n",
        "         linewidth=3, color='#2ecc71', alpha=0.8)\n",
        "plt.fill_between(df_evolucao['Data'], df_evolucao['Interesse_Publico'], \n",
        "                 alpha=0.3, color='#2ecc71')\n",
        "\n",
        "# Marcando eventos importantes\n",
        "eventos = {\n",
        "    '2017-06': ('Transformer Paper', 'red'),\n",
        "    '2018-06': ('BERT + GPT-1', 'blue'),\n",
        "    '2019-02': ('GPT-2', 'orange'),\n",
        "    '2020-06': ('GPT-3', 'purple'),\n",
        "    '2022-11': ('ChatGPT', 'gold'),\n",
        "    '2023-03': ('GPT-4', 'green')\n",
        "}\n",
        "\n",
        "for data_evento, (nome, cor) in eventos.items():\n",
        "    data_plt = pd.to_datetime(data_evento)\n",
        "    if data_plt in df_evolucao['Data'].values:\n",
        "        idx = df_evolucao[df_evolucao['Data'] == data_plt].index[0]\n",
        "        valor = df_evolucao.loc[idx, 'Interesse_Publico']\n",
        "    else:\n",
        "        # Interpolar valor\n",
        "        idx = df_evolucao['Data'].searchsorted(data_plt)\n",
        "        if idx < len(df_evolucao):\n",
        "            valor = df_evolucao.loc[min(idx, len(df_evolucao)-1), 'Interesse_Publico']\n",
        "        else:\n",
        "            valor = df_evolucao.iloc[-1]['Interesse_Publico']\n",
        "    \n",
        "    plt.axvline(x=data_plt, color=cor, linestyle='--', alpha=0.7)\n",
        "    plt.text(data_plt, valor + 5, nome, rotation=90, \n",
        "             ha='center', va='bottom', fontweight='bold', color=cor)\n",
        "\n",
        "plt.title('üöÄ A Explos√£o dos LLMs: Evolu√ß√£o do Interesse P√∫blico', \n",
        "          fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Ano', fontsize=12)\n",
        "plt.ylabel('Interesse P√∫blico (0-100)', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Olha s√≥ como o interesse explodiu ap√≥s o ChatGPT!\")\n",
        "print(\"üéØ De assunto acad√™mico para conversa de boteco em poucos anos!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé™ Principais Caracter√≠sticas dos LLMs\n\nAgora que j√° sabemos o que s√£o e de onde vieram, bora entender **o que faz os LLMs t√£o especiais**!\n\n### üåü Superpoderes dos LLMs\n\n#### 1. **üó£Ô∏è Gera√ß√£o de Texto**\n- Escrevem como humanos (√†s vezes at√© melhor!)\n- Mant√™m consist√™ncia em textos longos\n- Adaptam o estilo conforme necess√°rio\n\n#### 2. **üß† Compreens√£o Contextual**\n- Entendem nuances e subentendidos\n- Captam refer√™ncias a informa√ß√µes anteriores\n- Interpretam ambiguidades\n\n#### 3. **üé≠ Versatilidade de Tarefas**\n- Tradu√ß√£o entre idiomas\n- Resumos e s√≠nteses\n- An√°lise de sentimentos\n- Programa√ß√£o\n- Cria√ß√£o criativa\n\n#### 4. **üîÑ Aprendizado Few-Shot**\n- Aprendem com poucos exemplos\n- N√£o precisam ser retreinados para novas tarefas\n- Generalizam conhecimento\n\n**üí° Dica do Pedro:** Essa versatilidade vem do treinamento massivo que veremos no M√≥dulo 7!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos simular as diferentes capacidades de um LLM\n",
        "# Criando um \"mini-LLM\" educativo\n",
        "\n",
        "class MiniLLMDemo:\n",
        "    \"\"\"Uma simula√ß√£o simples para demonstrar capacidades de LLM\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.conhecimento = {\n",
        "            'traducao': {\n",
        "                'hello': 'ol√°',\n",
        "                'world': 'mundo', \n",
        "                'computer': 'computador',\n",
        "                'artificial intelligence': 'intelig√™ncia artificial'\n",
        "            },\n",
        "            'sentimentos': {\n",
        "                'amo': 'positivo',\n",
        "                'odeio': 'negativo',\n",
        "                'legal': 'positivo',\n",
        "                'terr√≠vel': 'negativo',\n",
        "                'incr√≠vel': 'positivo'\n",
        "            }\n",
        "        }\n",
        "    \n",
        "    def traduzir(self, texto_en):\n",
        "        \"\"\"Simula tradu√ß√£o ingl√™s -> portugu√™s\"\"\"\n",
        "        palavras = texto_en.lower().split()\n",
        "        traducao = []\n",
        "        \n",
        "        for palavra in palavras:\n",
        "            if palavra in self.conhecimento['traducao']:\n",
        "                traducao.append(self.conhecimento['traducao'][palavra])\n",
        "            else:\n",
        "                traducao.append(f'[{palavra}]')  # palavra n√£o conhecida\n",
        "        \n",
        "        return ' '.join(traducao)\n",
        "    \n",
        "    def analisar_sentimento(self, texto):\n",
        "        \"\"\"Simula an√°lise de sentimento\"\"\"\n",
        "        palavras = texto.lower().split()\n",
        "        sentimentos = []\n",
        "        \n",
        "        for palavra in palavras:\n",
        "            if palavra in self.conhecimento['sentimentos']:\n",
        "                sentimentos.append(self.conhecimento['sentimentos'][palavra])\n",
        "        \n",
        "        if not sentimentos:\n",
        "            return 'neutro'\n",
        "        \n",
        "        positivos = sentimentos.count('positivo')\n",
        "        negativos = sentimentos.count('negativo')\n",
        "        \n",
        "        if positivos > negativos:\n",
        "            return 'positivo'\n",
        "        elif negativos > positivos:\n",
        "            return 'negativo'\n",
        "        else:\n",
        "            return 'neutro'\n",
        "    \n",
        "    def gerar_resumo(self, texto):\n",
        "        \"\"\"Simula gera√ß√£o de resumo (bem simples!)\"\"\"\n",
        "        palavras = len(texto.split())\n",
        "        chars = len(texto)\n",
        "        \n",
        "        return f\"Resumo: Texto com {palavras} palavras e {chars} caracteres.\"\n",
        "\n",
        "# Testando nosso mini-LLM\n",
        "demo_llm = MiniLLMDemo()\n",
        "\n",
        "print(\"ü§ñ Demonstra√ß√£o das Capacidades de LLM\\n\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Teste 1: Tradu√ß√£o\n",
        "texto_en = \"Hello world artificial intelligence\"\n",
        "traducao = demo_llm.traduzir(texto_en)\n",
        "print(f\"üåç TRADU√á√ÉO:\")\n",
        "print(f\"   EN: {texto_en}\")\n",
        "print(f\"   PT: {traducao}\\n\")\n",
        "\n",
        "# Teste 2: An√°lise de Sentimento\n",
        "frases = [\n",
        "    \"Amo programar IA!\",\n",
        "    \"Odeio bugs no c√≥digo\",\n",
        "    \"Esse curso √© incr√≠vel\"\n",
        "]\n",
        "\n",
        "print(\"üòä AN√ÅLISE DE SENTIMENTO:\")\n",
        "for frase in frases:\n",
        "    sentimento = demo_llm.analisar_sentimento(frase)\n",
        "    emoji = \"üòä\" if sentimento == \"positivo\" else \"üò¢\" if sentimento == \"negativo\" else \"üòê\"\n",
        "    print(f\"   '{frase}' ‚Üí {emoji} {sentimento}\")\n",
        "\n",
        "print(\"\\nüí° Lembra: LLMs reais fazem isso com BILH√ïES de par√¢metros!\")\n",
        "print(\"üöÄ Por isso s√£o t√£o bons em entender contexto e nuances!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introdu√ß√£o-√†-llms-modulo-02_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando as principais capacidades dos LLMs\n",
        "capacidades = {\n",
        "    'Gera√ß√£o de Texto': 95,\n",
        "    'Compreens√£o': 90,\n",
        "    'Tradu√ß√£o': 88,\n",
        "    'Resumo': 85,\n",
        "    'Programa√ß√£o': 82,\n",
        "    'An√°lise Sentimento': 87,\n",
        "    'Matem√°tica': 75,\n",
        "    'Criatividade': 80\n",
        "}\n",
        "\n",
        "# Criando gr√°fico radar/polar\n",
        "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
        "\n",
        "# Preparando dados\n",
        "categorias = list(capacidades.keys())\n",
        "valores = list(capacidades.values())\n",
        "\n",
        "# √Çngulos para cada categoria\n",
        "angulos = np.linspace(0, 2 * np.pi, len(categorias), endpoint=False)\n",
        "valores += valores[:1]  # Fechando o c√≠rculo\n",
        "angulos = np.concatenate((angulos, [angulos[0]]))\n",
        "\n",
        "# Plotando\n",
        "ax.plot(angulos, valores, 'o-', linewidth=2, color='#3498db')\n",
        "ax.fill(angulos, valores, alpha=0.25, color='#3498db')\n",
        "\n",
        "# Configura√ß√µes\n",
        "ax.set_xticks(angulos[:-1])\n",
        "ax.set_xticklabels(categorias, fontsize=10)\n",
        "ax.set_ylim(0, 100)\n",
        "ax.set_yticks([20, 40, 60, 80, 100])\n",
        "ax.set_yticklabels(['20%', '40%', '60%', '80%', '100%'])\n",
        "ax.grid(True)\n",
        "\n",
        "plt.title('üéØ Radar de Capacidades dos LLMs Modernos\\n(N√≠veis de Compet√™ncia)', \n",
        "          fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Como interpretar este radar:\")\n",
        "print(\"‚úÖ 90%+ : N√≠vel quase humano ou superior\")\n",
        "print(\"‚úÖ 80-90%: Muito competente\")\n",
        "print(\"‚ö†Ô∏è  70-80%: Bom, mas com limita√ß√µes\")\n",
        "print(\"‚ùå <70% : Ainda precisa melhorar\")\n",
        "\n",
        "print(\"\\nüí° Dica do Pedro: Nos pr√≥ximos m√≥dulos vamos entender COMO eles conseguem essas capacidades!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Casos de Uso Reais: LLMs na Pr√°tica\n\nT√°, mas onde eu posso usar isso na vida real? Bora ver exemplos pr√°ticos!\n\n### üè¢ No Mundo Corporativo\n\n#### **Customer Service 2.0**\n- Chatbots inteligentes que realmente entendem\n- An√°lise de feedback autom√°tica\n- Respostas personalizadas em massa\n\n#### **Produtividade**\n- Gera√ß√£o autom√°tica de relat√≥rios\n- Resumos de reuni√µes\n- Cria√ß√£o de conte√∫do para marketing\n\n### üéì Na Educa√ß√£o\n\n- Tutores personalizados 24/7\n- Corre√ß√£o autom√°tica de reda√ß√µes\n- Gera√ß√£o de exerc√≠cios adaptativos\n\n### üíª Para Desenvolvedores\n\n- GitHub Copilot: pair programming com IA\n- Documenta√ß√£o autom√°tica\n- Debugging assistido\n\n### üé® Criatividade\n\n- Roteiros para v√≠deos\n- Letras de m√∫sica\n- Brainstorming de ideias\n\n**üí° Dica do Pedro:** A chave √© entender que LLMs s√£o ferramentas para **amplificar** sua criatividade e produtividade, n√£o substitu√≠-lo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos simular diferentes casos de uso com exemplos pr√°ticos\n",
        "casos_de_uso = {\n",
        "    'Customer Service': {\n",
        "        'input': 'Cliente: Meu produto chegou quebrado, quero reembolso!',\n",
        "        'output': 'Lamento muito pelo inconveniente! Vou processar seu reembolso imediatamente e enviar uma etiqueta de devolu√ß√£o. Posso tamb√©m oferecer um desconto de 20% na pr√≥xima compra.'\n",
        "    },\n",
        "    'Programa√ß√£o': {\n",
        "        'input': 'Preciso de uma fun√ß√£o para calcular fibonacci',\n",
        "        'output': '''def fibonacci(n):\n",
        "    if n <= 1:\n",
        "        return n\n",
        "    return fibonacci(n-1) + fibonacci(n-2)'''\n",
        "    },\n",
        "    'Tradu√ß√£o': {\n",
        "        'input': 'The weather is beautiful today',\n",
        "        'output': 'O tempo est√° lindo hoje'\n",
        "    },\n",
        "    'Resumo': {\n",
        "        'input': 'Texto longo sobre IA com 500 palavras explicando machine learning...',\n",
        "        'output': 'Resumo: IA e ML s√£o tecnologias que permitem m√°quinas aprenderem padr√µes em dados para fazer predi√ß√µes e automatizar tarefas complexas.'\n",
        "    },\n",
        "    'Criatividade': {\n",
        "        'input': 'Escreva um haicai sobre programa√ß√£o',\n",
        "        'output': 'C√≥digos dan√ßam\\nNa tela iluminada\\nBugs se escondem'\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"üé™ CASOS DE USO REAIS DE LLMs\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, (caso, exemplo) in enumerate(casos_de_uso.items(), 1):\n",
        "    print(f\"\\n{i}. üéØ {caso.upper()}\")\n",
        "    print(f\"   üì• Input:  {exemplo['input']}\")\n",
        "    print(f\"   üì§ Output: {exemplo['output']}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print(\"\\nüí° Cada um desses exemplos mostra como LLMs podem:\")\n",
        "print(\"   ‚úÖ Entender contexto\")\n",
        "print(\"   ‚úÖ Gerar respostas relevantes\")\n",
        "print(\"   ‚úÖ Adaptar estilo conforme necess√°rio\")\n",
        "print(\"   ‚úÖ Manter consist√™ncia\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos analisar o impacto dos LLMs em diferentes setores\n",
        "setores_impacto = {\n",
        "    'Tecnologia': 95,\n",
        "    'Educa√ß√£o': 85,\n",
        "    'Marketing': 90,\n",
        "    'Sa√∫de': 70,\n",
        "    'Finan√ßas': 75,\n",
        "    'M√≠dia': 88,\n",
        "    'Jur√≠dico': 65,\n",
        "    'Varejo': 80,\n",
        "    'Manufatura': 45,\n",
        "    'Governo': 55\n",
        "}\n",
        "\n",
        "# Ordenando por impacto\n",
        "setores_sorted = dict(sorted(setores_impacto.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "setores = list(setores_sorted.keys())\n",
        "impactos = list(setores_sorted.values())\n",
        "\n",
        "# Cores baseadas no n√≠vel de impacto\n",
        "cores = ['#e74c3c' if x >= 85 else '#f39c12' if x >= 70 else '#95a5a6' for x in impactos]\n",
        "\n",
        "bars = plt.barh(setores, impactos, color=cores, alpha=0.8)\n",
        "\n",
        "plt.title('üìä Impacto dos LLMs por Setor da Economia', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('N√≠vel de Impacto (%)', fontsize=12)\n",
        "plt.ylabel('Setores', fontsize=12)\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for bar, impacto in zip(bars, impactos):\n",
        "    width = bar.get_width()\n",
        "    plt.text(width + 1, bar.get_y() + bar.get_height()/2,\n",
        "             f'{impacto}%', ha='left', va='center', fontweight='bold')\n",
        "\n",
        "# Legenda\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [\n",
        "    Patch(facecolor='#e74c3c', label='Alto Impacto (85%+)'),\n",
        "    Patch(facecolor='#f39c12', label='M√©dio Impacto (70-84%)'),\n",
        "    Patch(facecolor='#95a5a6', label='Baixo Impacto (<70%)')\n",
        "]\n",
        "plt.legend(handles=legend_elements, loc='lower right')\n",
        "\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üéØ Principais insights:\")\n",
        "print(f\"ü•á Setor mais impactado: {setores[0]} ({impactos[0]}%)\")\n",
        "print(f\"üìà Setores de alto impacto: {len([x for x in impactos if x >= 85])} de {len(setores)}\")\n",
        "print(\"\\nüí° Quanto mais o setor depende de linguagem e comunica√ß√£o, maior o impacto!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introdu√ß√£o-√†-llms-modulo-02_img_04.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîó Preparando o Terreno: Pr√≥ximos M√≥dulos\n\nAgora que voc√™ j√° sabe **O QUE** s√£o LLMs, vamos nos preparar para entender **COMO** eles funcionam!\n\n### üó∫Ô∏è Nossa Jornada Continua...\n\n#### **M√≥dulo 3: Arquitetura Transformer** üèóÔ∏è\n- Vamos mergulhar na \"engine\" dos LLMs\n- Self-attention: o mecanismo m√°gico\n- Por que Transformers revolucionaram tudo\n\n#### **M√≥dulo 4: Tokens e Tokeniza√ß√£o** üî§\n- Como LLMs \"enxergam\" o texto\n- Por que \"tokeniza√ß√£o\" √© crucial\n- Diferentes estrat√©gias de tokeniza√ß√£o\n\n#### **M√≥dulo 5: Embeddings e Representa√ß√µes** üßÆ\n- Como palavras viram n√∫meros\n- O espa√ßo vetorial da linguagem\n- Por que \"rei - homem + mulher = rainha\"\n\n### üß† Conex√µes Importantes\n\n**Lembra quando falamos que LLMs calculam probabilidades?** \n- No M√≥dulo 3, veremos COMO eles fazem isso com Transformers\n- No M√≥dulo 4, entenderemos como o texto vira \"comida\" para o modelo\n- No M√≥dulo 5, descobriremos como significado vira matem√°tica\n\n**üí° Dica do Pedro:** Cada m√≥dulo vai \"clickar\" com os anteriores. √â como montar um quebra-cabe√ßa - cada pe√ßa que voc√™ aprende faz o quadro geral ficar mais claro!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mapa mental dos pr√≥ximos m√≥dulos\n",
        "modulos_info = {\n",
        "    'M√≥dulo 2\\n(ATUAL)': {\n",
        "        'conceitos': ['Defini√ß√£o LLMs', 'Hist√≥ria', 'Capacidades'],\n",
        "        'cor': '#e74c3c',\n",
        "        'status': 'Completo'\n",
        "    },\n",
        "    'M√≥dulo 3\\n(Transformers)': {\n",
        "        'conceitos': ['Self-Attention', 'Encoder/Decoder', 'Arquitetura'],\n",
        "        'cor': '#3498db', \n",
        "        'status': 'Pr√≥ximo'\n",
        "    },\n",
        "    'M√≥dulo 4\\n(Tokens)': {\n",
        "        'conceitos': ['Tokeniza√ß√£o', 'Vocabul√°rio', 'BPE'],\n",
        "        'cor': '#f39c12',\n",
        "        'status': 'Futuro'\n",
        "    },\n",
        "    'M√≥dulo 5\\n(Embeddings)': {\n",
        "        'conceitos': ['Vetores', 'Espa√ßo Sem√¢ntico', 'Similaridade'],\n",
        "        'cor': '#2ecc71',\n",
        "        'status': 'Futuro'\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"üó∫Ô∏è ROADMAP DO CURSO: PR√ìXIMOS M√ìDULOS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, (modulo, info) in enumerate(modulos_info.items(), 1):\n",
        "    status_emoji = \"‚úÖ\" if info['status'] == 'Completo' else \"‚ñ∂Ô∏è\" if info['status'] == 'Pr√≥ximo' else \"‚è≥\"\n",
        "    \n",
        "    print(f\"\\n{status_emoji} {modulo}\")\n",
        "    print(f\"   Status: {info['status']}\")\n",
        "    print(f\"   Conceitos-chave: {', '.join(info['conceitos'])}\")\n",
        "    \n",
        "    if info['status'] == 'Pr√≥ximo':\n",
        "        print(\"   üéØ FOCO: Entender a arquitetura que torna LLMs poss√≠veis!\")\n",
        "    elif info['status'] == 'Futuro' and 'Tokens' in modulo:\n",
        "        print(\"   üéØ FOCO: Como texto vira n√∫meros que LLMs entendem\")\n",
        "    elif info['status'] == 'Futuro' and 'Embeddings' in modulo:\n",
        "        print(\"   üéØ FOCO: A matem√°tica por tr√°s do significado\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üí° Lembre-se: cada m√≥dulo constr√≥i em cima do anterior!\")\n",
        "print(\"üöÄ Voc√™ j√° deu o primeiro passo importante entendendo O QUE s√£o LLMs!\")\n",
        "print(\"üìö Agora vamos descobrir COMO eles fazem a m√°gica acontecer!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üí™ Exerc√≠cio Pr√°tico 1: Identificando LLMs na Vida Real\n\nHora de colocar a m√£o na massa! Vamos identificar onde voc√™ j√° usa LLMs sem saber!\n\n### üéØ Seu Desafio:\nComplete a lista abaixo identificando se cada ferramenta usa ou n√£o LLMs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO 1: Identificando LLMs na vida real\n",
        "# Complete True/False para cada ferramenta\n",
        "\n",
        "ferramentas_quiz = {\n",
        "    'ChatGPT': None,                    # Substitua None por True ou False\n",
        "    'Google Translate': None,           # Dica: vers√µes modernas usam!\n",
        "    'GitHub Copilot': None,             # Para programa√ß√£o\n",
        "    'Siri (2023+)': None,               # Vers√µes recentes\n",
        "    'Excel tradicional': None,          # Planilhas normais\n",
        "    'Grammarly': None,                  # Corretor de texto\n",
        "    'Netflix recomenda√ß√µes': None,      # Sistema de recomenda√ß√£o\n",
        "    'Claude (Anthropic)': None,         # Chatbot IA\n",
        "    'WhatsApp corretor': None,          # Corretor simples\n",
        "    'Jasper AI': None                   # Ferramenta de copywriting\n",
        "}\n",
        "\n",
        "# SUAS RESPOSTAS AQUI:\n",
        "# Exemplo: ferramentas_quiz['ChatGPT'] = True\n",
        "\n",
        "# TODO: Complete suas respostas acima!\n",
        "\n",
        "# Gabarito (n√£o olhe antes de tentar!)\n",
        "gabarito = {\n",
        "    'ChatGPT': True,                    # √ìbvio! √â um LLM\n",
        "    'Google Translate': True,           # Vers√µes modernas usam LLMs\n",
        "    'GitHub Copilot': True,             # Baseado em LLMs para c√≥digo\n",
        "    'Siri (2023+)': True,               # Apple integrou LLMs\n",
        "    'Excel tradicional': False,         # S√≥ f√≥rmulas, sem IA generativa\n",
        "    'Grammarly': True,                  # Usa LLMs para sugest√µes avan√ßadas\n",
        "    'Netflix recomenda√ß√µes': False,     # ML tradicional, n√£o LLM\n",
        "    'Claude (Anthropic)': True,         # √â um LLM competidor do GPT\n",
        "    'WhatsApp corretor': False,         # Corretor simples, baseado em regras\n",
        "    'Jasper AI': True                   # Ferramenta de copywriting com LLM\n",
        "}\n",
        "\n",
        "def verificar_respostas(suas_respostas, gabarito):\n",
        "    \"\"\"Verifica suas respostas contra o gabarito\"\"\"\n",
        "    acertos = 0\n",
        "    total = len(gabarito)\n",
        "    \n",
        "    print(\"üìù CORRE√á√ÉO DO EXERC√çCIO\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    for ferramenta, resposta_correta in gabarito.items():\n",
        "        sua_resposta = suas_respostas.get(ferramenta)\n",
        "        \n",
        "        if sua_resposta is None:\n",
        "            status = \"‚ùå N√£o respondido\"\n",
        "        elif sua_resposta == resposta_correta:\n",
        "            status = \"‚úÖ Correto\"\n",
        "            acertos += 1\n",
        "        else:\n",
        "            status = \"‚ùå Incorreto\"\n",
        "        \n",
        "        print(f\"{ferramenta:20} | {status:15} | Gabarito: {resposta_correta}\")\n",
        "    \n",
        "    nota = (acertos / total) * 100\n",
        "    print(\"\\n\" + \"=\" * 40)\n",
        "    print(f\"üéØ Sua pontua√ß√£o: {acertos}/{total} ({nota:.1f}%)\")\n",
        "    \n",
        "    if nota >= 80:\n",
        "        print(\"üèÜ Excelente! Voc√™ j√° entende bem onde LLMs s√£o usados!\")\n",
        "    elif nota >= 60:\n",
        "        print(\"üëç Bom trabalho! Algumas ferramentas podem ter te surpreendido.\")\n",
        "    else:\n",
        "        print(\"üìö Precisa estudar mais! Releia o m√≥dulo e tente novamente.\")\n",
        "\n",
        "# Descomente a linha abaixo AP√ìS completar suas respostas\n",
        "# verificar_respostas(ferramentas_quiz, gabarito)\n",
        "\n",
        "print(\"üí° Complete suas respostas acima e descomente a √∫ltima linha para ver o resultado!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß© Exerc√≠cio Pr√°tico 2: Criando Seu Pr√≥prio Caso de Uso\n\nAgora √© sua vez de ser criativo! Vamos pensar em como voc√™ poderia usar LLMs no seu dia a dia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO 2: Criando seu caso de uso personalizado\n",
        "\n",
        "def meu_caso_de_uso_llm():\n",
        "    \"\"\"\n",
        "    Complete as informa√ß√µes sobre como VOC√ä usaria um LLM:\n",
        "    \"\"\"\n",
        "    \n",
        "    # TODO: Complete as informa√ß√µes abaixo\n",
        "    caso_uso = {\n",
        "        'area': '',           # Ex: \"Educa√ß√£o\", \"Trabalho\", \"Hobby\", etc.\n",
        "        'problema': '',       # Que problema voc√™ quer resolver?\n",
        "        'solucao_llm': '',    # Como um LLM ajudaria?\n",
        "        'input_exemplo': '',  # Exemplo de entrada\n",
        "        'output_esperado': '', # O que voc√™ esperaria receber\n",
        "        'beneficios': []      # Lista de benef√≠cios (pelo menos 3)\n",
        "    }\n",
        "    \n",
        "    return caso_uso\n",
        "\n",
        "# Exemplo preenchido para inspira√ß√£o:\n",
        "exemplo_caso = {\n",
        "    'area': 'Educa√ß√£o',\n",
        "    'problema': 'Criar exerc√≠cios personalizados para meus alunos',\n",
        "    'solucao_llm': 'LLM geraria exerc√≠cios adaptativos baseados no n√≠vel de cada aluno',\n",
        "    'input_exemplo': 'Crie 5 exerc√≠cios de matem√°tica sobre fra√ß√µes para n√≠vel iniciante',\n",
        "    'output_esperado': 'Lista de exerc√≠cios progressivos com explica√ß√µes passo-a-passo',\n",
        "    'beneficios': [\n",
        "        'Economiza tempo na prepara√ß√£o',\n",
        "        'Personaliza√ß√£o autom√°tica', \n",
        "        'Exerc√≠cios sempre variados',\n",
        "        'Feedback instant√¢neo'\n",
        "    ]\n",
        "}\n",
        "\n",
        "def avaliar_caso_uso(caso):\n",
        "    \"\"\"Avalia se o caso de uso est√° bem estruturado\"\"\"\n",
        "    print(\"üîç AN√ÅLISE DO SEU CASO DE USO\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    pontos = 0\n",
        "    feedback = []\n",
        "    \n",
        "    # Verifica√ß√µes\n",
        "    if caso['area']:\n",
        "        pontos += 1\n",
        "        print(f\"‚úÖ √Årea definida: {caso['area']}\")\n",
        "    else:\n",
        "        feedback.append(\"‚ùå Defina a √°rea de aplica√ß√£o\")\n",
        "    \n",
        "    if caso['problema']:\n",
        "        pontos += 1\n",
        "        print(f\"‚úÖ Problema claro: {caso['problema'][:50]}...\")\n",
        "    else:\n",
        "        feedback.append(\"‚ùå Descreva o problema a resolver\")\n",
        "    \n",
        "    if caso['solucao_llm']:\n",
        "        pontos += 1\n",
        "        print(f\"‚úÖ Solu√ß√£o com LLM: {caso['solucao_llm'][:50]}...\")\n",
        "    else:\n",
        "        feedback.append(\"‚ùå Explique como LLM ajudaria\")\n",
        "    \n",
        "    if len(caso['beneficios']) >= 3:\n",
        "        pontos += 1\n",
        "        print(f\"‚úÖ Benef√≠cios listados: {len(caso['beneficios'])} itens\")\n",
        "    else:\n",
        "        feedback.append(\"‚ùå Liste pelo menos 3 benef√≠cios\")\n",
        "    \n",
        "    print(f\"\\nüéØ Pontua√ß√£o: {pontos}/4\")\n",
        "    \n",
        "    if pontos == 4:\n",
        "        print(\"üèÜ Perfeito! Seu caso de uso est√° muito bem estruturado!\")\n",
        "    elif pontos >= 2:\n",
        "        print(\"üëç Bom in√≠cio! Alguns ajustes podem melhorar:\")\n",
        "        for f in feedback:\n",
        "            print(f\"   {f}\")\n",
        "    else:\n",
        "        print(\"üìö Precisa desenvolver mais. Sugest√µes:\")\n",
        "        for f in feedback:\n",
        "            print(f\"   {f}\")\n",
        "\n",
        "# TODO: Complete a fun√ß√£o meu_caso_de_uso_llm() acima\n",
        "# Depois descomente as linhas abaixo:\n",
        "\n",
        "# meu_caso = meu_caso_de_uso_llm()\n",
        "# avaliar_caso_uso(meu_caso)\n",
        "\n",
        "print(\"üí° Complete sua fun√ß√£o acima e descomente as √∫ltimas linhas para avalia√ß√£o!\")\n",
        "print(\"üéØ Use o exemplo como inspira√ß√£o, mas crie algo √öNICO para voc√™!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéä Resumo do M√≥dulo: O que Aprendemos\n\n**Parab√©ns!** üéâ Voc√™ completou o M√≥dulo 2 e agora tem uma base s√≥lida sobre LLMs!\n\n### üß† Conceitos-Chave Dominados:\n\n‚úÖ **Defini√ß√£o Clara**: LLMs s√£o modelos de rede neural gigantes treinados em texto  \n‚úÖ **Funcionamento B√°sico**: Predizem pr√≥ximas palavras baseado em probabilidades  \n‚úÖ **Evolu√ß√£o Hist√≥rica**: De Transformer (2017) at√© GPT-4 (2023)  \n‚úÖ **Capacidades Principais**: Gera√ß√£o, compreens√£o, tradu√ß√£o, programa√ß√£o  \n‚úÖ **Casos de Uso Reais**: Customer service, educa√ß√£o, criatividade, produtividade  \n\n### üîó Conex√µes com Pr√≥ximos M√≥dulos:\n\n- **M√≥dulo 3 (Transformers)**: Vai explicar COMO eles fazem os c√°lculos de probabilidade\n- **M√≥dulo 4 (Tokens)**: Vai mostrar como texto vira \"comida\" para LLMs\n- **M√≥dulo 5 (Embeddings)**: Vai revelar como significado vira matem√°tica\n\n### üéØ Principais Insights:\n\n1. **Size Matters**: \"Large\" n√£o √© marketing - s√£o BILH√ïES de par√¢metros\n2. **Context is King**: LLMs s√£o mestres em entender contexto\n3. **Versatilidade**: Uma tecnologia, infinitas aplica√ß√µes\n4. **Still Evolving**: Estamos apenas no come√ßo dessa revolu√ß√£o\n\n**üí° Dica Final do Pedro**: Agora que voc√™ entende O QUE s√£o LLMs, est√° pronto para mergulhar no COMO eles funcionam. No pr√≥ximo m√≥dulo, vamos destrinchar a arquitetura Transformer - prepare-se para algumas revela√ß√µes incr√≠veis!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualiza√ß√£o final: Seu progresso no curso\n",
        "modulos_curso = [\n",
        "    'Setup Inicial',\n",
        "    'O que s√£o LLMs',          # <- VOC√ä EST√Å AQUI!\n",
        "    'Arquitetura Transformer',\n",
        "    'Tokens e Tokeniza√ß√£o', \n",
        "    'Embeddings',\n",
        "    'Tipos de Modelos',\n",
        "    'Treinamento',\n",
        "    'Prompting',\n",
        "    'Avalia√ß√£o',\n",
        "    'Seguran√ßa',\n",
        "    'Limita√ß√µes',\n",
        "    'Projeto Final',\n",
        "    'T√≥picos Avan√ßados'\n",
        "]\n",
        "\n",
        "progresso = [100, 100] + [0] * 11  # M√≥dulos 1 e 2 completos\n",
        "status_cores = ['#2ecc71' if p == 100 else '#f39c12' if p > 0 else '#ecf0f1' for p in progresso]\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "bars = plt.barh(range(len(modulos_curso)), progresso, color=status_cores, alpha=0.8)\n",
        "\n",
        "# Destacar m√≥dulo atual\n",
        "bars[1].set_edgecolor('#e74c3c')\n",
        "bars[1].set_linewidth(3)\n",
        "\n",
        "plt.title('üöÄ Seu Progresso no Curso \"Introdu√ß√£o √† LLMs\"', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Progresso (%)', fontsize=12)\n",
        "plt.ylabel('M√≥dulos', fontsize=12)\n",
        "\n",
        "# Labels dos m√≥dulos\n",
        "plt.yticks(range(len(modulos_curso)), \n",
        "           [f'{i+1}. {modulo}' for i, modulo in enumerate(modulos_curso)])\n",
        "\n",
        "# Adicionando percentuais e status\n",
        "for i, (bar, prog) in enumerate(zip(bars, progresso)):\n",
        "    width = bar.get_width()\n",
        "    if prog == 100:\n",
        "        label = '‚úÖ 100%'\n",
        "        color = 'white'\n",
        "    elif prog > 0:\n",
        "        label = f'{prog}%'\n",
        "        color = 'white'\n",
        "    else:\n",
        "        label = 'Pendente'\n",
        "        color = '#7f8c8d'\n",
        "    \n",
        "    plt.text(width/2 if prog > 0 else 5, bar.get_y() + bar.get_height()/2,\n",
        "             label, ha='center', va='center', fontweight='bold', color=color)\n",
        "\n",
        "# Destacar m√≥dulo atual\n",
        "plt.text(110, 1, 'üëà VOC√ä EST√Å AQUI!', \n",
        "         ha='left', va='center', fontsize=12, fontweight='bold', color='#e74c3c')\n",
        "\n",
        "plt.xlim(0, 120)\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üèÜ PARAB√âNS! Voc√™ completou mais um m√≥dulo!\")\n",
        "print(f\"üìä Progresso geral: {sum(progresso)/len(progresso):.1f}%\")\n",
        "print(f\"‚úÖ M√≥dulos completos: {len([p for p in progresso if p == 100])}/13\")\n",
        "print(\"\\nüéØ Pr√≥xima parada: Arquitetura Transformer!\")\n",
        "print(\"üí™ Continue assim - voc√™ est√° indo muito bem!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introdu√ß√£o-√†-llms-modulo-02_img_05.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## üöÄ At√© o Pr√≥ximo M√≥dulo!\n\n**Liiindo!** Voc√™ arrasou neste m√≥dulo! üéä\n\nAgora voc√™:\n- Entende o que s√£o LLMs de verdade\n- Sabe como eles evolu√≠ram\n- Conhece suas principais capacidades\n- Pode identific√°-los na vida real\n\n**No pr√≥ximo m√≥dulo** vamos abrir o cap√¥ e ver como a m√°gica acontece com **Transformers**. Prepare-se para entender o mecanismo de **self-attention** que mudou tudo!\n\n**Bora que bora!** üöÄ\n\n---\n\n*Desenvolvido com ‚ù§Ô∏è por Pedro Nunes Guth*  \n*Curso: Introdu√ß√£o √† LLMs - M√≥dulo 2/13*"
      ]
    }
  ]
}