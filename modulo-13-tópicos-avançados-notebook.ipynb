{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftXpC3n5Y2mB"
      },
      "source": [
        "# üöÄ LLMs do Futuro: Explorando o Imposs√≠vel (Que J√° Est√° Acontecendo!)\n",
        "\n",
        "**M√≥dulo 13 - T√≥picos Avan√ßados | Curso Introdu√ß√£o √† LLMs**\n",
        "\n",
        "---\n",
        "\n",
        "E a√≠, pessoal! üéØ Chegamos ao nosso √∫ltimo m√≥dulo e, cara, que jornada foi essa!\n",
        "\n",
        "Lembra quando come√ßamos falando sobre tokens no M√≥dulo 4? Ou quando desvendamos os mist√©rios do Transformer no M√≥dulo 3? Agora vamos ver o que vem por a√≠ no mundo dos LLMs!\n",
        "\n",
        "Bora explorar as tecnologias que v√£o revolucionar ainda mais esse universo nos pr√≥ximos anos!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lS16BdCY2mC"
      },
      "source": [
        "## üéØ O Que Vamos Aprender\n",
        "\n",
        "Neste m√≥dulo final, vamos mergulhar nos t√≥picos mais avan√ßados:\n",
        "\n",
        "- **Retrieval Augmented Generation (RAG)**: Como dar \"superpoderes\" aos LLMs\n",
        "- **Multimodalidade**: LLMs que \"veem\" e \"ouvem\"\n",
        "- **Agentes Aut√¥nomos**: IA que age no mundo real\n",
        "- **T√©cnicas de Otimiza√ß√£o**: Como deixar tudo mais r√°pido\n",
        "- **O Futuro dos LLMs**: O que vem por a√≠\n",
        "\n",
        "**Dica do Pedro**: Este m√≥dulo √© como o \"p√≥s-cr√©ditos\" de um filme da Marvel - aqui voc√™ vai ver o que est√° vindo por a√≠! üé¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ha-1MMwBY2mC"
      },
      "outputs": [],
      "source": [
        "# Setup inicial - importando as bibliotecas para nossa jornada avan√ßada\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configura√ß√£o dos gr√°ficos\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"üöÄ Ambiente configurado! Bora para os t√≥picos avan√ßados!\")\n",
        "print(f\"üìÖ Data de in√≠cio da aventura: {datetime.now().strftime('%d/%m/%Y %H:%M')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-24fsZ4dY2mD"
      },
      "source": [
        "## üîç RAG (Retrieval Augmented Generation)\n",
        "\n",
        "### O Que √© RAG? √â Como Dar um Google Pro ao seu LLM!\n",
        "\n",
        "T√°, mas o que √© RAG? Imagine que voc√™ tem um amigo superinteligente (o LLM), mas que s√≥ sabe das coisas at√© 2021. Da√≠ voc√™ d√° um celular pra ele (o sistema de retrieval) para ele pesquisar informa√ß√µes atuais antes de responder.\n",
        "\n",
        "**√â isso que o RAG faz!**\n",
        "\n",
        "### Como Funciona?\n",
        "\n",
        "1. **Pergunta chega**: \"Qual foi o √∫ltimo lan√ßamento da Tesla?\"\n",
        "2. **Sistema busca**: Vai em uma base de dados atualizada\n",
        "3. **Encontra informa√ß√£o**: Dados recentes sobre Tesla\n",
        "4. **LLM responde**: Usando tanto seu conhecimento quanto a info nova\n",
        "\n",
        "![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/introduc%CC%A7a%CC%83o-a%CC%80-llms-modulo-13_img_01.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeoIeFBjY2mD"
      },
      "outputs": [],
      "source": [
        "# Simulando um sistema RAG simples\n",
        "class SimpleRAG:\n",
        "    def __init__(self):\n",
        "        # Base de conhecimento simulada (seria um vetor database na vida real)\n",
        "        self.knowledge_base = {\n",
        "            \"python\": \"Python √© uma linguagem de programa√ß√£o de alto n√≠vel, lan√ßada em 1991\",\n",
        "            \"machine learning\": \"ML √© um subcampo da IA que permite sistemas aprenderem automaticamente\",\n",
        "            \"transformer\": \"Arquitetura revolucion√°ria apresentada no paper 'Attention is All You Need'\",\n",
        "            \"tokens\": \"Unidades b√°sicas de texto processadas pelos modelos de linguagem\"\n",
        "        }\n",
        "\n",
        "    def retrieve(self, query):\n",
        "        \"\"\"Simula a busca por informa√ß√£o relevante\"\"\"\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        # Busca simples por palavras-chave\n",
        "        for key, value in self.knowledge_base.items():\n",
        "            if key in query_lower:\n",
        "                return value\n",
        "\n",
        "        return \"Informa√ß√£o n√£o encontrada na base de conhecimento\"\n",
        "\n",
        "    def generate_response(self, query, retrieved_info):\n",
        "        \"\"\"Simula a gera√ß√£o de resposta do LLM\"\"\"\n",
        "        if \"n√£o encontrada\" in retrieved_info:\n",
        "            return f\"Desculpe, n√£o tenho informa√ß√µes espec√≠ficas sobre: {query}\"\n",
        "\n",
        "        return f\"Com base nas informa√ß√µes mais recentes: {retrieved_info}. Isso responde sua pergunta sobre {query}.\"\n",
        "\n",
        "    def ask(self, query):\n",
        "        \"\"\"Pipeline completo RAG\"\"\"\n",
        "        print(f\"üîç Pergunta: {query}\")\n",
        "\n",
        "        # Passo 1: Retrieval\n",
        "        retrieved = self.retrieve(query)\n",
        "        print(f\"üìö Informa√ß√£o encontrada: {retrieved}\")\n",
        "\n",
        "        # Passo 2: Generation\n",
        "        response = self.generate_response(query, retrieved)\n",
        "        print(f\"ü§ñ Resposta final: {response}\\n\")\n",
        "\n",
        "        return response\n",
        "\n",
        "# Testando nosso RAG\n",
        "rag_system = SimpleRAG()\n",
        "\n",
        "# Perguntas de teste\n",
        "perguntas = [\n",
        "    \"O que √© Python?\",\n",
        "    \"Explique machine learning\",\n",
        "    \"Como funcionam os tokens?\"\n",
        "]\n",
        "\n",
        "print(\"üéØ Testando nosso sistema RAG simples:\\n\")\n",
        "for pergunta in perguntas:\n",
        "    rag_system.ask(pergunta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNPFuJfEY2mD"
      },
      "source": [
        "### Arquitetura RAG em Detalhes\n",
        "\n",
        "Vamos visualizar como funciona um sistema RAG completo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_VnIOHVY2mE"
      },
      "outputs": [],
      "source": [
        "# Visualizando o pipeline RAG\n",
        "fig, ax = plt.subplots(figsize=(14, 10))\n",
        "\n",
        "# Dados para o fluxo RAG\n",
        "steps = ['Query\\nUsu√°rio', 'Embedding\\nQuery', 'Busca\\nVetorial', 'Retrieval\\nDocumentos',\n",
        "         'Context\\nAugmentation', 'LLM\\nGeneration', 'Resposta\\nFinal']\n",
        "times = [0, 50, 200, 300, 350, 800, 900]  # Tempos simulados em ms\n",
        "complexities = [1, 3, 5, 4, 6, 9, 8]  # Complexidade computacional\n",
        "\n",
        "# Gr√°fico de linha para tempo\n",
        "ax2 = ax.twinx()\n",
        "line1 = ax.plot(steps, times, 'bo-', linewidth=3, markersize=8, label='Tempo (ms)')\n",
        "line2 = ax2.plot(steps, complexities, 'ro-', linewidth=3, markersize=8, label='Complexidade')\n",
        "\n",
        "# Configura√ß√£o dos eixos\n",
        "ax.set_xlabel('Etapas do Pipeline RAG', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('Tempo (ms)', fontsize=14, fontweight='bold', color='blue')\n",
        "ax2.set_ylabel('Complexidade Computacional', fontsize=14, fontweight='bold', color='red')\n",
        "\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.tick_params(axis='y', labelcolor='blue')\n",
        "ax2.tick_params(axis='y', labelcolor='red')\n",
        "\n",
        "# T√≠tulo e grid\n",
        "ax.set_title('Pipeline RAG: Tempo vs Complexidade por Etapa', fontsize=16, fontweight='bold', pad=20)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Legenda\n",
        "lines1, labels1 = ax.get_legend_handles_labels()\n",
        "lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "ax.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Observa√ß√µes importantes:\")\n",
        "print(\"‚Ä¢ A gera√ß√£o pelo LLM √© o passo mais demorado\")\n",
        "print(\"‚Ä¢ A busca vetorial √© super r√°pida mas complexa\")\n",
        "print(\"‚Ä¢ O context augmentation √© crucial para qualidade\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi5Gh4tiY2mE"
      },
      "source": [
        "**Dica do Pedro**: RAG √© como ter uma biblioteca infinita + um bibliotec√°rio super inteligente. O bibliotec√°rio (LLM) n√£o precisa decorar todos os livros, s√≥ precisa saber onde encontrar a informa√ß√£o! üìö"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3EyjLxCY2mE"
      },
      "source": [
        "## üëÅÔ∏è Multimodalidade: LLMs que Veem, Ouvem e Sentem\n",
        "\n",
        "### Al√©m do Texto: A Revolu√ß√£o Sensorial dos LLMs\n",
        "\n",
        "Lembra quando falamos sobre tokens no M√≥dulo 4? Pois √©, agora os \"tokens\" podem ser:\n",
        "- **Pixels de imagem** üñºÔ∏è\n",
        "- **Frequ√™ncias de √°udio** üéµ  \n",
        "- **Coordenadas 3D** üéÆ\n",
        "- **Sinais de v√≠deo** üé¨\n",
        "\n",
        "√â como se o LLM ganhasse olhos, ouvidos e tato!\n",
        "\n",
        "### Tipos de Modalidades\n",
        "\n",
        "![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/introduc%CC%A7a%CC%83o-a%CC%80-llms-modulo-13_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9tFqRqbY2mE"
      },
      "outputs": [],
      "source": [
        "# Simulando processamento multimodal\n",
        "class MultimodalProcessor:\n",
        "    def __init__(self):\n",
        "        self.modalities = {\n",
        "            'texto': {'dimensao': 768, 'tipo': 'sequencial'},\n",
        "            'imagem': {'dimensao': 2048, 'tipo': 'espacial'},\n",
        "            'audio': {'dimensao': 1024, 'tipo': 'temporal'},\n",
        "            'video': {'dimensao': 3072, 'tipo': 'espaco-temporal'}\n",
        "        }\n",
        "\n",
        "    def process_modality(self, modality_type, input_size):\n",
        "        \"\"\"Simula o processamento de diferentes modalidades\"\"\"\n",
        "        config = self.modalities[modality_type]\n",
        "\n",
        "        # Simula√ß√£o de embedding para cada modalidade\n",
        "        embedding_dim = config['dimensao']\n",
        "        processing_type = config['tipo']\n",
        "\n",
        "        # Tempo de processamento varia por modalidade\n",
        "        processing_times = {\n",
        "            'texto': input_size * 0.1,\n",
        "            'imagem': input_size * 0.5,\n",
        "            'audio': input_size * 0.3,\n",
        "            'video': input_size * 1.0\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            'embedding_dim': embedding_dim,\n",
        "            'processing_type': processing_type,\n",
        "            'processing_time': processing_times[modality_type],\n",
        "            'output_tokens': input_size // 4  # Compress√£o simulada\n",
        "        }\n",
        "\n",
        "    def fuse_modalities(self, modalities_data):\n",
        "        \"\"\"Simula a fus√£o de m√∫ltiplas modalidades\"\"\"\n",
        "        total_tokens = sum(data['output_tokens'] for data in modalities_data.values())\n",
        "        total_time = sum(data['processing_time'] for data in modalities_data.values())\n",
        "\n",
        "        return {\n",
        "            'total_tokens': total_tokens,\n",
        "            'total_processing_time': total_time,\n",
        "            'fusion_complexity': len(modalities_data) ** 2\n",
        "        }\n",
        "\n",
        "# Testando processamento multimodal\n",
        "processor = MultimodalProcessor()\n",
        "\n",
        "# Simulando diferentes inputs\n",
        "inputs = {\n",
        "    'texto': 100,      # 100 tokens de texto\n",
        "    'imagem': 1000,    # 1000 pixels processados\n",
        "    'audio': 500,      # 500 samples de √°udio\n",
        "    'video': 2000      # 2000 frames de v√≠deo\n",
        "}\n",
        "\n",
        "print(\"üéØ Processamento Multimodal em A√ß√£o!\\n\")\n",
        "\n",
        "results = {}\n",
        "for modality, input_size in inputs.items():\n",
        "    result = processor.process_modality(modality, input_size)\n",
        "    results[modality] = result\n",
        "\n",
        "    print(f\"üìä {modality.upper()}:\")\n",
        "    print(f\"   ‚Ä¢ Dimens√£o embedding: {result['embedding_dim']}\")\n",
        "    print(f\"   ‚Ä¢ Tipo processamento: {result['processing_type']}\")\n",
        "    print(f\"   ‚Ä¢ Tempo: {result['processing_time']:.2f}ms\")\n",
        "    print(f\"   ‚Ä¢ Tokens output: {result['output_tokens']}\\n\")\n",
        "\n",
        "# Fus√£o multimodal\n",
        "fusion_result = processor.fuse_modalities(results)\n",
        "print(\"üî• FUS√ÉO MULTIMODAL:\")\n",
        "print(f\"   ‚Ä¢ Total de tokens: {fusion_result['total_tokens']}\")\n",
        "print(f\"   ‚Ä¢ Tempo total: {fusion_result['total_processing_time']:.2f}ms\")\n",
        "print(f\"   ‚Ä¢ Complexidade fus√£o: {fusion_result['fusion_complexity']}x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2MC2tw8Y2mE"
      },
      "source": [
        "### Arquitetura de Attention Multimodal\n",
        "\n",
        "Lembra do mecanismo de attention que vimos no M√≥dulo 3? Agora ele precisa funcionar entre diferentes modalidades!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dM-P9GzY2mF"
      },
      "outputs": [],
      "source": [
        "# Visualizando attention multimodal\n",
        "def create_multimodal_attention_matrix():\n",
        "    # Simulando matriz de attention entre modalidades\n",
        "    modalities = ['Texto', 'Imagem', '√Åudio', 'V√≠deo']\n",
        "    n_mod = len(modalities)\n",
        "\n",
        "    # Criando matriz de attention simulada\n",
        "    attention_matrix = np.random.rand(n_mod, n_mod)\n",
        "\n",
        "    # Fazendo a matriz sim√©trica e normalizando\n",
        "    attention_matrix = (attention_matrix + attention_matrix.T) / 2\n",
        "    attention_matrix = attention_matrix / attention_matrix.sum(axis=1, keepdims=True)\n",
        "\n",
        "    return attention_matrix, modalities\n",
        "\n",
        "# Criando e visualizando\n",
        "attention_matrix, modalities = create_multimodal_attention_matrix()\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Heatmap da matriz de attention\n",
        "im1 = ax1.imshow(attention_matrix, cmap='Blues', aspect='equal')\n",
        "ax1.set_title('Matriz de Attention Multimodal', fontsize=14, fontweight='bold')\n",
        "ax1.set_xticks(range(len(modalities)))\n",
        "ax1.set_yticks(range(len(modalities)))\n",
        "ax1.set_xticklabels(modalities)\n",
        "ax1.set_yticklabels(modalities)\n",
        "\n",
        "# Adicionando valores na matriz\n",
        "for i in range(len(modalities)):\n",
        "    for j in range(len(modalities)):\n",
        "        text = ax1.text(j, i, f'{attention_matrix[i, j]:.2f}',\n",
        "                       ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n",
        "\n",
        "plt.colorbar(im1, ax=ax1)\n",
        "\n",
        "# Gr√°fico de barras das modalidades\n",
        "modal_importance = attention_matrix.mean(axis=0)\n",
        "bars = ax2.bar(modalities, modal_importance,\n",
        "               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
        "ax2.set_title('Import√¢ncia M√©dia por Modalidade', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylabel('Score de Attention')\n",
        "ax2.set_ylim(0, max(modal_importance) * 1.1)\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for bar, value in zip(bars, modal_importance):\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üéØ Insights sobre Attention Multimodal:\")\n",
        "print(f\"‚Ä¢ Modalidade mais 'atenta': {modalities[np.argmax(modal_importance)]}\")\n",
        "print(f\"‚Ä¢ Modalidade menos 'atenta': {modalities[np.argmin(modal_importance)]}\")\n",
        "print(\"‚Ä¢ Cada modalidade 'conversa' com as outras atrav√©s do attention!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3PSGuCdY2mF"
      },
      "source": [
        "## ü§ñ Agentes Aut√¥nomos: LLMs que Agem no Mundo Real\n",
        "\n",
        "### Da Conversa para a A√ß√£o!\n",
        "\n",
        "Imagina um LLM que n√£o s√≥ responde suas perguntas, mas tamb√©m:\n",
        "- **Agenda suas reuni√µes** üìÖ\n",
        "- **Faz compras online** üõí\n",
        "- **Controla sua casa inteligente** üè†\n",
        "- **Programa c√≥digo e deploya** üíª\n",
        "\n",
        "**Isso s√£o os Agentes Aut√¥nomos!**\n",
        "\n",
        "### Arquitetura de um Agente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T39cPUWVY2mF"
      },
      "source": [
        "[![](https://mermaid.ink/img/eyJjb2RlIjoiZ3JhcGggVERcbiAgICBBW0VudHJhZGEgZG8gVXN1w6FyaW9dIC0tPiBCW0xMTSBSZWFzb25pbmddXG4gICAgQiAtLT4gQ3tQcmVjaXNhIGRlIEHDp8Ojbz99XG4gICAgQyAtLT58U2ltfCBEW1NlbGXDp8OjbyBkZSBUb29sXVxuICAgIEMgLS0-fE7Do298IEhbUmVzcG9zdGEgRGlyZXRhXVxuICAgIEQgLS0-IEVbRXhlY3XDp8OjbyBkYSBBw6fDo29dXG4gICAgRSAtLT4gRltSZXN1bHRhZG8gZGEgQcOnw6NvXVxuICAgIEYgLS0-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)](https://mermaid.d.foundation/#/edit/eyJjb2RlIjoiZ3JhcGggVERcbiAgICBBW0VudHJhZGEgZG8gVXN1w6FyaW9dIC0tPiBCW0xMTSBSZWFzb25pbmddXG4gICAgQiAtLT4gQ3tQcmVjaXNhIGRlIEHDp8Ojbz99XG4gICAgQyAtLT58U2ltfCBEW1NlbGXDp8OjbyBkZSBUb29sXVxuICAgIEMgLS0-fE7Do298IEhbUmVzcG9zdGEgRGlyZXRhXVxuICAgIEQgLS0-IEVbRXhlY3XDp8OjbyBkYSBBw6fDo29dXG4gICAgRSAtLT4gRltSZXN1bHRhZG8gZGEgQcOnw6NvXVxuICAgIEYgLS0-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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2D8IxIFNY2mF"
      },
      "outputs": [],
      "source": [
        "# Sistema de Agente Aut√¥nomo Simples\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "class AutonomousAgent:\n",
        "    def __init__(self):\n",
        "        self.tools = {\n",
        "            'calculadora': self.calculator,\n",
        "            'agenda': self.schedule_meeting,\n",
        "            'clima': self.get_weather,\n",
        "            'busca': self.web_search\n",
        "        }\n",
        "\n",
        "        self.memory = []  # Mem√≥ria das a√ß√µes\n",
        "\n",
        "    def calculator(self, expression):\n",
        "        \"\"\"Tool: Calculadora segura\"\"\"\n",
        "        try:\n",
        "            # Avalia√ß√£o segura apenas de express√µes matem√°ticas\n",
        "            allowed_chars = '0123456789+-*/.() '\n",
        "            if all(c in allowed_chars for c in expression):\n",
        "                result = eval(expression)\n",
        "                return f\"Resultado: {result}\"\n",
        "            else:\n",
        "                return \"Erro: Express√£o inv√°lida\"\n",
        "        except:\n",
        "            return \"Erro no c√°lculo\"\n",
        "\n",
        "    def schedule_meeting(self, details):\n",
        "        \"\"\"Tool: Agendamento de reuni√£o\"\"\"\n",
        "        meeting_time = datetime.now() + timedelta(days=1)\n",
        "        return f\"Reuni√£o '{details}' agendada para {meeting_time.strftime('%d/%m/%Y %H:%M')}\"\n",
        "\n",
        "    def get_weather(self, location):\n",
        "        \"\"\"Tool: Previs√£o do tempo (simulada)\"\"\"\n",
        "        weathers = ['Ensolarado', 'Nublado', 'Chuvoso', 'Parcialmente nublado']\n",
        "        temp = np.random.randint(15, 35)\n",
        "        weather = np.random.choice(weathers)\n",
        "        return f\"Em {location}: {weather}, {temp}¬∞C\"\n",
        "\n",
        "    def web_search(self, query):\n",
        "        \"\"\"Tool: Busca web (simulada)\"\"\"\n",
        "        results = [\n",
        "            f\"Encontrei 3 resultados relevantes sobre '{query}'\",\n",
        "            f\"Principais fontes sobre {query}: Wikipedia, artigos cient√≠ficos\",\n",
        "            f\"Informa√ß√µes mais recentes sobre {query} de fontes confi√°veis\"\n",
        "        ]\n",
        "        return np.random.choice(results)\n",
        "\n",
        "    def parse_intent(self, user_input):\n",
        "        \"\"\"Analisa a inten√ß√£o do usu√°rio e identifica tool necess√°rio\"\"\"\n",
        "        input_lower = user_input.lower()\n",
        "\n",
        "        if any(word in input_lower for word in ['calcular', 'soma', 'multiplicar', '+', '-', '*', '/']):\n",
        "            return 'calculadora'\n",
        "        elif any(word in input_lower for word in ['agendar', 'reuni√£o', 'meeting']):\n",
        "            return 'agenda'\n",
        "        elif any(word in input_lower for word in ['clima', 'tempo', 'temperatura']):\n",
        "            return 'clima'\n",
        "        elif any(word in input_lower for word in ['buscar', 'procurar', 'pesquisar']):\n",
        "            return 'busca'\n",
        "        else:\n",
        "            return 'conversa'  # Resposta conversacional\n",
        "\n",
        "    def extract_parameters(self, user_input, tool_type):\n",
        "        \"\"\"Extrai par√¢metros para cada tipo de tool\"\"\"\n",
        "        if tool_type == 'calculadora':\n",
        "            # Procura por express√£o matem√°tica\n",
        "            import re\n",
        "            math_expr = re.search(r'[0-9+\\-*/().\\s]+', user_input)\n",
        "            return math_expr.group() if math_expr else \"2+2\"\n",
        "\n",
        "        elif tool_type == 'agenda':\n",
        "            # Extrai detalhes da reuni√£o\n",
        "            return user_input.split('agendar')[-1].strip()\n",
        "\n",
        "        elif tool_type == 'clima':\n",
        "            # Procura por nome de cidade\n",
        "            cities = ['S√£o Paulo', 'Rio de Janeiro', 'Bras√≠lia', 'Salvador']\n",
        "            for city in cities:\n",
        "                if city.lower() in user_input.lower():\n",
        "                    return city\n",
        "            return \"S√£o Paulo\"  # Padr√£o\n",
        "\n",
        "        elif tool_type == 'busca':\n",
        "            # Extrai termo de busca\n",
        "            search_terms = user_input.replace('buscar', '').replace('procurar', '').strip()\n",
        "            return search_terms\n",
        "\n",
        "        return user_input\n",
        "\n",
        "    def process_request(self, user_input):\n",
        "        \"\"\"Pipeline principal do agente\"\"\"\n",
        "        print(f\"üë§ Usu√°rio: {user_input}\")\n",
        "\n",
        "        # 1. An√°lise de inten√ß√£o\n",
        "        intent = self.parse_intent(user_input)\n",
        "        print(f\"üß† Inten√ß√£o detectada: {intent}\")\n",
        "\n",
        "        # 2. Se for conversa simples\n",
        "        if intent == 'conversa':\n",
        "            response = \"Entendi! Como posso ajudar voc√™ hoje? Posso calcular, agendar, verificar clima ou buscar informa√ß√µes.\"\n",
        "            print(f\"ü§ñ Resposta: {response}\\n\")\n",
        "            return response\n",
        "\n",
        "        # 3. Extra√ß√£o de par√¢metros\n",
        "        params = self.extract_parameters(user_input, intent)\n",
        "        print(f\"‚öôÔ∏è  Par√¢metros: {params}\")\n",
        "\n",
        "        # 4. Execu√ß√£o do tool\n",
        "        if intent in self.tools:\n",
        "            tool_result = self.tools[intent](params)\n",
        "            print(f\"üîß Resultado do tool: {tool_result}\")\n",
        "\n",
        "            # 5. Salvar na mem√≥ria\n",
        "            self.memory.append({\n",
        "                'timestamp': datetime.now(),\n",
        "                'input': user_input,\n",
        "                'intent': intent,\n",
        "                'result': tool_result\n",
        "            })\n",
        "\n",
        "            # 6. Resposta final\n",
        "            final_response = f\"Pronto! {tool_result}\"\n",
        "            print(f\"üéØ Resposta final: {final_response}\\n\")\n",
        "            return final_response\n",
        "\n",
        "# Testando nosso agente\n",
        "agent = AutonomousAgent()\n",
        "\n",
        "# Casos de teste\n",
        "test_cases = [\n",
        "    \"Calcular 15 * 8 + 32\",\n",
        "    \"Agendar reuni√£o com equipe de desenvolvimento\",\n",
        "    \"Como est√° o clima em S√£o Paulo?\",\n",
        "    \"Buscar informa√ß√µes sobre machine learning\",\n",
        "    \"Ol√°, como voc√™ est√°?\"\n",
        "]\n",
        "\n",
        "print(\"üöÄ Testando Agente Aut√¥nomo:\\n\")\n",
        "for test in test_cases:\n",
        "    agent.process_request(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBjex5BCY2mF"
      },
      "source": [
        "**Dica do Pedro**: Agentes aut√¥nomos s√£o como ter um assistente pessoal que nunca dorme, nunca esquece e est√° sempre aprendendo. √â o futuro da automa√ß√£o inteligente! ü§ñ‚ú®"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xTPlYxbY2mF"
      },
      "source": [
        "## ‚ö° T√©cnicas de Otimiza√ß√£o: Deixando Tudo Mais R√°pido\n",
        "\n",
        "### O Problema da Velocidade\n",
        "\n",
        "LLMs s√£o poderosos, mas... cara, como s√£o lentos √†s vezes! üêå\n",
        "\n",
        "Lembra da arquitetura Transformer que vimos no M√≥dulo 3? Ela tem algumas \"pegadinhas\" de performance:\n",
        "\n",
        "### Principais Gargalos:\n",
        "1. **Attention Quadr√°tica**: O(n¬≤) - cresce muito r√°pido!\n",
        "2. **Tamanho dos Modelos**: Bilh√µes de par√¢metros\n",
        "3. **Autoregressive Generation**: Uma palavra por vez\n",
        "4. **Memory Bandwidth**: Movimenta√ß√£o de dados\n",
        "\n",
        "![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/introduc%CC%A7a%CC%83o-a%CC%80-llms-modulo-13_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MskRNfTyY2mF"
      },
      "outputs": [],
      "source": [
        "# Comparando diferentes t√©cnicas de otimiza√ß√£o\n",
        "class OptimizationTechniques:\n",
        "    def __init__(self):\n",
        "        self.techniques = {\n",
        "            'vanilla_transformer': {'speed': 1.0, 'memory': 1.0, 'quality': 1.0},\n",
        "            'quantization_int8': {'speed': 1.8, 'memory': 0.5, 'quality': 0.98},\n",
        "            'pruning': {'speed': 2.2, 'memory': 0.3, 'quality': 0.95},\n",
        "            'distillation': {'speed': 3.5, 'memory': 0.2, 'quality': 0.92},\n",
        "            'linear_attention': {'speed': 2.8, 'memory': 0.4, 'quality': 0.96},\n",
        "            'speculative_decoding': {'speed': 4.2, 'memory': 1.2, 'quality': 1.0},\n",
        "            'flash_attention': {'speed': 2.1, 'memory': 0.6, 'quality': 1.0}\n",
        "        }\n",
        "\n",
        "    def benchmark_sequence_lengths(self):\n",
        "        \"\"\"Simula performance vs tamanho da sequ√™ncia\"\"\"\n",
        "        sequence_lengths = [128, 512, 1024, 2048, 4096, 8192]\n",
        "\n",
        "        results = {}\n",
        "        for technique, metrics in self.techniques.items():\n",
        "            times = []\n",
        "            for seq_len in sequence_lengths:\n",
        "                # Simula√ß√£o de tempo baseado na complexidade\n",
        "                if 'linear' in technique:\n",
        "                    base_time = seq_len * 0.001  # O(n)\n",
        "                else:\n",
        "                    base_time = (seq_len ** 1.8) * 0.000001  # Aproximadamente O(n¬≤)\n",
        "\n",
        "                optimized_time = base_time / metrics['speed']\n",
        "                times.append(optimized_time)\n",
        "\n",
        "            results[technique] = times\n",
        "\n",
        "        return sequence_lengths, results\n",
        "\n",
        "# Executando benchmark\n",
        "optimizer = OptimizationTechniques()\n",
        "seq_lengths, performance_results = optimizer.benchmark_sequence_lengths()\n",
        "\n",
        "# Visualizando resultados\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Performance vs Sequence Length\n",
        "colors = plt.cm.Set3(np.linspace(0, 1, len(performance_results)))\n",
        "for i, (technique, times) in enumerate(performance_results.items()):\n",
        "    if technique in ['vanilla_transformer', 'quantization_int8', 'flash_attention', 'speculative_decoding']:\n",
        "        ax1.plot(seq_lengths, times, 'o-', linewidth=2,\n",
        "                label=technique.replace('_', ' ').title(), color=colors[i])\n",
        "\n",
        "ax1.set_xlabel('Tamanho da Sequ√™ncia')\n",
        "ax1.set_ylabel('Tempo de Processamento (s)')\n",
        "ax1.set_title('Performance vs Tamanho da Sequ√™ncia')\n",
        "ax1.set_yscale('log')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Speed vs Quality Trade-off\n",
        "techniques_list = list(optimizer.techniques.keys())\n",
        "speeds = [optimizer.techniques[t]['speed'] for t in techniques_list]\n",
        "qualities = [optimizer.techniques[t]['quality'] for t in techniques_list]\n",
        "\n",
        "scatter = ax2.scatter(speeds, qualities, s=100, c=range(len(techniques_list)),\n",
        "                    cmap='viridis', alpha=0.7)\n",
        "ax2.set_xlabel('Speedup (x times faster)')\n",
        "ax2.set_ylabel('Quality Retention')\n",
        "ax2.set_title('Speed vs Quality Trade-off')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Adicionando labels\n",
        "for i, technique in enumerate(techniques_list):\n",
        "    ax2.annotate(technique.replace('_', '\\n'), (speeds[i], qualities[i]),\n",
        "                xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
        "\n",
        "# 3. Memory Usage Comparison\n",
        "memory_usage = [optimizer.techniques[t]['memory'] for t in techniques_list]\n",
        "bars = ax3.bar(range(len(techniques_list)), memory_usage,\n",
        "               color=colors[:len(techniques_list)])\n",
        "ax3.set_xlabel('T√©cnicas de Otimiza√ß√£o')\n",
        "ax3.set_ylabel('Uso de Mem√≥ria (relativo)')\n",
        "ax3.set_title('Compara√ß√£o de Uso de Mem√≥ria')\n",
        "ax3.set_xticks(range(len(techniques_list)))\n",
        "ax3.set_xticklabels([t.replace('_', '\\n') for t in techniques_list], rotation=45)\n",
        "\n",
        "# 4. Radar Chart - Compara√ß√£o Geral\n",
        "from math import pi\n",
        "\n",
        "categories = ['Speed', 'Memory Efficiency', 'Quality']\n",
        "N = len(categories)\n",
        "\n",
        "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
        "angles += angles[:1]\n",
        "\n",
        "# Comparando 3 t√©cnicas principais\n",
        "compare_techniques = ['vanilla_transformer', 'quantization_int8', 'speculative_decoding']\n",
        "colors_radar = ['red', 'blue', 'green']\n",
        "\n",
        "for i, technique in enumerate(compare_techniques):\n",
        "    metrics = optimizer.techniques[technique]\n",
        "    values = [metrics['speed'], 1/metrics['memory'], metrics['quality']]\n",
        "    values += values[:1]\n",
        "\n",
        "    ax4.plot(angles, values, 'o-', linewidth=2, label=technique.replace('_', ' ').title(),\n",
        "             color=colors_radar[i])\n",
        "    ax4.fill(angles, values, alpha=0.25, color=colors_radar[i])\n",
        "\n",
        "ax4.set_xticks(angles[:-1])\n",
        "ax4.set_xticklabels(categories)\n",
        "ax4.set_title('Compara√ß√£o Multidimensional')\n",
        "ax4.legend()\n",
        "ax4.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üéØ Principais Insights de Otimiza√ß√£o:\")\n",
        "print(\"‚Ä¢ Speculative Decoding: Melhor speedup mantendo qualidade\")\n",
        "print(\"‚Ä¢ Quantization: Boa redu√ß√£o de mem√≥ria com pouca perda\")\n",
        "print(\"‚Ä¢ Flash Attention: Otimiza√ß√£o 'gratuita' sem perda de qualidade\")\n",
        "print(\"‚Ä¢ Trade-off sempre existe: speed vs quality vs memory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MmC2cmSY2mF"
      },
      "source": [
        "### T√©cnicas de Otimiza√ß√£o Detalhadas\n",
        "\n",
        "**1. Quantization (Quantiza√ß√£o)**\n",
        "- Reduz precis√£o: FP32 ‚Üí INT8 ‚Üí INT4\n",
        "- Economiza 4-8x mem√≥ria\n",
        "- Speedup significativo\n",
        "\n",
        "**2. Pruning (Poda)**\n",
        "- Remove conex√µes \"desnecess√°rias\"\n",
        "- Modelo esparso (sparse)\n",
        "- Mant√©m performance com menos par√¢metros\n",
        "\n",
        "**3. Distillation (Destila√ß√£o)**\n",
        "- Professor (modelo grande) ‚Üí Aluno (modelo pequeno)\n",
        "- Transfere conhecimento\n",
        "- Modelo final muito mais r√°pido\n",
        "\n",
        "**Dica do Pedro**: √â como fazer um carro de F√≥rmula 1 - voc√™ otimiza cada componente para extrair m√°xima performance! üèéÔ∏è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T69yWGUbY2mG"
      },
      "source": [
        "## üîÆ O Futuro dos LLMs: O Que Vem Por A√≠\n",
        "\n",
        "### Tend√™ncias para os Pr√≥ximos Anos\n",
        "\n",
        "Baseado em tudo que aprendemos neste curso, vamos dar uma espiada no que o futuro reserva:\n",
        "\n",
        "![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/introduc%CC%A7a%CC%83o-a%CC%80-llms-modulo-13_img_04.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUzLtAgpY2mG"
      },
      "outputs": [],
      "source": [
        "# Proje√ß√µes para o futuro dos LLMs\n",
        "import pandas as pd\n",
        "\n",
        "# Dados das tend√™ncias futuras\n",
        "future_trends = {\n",
        "    'Ano': [2024, 2025, 2026, 2027, 2028, 2029, 2030],\n",
        "    'Par√¢metros (Trilh√µes)': [1.8, 5.0, 15.0, 50.0, 100.0, 200.0, 500.0],\n",
        "    'Efici√™ncia Energ√©tica (x)': [1.0, 2.5, 6.0, 15.0, 40.0, 80.0, 150.0],\n",
        "    'Modalidades Suportadas': [4, 6, 8, 12, 16, 20, 25],\n",
        "    'Lat√™ncia (ms)': [500, 300, 150, 75, 40, 20, 10],\n",
        "    'Custo por Token ($/M)': [20, 12, 6, 3, 1.5, 0.8, 0.4]\n",
        "}\n",
        "\n",
        "df_future = pd.DataFrame(future_trends)\n",
        "\n",
        "# Visualizando as tend√™ncias\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "metrics = [\n",
        "    ('Par√¢metros (Trilh√µes)', 'Evolu√ß√£o do Tamanho dos Modelos', 'green'),\n",
        "    ('Efici√™ncia Energ√©tica (x)', 'Melhoria na Efici√™ncia Energ√©tica', 'blue'),\n",
        "    ('Modalidades Suportadas', 'Expans√£o Multimodal', 'orange'),\n",
        "    ('Lat√™ncia (ms)', 'Redu√ß√£o da Lat√™ncia', 'red'),\n",
        "    ('Custo por Token ($/M)', 'Democratiza√ß√£o dos Custos', 'purple')\n",
        "]\n",
        "\n",
        "for i, (metric, title, color) in enumerate(metrics):\n",
        "    axes[i].plot(df_future['Ano'], df_future[metric], 'o-',\n",
        "                linewidth=3, markersize=8, color=color)\n",
        "    axes[i].set_title(title, fontsize=12, fontweight='bold')\n",
        "    axes[i].set_xlabel('Ano')\n",
        "    axes[i].set_ylabel(metric)\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "    # Destacando valores espec√≠ficos\n",
        "    for j, (year, value) in enumerate(zip(df_future['Ano'], df_future[metric])):\n",
        "        if j % 2 == 0:  # A cada 2 anos\n",
        "            axes[i].annotate(f'{value}', (year, value),\n",
        "                           xytext=(0, 10), textcoords='offset points',\n",
        "                           ha='center', fontweight='bold')\n",
        "\n",
        "# Gr√°fico combinado na √∫ltima posi√ß√£o\n",
        "ax_combined = axes[5]\n",
        "\n",
        "# Normalizando m√©tricas para compara√ß√£o\n",
        "normalized_data = {\n",
        "    'Par√¢metros': df_future['Par√¢metros (Trilh√µes)'] / df_future['Par√¢metros (Trilh√µes)'].iloc[0],\n",
        "    'Efici√™ncia': df_future['Efici√™ncia Energ√©tica (x)'],\n",
        "    'Modalidades': df_future['Modalidades Suportadas'] / df_future['Modalidades Suportadas'].iloc[0]\n",
        "}\n",
        "\n",
        "for metric, data in normalized_data.items():\n",
        "    ax_combined.plot(df_future['Ano'], data, 'o-', linewidth=2,\n",
        "                    markersize=6, label=metric)\n",
        "\n",
        "ax_combined.set_title('Crescimento Comparativo (Normalizado)', fontsize=12, fontweight='bold')\n",
        "ax_combined.set_xlabel('Ano')\n",
        "ax_combined.set_ylabel('Crescimento Relativo (x vezes)')\n",
        "ax_combined.legend()\n",
        "ax_combined.grid(True, alpha=0.3)\n",
        "ax_combined.set_yscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üîÆ PREVIS√ïES PARA O FUTURO DOS LLMs:\\n\")\n",
        "print(\"üìä Crescimento Exponencial:\")\n",
        "print(f\"‚Ä¢ 2024‚Üí2030: {df_future['Par√¢metros (Trilh√µes)'].iloc[-1]/df_future['Par√¢metros (Trilh√µes)'].iloc[0]:.0f}x mais par√¢metros\")\n",
        "print(f\"‚Ä¢ Efici√™ncia: {df_future['Efici√™ncia Energ√©tica (x)'].iloc[-1]:.0f}x mais eficiente\")\n",
        "print(f\"‚Ä¢ Lat√™ncia: {df_future['Lat√™ncia (ms)'].iloc[0]/df_future['Lat√™ncia (ms)'].iloc[-1]:.0f}x mais r√°pido\")\n",
        "print(f\"‚Ä¢ Custo: {df_future['Custo por Token ($/M)'].iloc[0]/df_future['Custo por Token ($/M)'].iloc[-1]:.0f}x mais barato\")\n",
        "\n",
        "print(\"\\nüöÄ Marcos Importantes:\")\n",
        "print(\"‚Ä¢ 2025: Primeiros modelos verdadeiramente multimodais\")\n",
        "print(\"‚Ä¢ 2026: LLMs com racioc√≠nio cient√≠fico avan√ßado\")\n",
        "print(\"‚Ä¢ 2027: Agentes aut√¥nomos em massa\")\n",
        "print(\"‚Ä¢ 2028: Modelos auto-melhorantes\")\n",
        "print(\"‚Ä¢ 2030: IA Geral Artificial? ü§î\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwxb4XlWY2mG"
      },
      "source": [
        "### Tecnologias Emergentes\n",
        "\n",
        "**1. Neuromorphic Computing** üß†\n",
        "- Hardware que imita o c√©rebro\n",
        "- Efici√™ncia energ√©tica extrema\n",
        "- Processamento em tempo real\n",
        "\n",
        "**2. Quantum-Enhanced LLMs** ‚öõÔ∏è\n",
        "- Computa√ß√£o qu√¢ntica para attention\n",
        "- Speedup exponencial em problemas espec√≠ficos\n",
        "- Nova classe de algoritmos\n",
        "\n",
        "**3. Continual Learning** üìö\n",
        "- Modelos que aprendem continuamente\n",
        "- Sem \"esquecer\" conhecimento anterior\n",
        "- Adapta√ß√£o em tempo real\n",
        "\n",
        "**4. Causal Reasoning** üîó\n",
        "- Entendimento de causa e efeito\n",
        "- Racioc√≠nio cient√≠fico avan√ßado\n",
        "- Previs√µes mais confi√°veis\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kalu9vJY2mG"
      },
      "source": [
        "## üéØ Exerc√≠cio Pr√°tico: Monte seu LLM do Futuro!\n",
        "\n",
        "Agora √© sua vez! Vamos projetar um LLM futur√≠stico com tudo que aprendemos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9so-NWRnY2mG"
      },
      "outputs": [],
      "source": [
        "# EXERC√çCIO 1: Design de LLM Futur√≠stico\n",
        "class FutureLLMDesigner:\n",
        "    def __init__(self):\n",
        "        self.design_choices = {\n",
        "            'arquitetura': ['Transformer', 'Mamba', 'Hybrid', 'Quantum-Enhanced'],\n",
        "            'modalidades': ['Texto', 'Imagem', 'Audio', 'Video', '3D', 'Sensores'],\n",
        "            'otimizacoes': ['Quantization', 'Pruning', 'Distillation', 'Flash-Attention'],\n",
        "            'capabilities': ['RAG', 'Agentes', 'Reasoning', 'Continual-Learning']\n",
        "        }\n",
        "\n",
        "        self.design_metrics = {\n",
        "            'performance_score': 0,\n",
        "            'efficiency_score': 0,\n",
        "            'innovation_score': 0,\n",
        "            'total_score': 0\n",
        "        }\n",
        "\n",
        "    def calculate_design_score(self, user_design):\n",
        "        \"\"\"Calcula score baseado nas escolhas do usu√°rio\"\"\"\n",
        "\n",
        "        # Pontua√ß√£o por arquitetura\n",
        "        arch_scores = {\n",
        "            'Transformer': 7, 'Mamba': 8, 'Hybrid': 9, 'Quantum-Enhanced': 10\n",
        "        }\n",
        "\n",
        "        # Pontua√ß√£o por modalidades (mais = melhor, mas com diminishing returns)\n",
        "        modal_score = min(len(user_design.get('modalidades', [])) * 2, 10)\n",
        "\n",
        "        # Pontua√ß√£o por otimiza√ß√µes\n",
        "        optim_score = len(user_design.get('otimizacoes', [])) * 1.5\n",
        "\n",
        "        # Pontua√ß√£o por capabilities\n",
        "        cap_score = len(user_design.get('capabilities', [])) * 2\n",
        "\n",
        "        # Calculando scores\n",
        "        performance = arch_scores.get(user_design.get('arquitetura', 'Transformer'), 7) + modal_score\n",
        "        efficiency = optim_score * 2\n",
        "        innovation = cap_score + (1 if user_design.get('arquitetura') == 'Quantum-Enhanced' else 0)\n",
        "\n",
        "        total = (performance + efficiency + innovation) / 3\n",
        "\n",
        "        return {\n",
        "            'performance_score': round(performance, 1),\n",
        "            'efficiency_score': round(efficiency, 1),\n",
        "            'innovation_score': round(innovation, 1),\n",
        "            'total_score': round(total, 1)\n",
        "        }\n",
        "\n",
        "    def generate_feedback(self, design, scores):\n",
        "        \"\"\"Gera feedback personalizado\"\"\"\n",
        "        feedback = [\"\\nüéØ FEEDBACK DO SEU DESIGN:\\n\"]\n",
        "\n",
        "        if scores['total_score'] >= 15:\n",
        "            feedback.append(\"üöÄ INCR√çVEL! Seu LLM est√° no n√≠vel 'Futuro Chegou!'\")\n",
        "        elif scores['total_score'] >= 12:\n",
        "            feedback.append(\"‚≠ê MUITO BOM! Design s√≥lido e inovador!\")\n",
        "        elif scores['total_score'] >= 9:\n",
        "            feedback.append(\"üëç BOM! Com algumas melhorias, vai ficar perfeito!\")\n",
        "        else:\n",
        "            feedback.append(\"üí° POTENCIAL! Que tal explorar mais op√ß√µes?\")\n",
        "\n",
        "        # Feedback espec√≠fico por √°rea\n",
        "        if scores['performance_score'] < 10:\n",
        "            feedback.append(\"‚Ä¢ Performance: Considere arquitetura mais avan√ßada ou mais modalidades\")\n",
        "\n",
        "        if scores['efficiency_score'] < 8:\n",
        "            feedback.append(\"‚Ä¢ Efici√™ncia: Adicione mais t√©cnicas de otimiza√ß√£o\")\n",
        "\n",
        "        if scores['innovation_score'] < 6:\n",
        "            feedback.append(\"‚Ä¢ Inova√ß√£o: Explore capabilities mais avan√ßadas\")\n",
        "\n",
        "        return \"\\n\".join(feedback)\n",
        "\n",
        "# Seu turno! Fa√ßa seu design\n",
        "designer = FutureLLMDesigner()\n",
        "\n",
        "print(\"üé® DESIGN SEU LLM DO FUTURO!\\n\")\n",
        "print(\"Op√ß√µes dispon√≠veis:\")\n",
        "for category, options in designer.design_choices.items():\n",
        "    print(f\"‚Ä¢ {category.upper()}: {', '.join(options)}\")\n",
        "\n",
        "# Exemplo de design (voc√™ pode modificar!)\n",
        "meu_design = {\n",
        "    'arquitetura': 'Hybrid',  # Mude aqui!\n",
        "    'modalidades': ['Texto', 'Imagem', 'Audio', '3D'],  # Adicione/remova modalidades!\n",
        "    'otimizacoes': ['Quantization', 'Flash-Attention'],  # Escolha suas otimiza√ß√µes!\n",
        "    'capabilities': ['RAG', 'Agentes', 'Reasoning']  # Que superpoderes seu LLM ter√°?\n",
        "}\n",
        "\n",
        "print(\"\\nüîß SEU DESIGN ATUAL:\")\n",
        "for key, value in meu_design.items():\n",
        "    print(f\"‚Ä¢ {key.upper()}: {value}\")\n",
        "\n",
        "# Calculando e mostrando resultados\n",
        "scores = designer.calculate_design_score(meu_design)\n",
        "feedback = designer.generate_feedback(meu_design, scores)\n",
        "\n",
        "print(\"\\nüìä SCORES DO SEU LLM:\")\n",
        "for metric, score in scores.items():\n",
        "    print(f\"‚Ä¢ {metric.replace('_', ' ').title()}: {score}/20\")\n",
        "\n",
        "print(feedback)\n",
        "\n",
        "print(\"\\nüí° DESAFIO: Modifique o 'meu_design' acima e rode novamente para melhorar seus scores!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L90iKW_Y2mG"
      },
      "source": [
        "## üéì Exerc√≠cio Final: Jornada Completa\n",
        "\n",
        "Vamos revisar tudo que aprendemos neste curso inteiro!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm5NGQwmY2mG"
      },
      "outputs": [],
      "source": [
        "# EXERC√çCIO 2: Quiz Final - Jornada Completa do Curso\n",
        "class CourseJourneyQuiz:\n",
        "    def __init__(self):\n",
        "        self.modules_knowledge = {\n",
        "            'M√≥dulo 2 - LLMs Basics': {\n",
        "                'question': \"Qual a principal caracter√≠stica dos LLMs?\",\n",
        "                'answer': \"Predizer pr√≥xima palavra baseado em contexto\"\n",
        "            },\n",
        "            'M√≥dulo 3 - Transformer': {\n",
        "                'question': \"Qual o mecanismo fundamental do Transformer?\",\n",
        "                'answer': \"Attention mechanism\"\n",
        "            },\n",
        "            'M√≥dulo 4 - Tokens': {\n",
        "                'question': \"Como o texto √© processado pelos LLMs?\",\n",
        "                'answer': \"Dividido em tokens menores\"\n",
        "            },\n",
        "            'M√≥dulo 5 - Embeddings': {\n",
        "                'question': \"Como palavras viram n√∫meros?\",\n",
        "                'answer': \"Atrav√©s de embeddings vetoriais\"\n",
        "            },\n",
        "            'M√≥dulo 8 - Prompting': {\n",
        "                'question': \"Qual t√©cnica melhora respostas sem treinar?\",\n",
        "                'answer': \"Engenharia de prompts\"\n",
        "            },\n",
        "            'M√≥dulo 9 - Avalia√ß√£o': {\n",
        "                'question': \"Como medimos qualidade de LLMs?\",\n",
        "                'answer': \"M√©tricas como BLEU, ROUGE, avalia√ß√£o humana\"\n",
        "            },\n",
        "            'M√≥dulo 13 - Avan√ßados': {\n",
        "                'question': \"Qual t√©cnica d√° conhecimento atualizado aos LLMs?\",\n",
        "                'answer': \"RAG - Retrieval Augmented Generation\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.journey_milestones = [\n",
        "            \"üöÄ Descobriu o que s√£o LLMs\",\n",
        "            \"üß† Entendeu a arquitetura Transformer\",\n",
        "            \"üî§ Dominou tokens e tokeniza√ß√£o\",\n",
        "            \"üìä Compreendeu embeddings\",\n",
        "            \"üéØ Aprendeu prompting avan√ßado\",\n",
        "            \"üìè Sabe avaliar modelos\",\n",
        "            \"üîÆ Explorou o futuro dos LLMs\"\n",
        "        ]\n",
        "\n",
        "    def generate_certificate(self, student_name=\"Estudante\"):\n",
        "        \"\"\"Gera certificado de conclus√£o\"\"\"\n",
        "        certificate = f\"\"\"\n",
        "    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    ‚ïë                    üéì CERTIFICADO DE CONCLUS√ÉO üéì            ‚ïë\n",
        "    ‚ïë                                                              ‚ïë\n",
        "    ‚ïë        Curso: Introdu√ß√£o √† LLMs - T√≥picos Avan√ßados         ‚ïë\n",
        "    ‚ïë                                                              ‚ïë\n",
        "    ‚ïë                Estudante: {student_name:^30}                ‚ïë\n",
        "    ‚ïë                                                              ‚ïë\n",
        "    ‚ïë    Concluiu com sucesso todos os 13 m√≥dulos do curso,        ‚ïë\n",
        "    ‚ïë    demonstrando conhecimento em:                             ‚ïë\n",
        "    ‚ïë                                                              ‚ïë\n",
        "    ‚ïë    ‚úÖ Fundamentos de Large Language Models                   ‚ïë\n",
        "    ‚ïë    ‚úÖ Arquitetura Transformer & Attention                    ‚ïë\n",
        "    ‚ïë    ‚úÖ Tokeniza√ß√£o e Embeddings                               ‚ïë\n",
        "    ‚ïë    ‚úÖ Engenharia de Prompts                                  ‚ïë\n",
        "    ‚ïë    ‚úÖ Avalia√ß√£o de Modelos                                   ‚ïë\n",
        "    ‚ïë    ‚úÖ RAG e Multimodalidade                                  ‚ïë\n",
        "    ‚ïë    ‚úÖ Agentes Aut√¥nomos                                      ‚ïë\n",
        "    ‚ïë    ‚úÖ Otimiza√ß√£o e Futuro dos LLMs                          ‚ïë\n",
        "    ‚ïë                                                              ‚ïë\n",
        "    ‚ïë            Instrutor: Pedro Nunes Guth                      ‚ïë\n",
        "    ‚ïë            Data: {datetime.now().strftime('%d/%m/%Y'):^34}              ‚ïë\n",
        "    ‚ïë                                                              ‚ïë\n",
        "    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "        \"\"\"\n",
        "        return certificate\n",
        "\n",
        "    def show_journey_summary(self):\n",
        "        \"\"\"Mostra resumo da jornada\"\"\"\n",
        "        print(\"üéØ SUA JORNADA PELOS LLMs - RESUMO COMPLETO:\\n\")\n",
        "\n",
        "        for i, milestone in enumerate(self.journey_milestones, 1):\n",
        "            print(f\"M√≥dulo {i}: {milestone}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üèÜ PARAB√âNS! Voc√™ agora √© um Expert em LLMs!\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return True\n",
        "\n",
        "# Executando o quiz final\n",
        "quiz = CourseJourneyQuiz()\n",
        "\n",
        "# Mostrando jornada completa\n",
        "quiz.show_journey_summary()\n",
        "\n",
        "# Gerando certificado\n",
        "certificate = quiz.generate_certificate(\"Future AI Expert\")  # Coloque seu nome aqui!\n",
        "print(certificate)\n",
        "\n",
        "print(\"\\nüöÄ O QUE VOC√ä PODE FAZER AGORA:\")\n",
        "print(\"‚Ä¢ Implementar sistemas RAG em produ√ß√£o\")\n",
        "print(\"‚Ä¢ Criar agentes aut√¥nomos inteligentes\")\n",
        "print(\"‚Ä¢ Otimizar LLMs para performance\")\n",
        "print(\"‚Ä¢ Avaliar e comparar diferentes modelos\")\n",
        "print(\"‚Ä¢ Estar preparado para as pr√≥ximas inova√ß√µes\")\n",
        "\n",
        "print(\"\\nüí° PR√ìXIMOS PASSOS SUGERIDOS:\")\n",
        "print(\"‚Ä¢ Implemente um projeto real usando RAG\")\n",
        "print(\"‚Ä¢ Experimente com modelos multimodais\")\n",
        "print(\"‚Ä¢ Contribua para projetos open-source\")\n",
        "print(\"‚Ä¢ Continue aprendendo - o campo evolui rapidamente!\")\n",
        "\n",
        "print(\"\\nüéâ LIIIIINDO! Voc√™ chegou ao fim da jornada! üéâ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovfqFF3IY2mG"
      },
      "source": [
        "## üéä Conclus√£o: O Fim √© S√≥ o Come√ßo!\n",
        "\n",
        "### Recapitulando Nossa Jornada √âpica\n",
        "\n",
        "Cara, que viagem foi essa! üöÄ\n",
        "\n",
        "Come√ßamos l√° no **M√≥dulo 1** configurando ambiente, passamos pela teoria fundamental nos **M√≥dulos 2-5**, mergulhamos na pr√°tica nos **M√≥dulos 6-9**, exploramos seguran√ßa e limita√ß√µes nos **M√≥dulos 10-11**, fizemos um projeto completo no **M√≥dulo 12**, e agora terminamos explorando o futuro!\n",
        "\n",
        "### Principais Aprendizados Deste M√≥dulo:\n",
        "\n",
        "‚úÖ **RAG**: Como dar \"superpoderes\" de conhecimento atualizado aos LLMs\n",
        "\n",
        "‚úÖ **Multimodalidade**: LLMs que \"veem\", \"ouvem\" e processam m√∫ltiplas modalidades\n",
        "\n",
        "‚úÖ **Agentes Aut√¥nomos**: IA que age no mundo real, n√£o s√≥ conversa\n",
        "\n",
        "‚úÖ **Otimiza√ß√£o**: T√©cnicas para deixar tudo mais r√°pido e eficiente\n",
        "\n",
        "‚úÖ **Futuro**: Tend√™ncias e tecnologias emergentes\n",
        "\n",
        "### Dica Final do Pedro:\n",
        "\n",
        "O campo de LLMs evolui na velocidade da luz! üåü O que aprendemos hoje √© a base s√≥lida, mas mantenha-se sempre curioso e continue aprendendo.\n",
        "\n",
        "**Lembre-se**: Voc√™ agora tem todas as ferramentas para entender, avaliar e implementar qualquer nova tecnologia que apare√ßa no mundo dos LLMs!\n",
        "\n",
        "![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/introduc%CC%A7a%CC%83o-a%CC%80-llms-modulo-13_img_06.png)\n",
        "\n",
        "---\n",
        "\n",
        "### üöÄ Continue a Jornada:\n",
        "\n",
        "- **GitHub**: Contribua para projetos open-source\n",
        "- **Papers**: Leia os √∫ltimos papers em arXiv\n",
        "- **Comunidade**: Participe de discuss√µes e eventos\n",
        "- **Pr√°tica**: Implemente projetos reais\n",
        "\n",
        "**Bora mudar o mundo com IA! üåç‚ú®**"
      ]
    }
  ]
}