{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸš€ LLMs do Futuro: Explorando o ImpossÃ­vel (Que JÃ¡ EstÃ¡ Acontecendo!)\n\n**MÃ³dulo 13 - TÃ³picos AvanÃ§ados | Curso IntroduÃ§Ã£o Ã  LLMs**\n\n---\n\nE aÃ­, pessoal! ğŸ¯ Chegamos ao nosso Ãºltimo mÃ³dulo e, cara, que jornada foi essa!\n\nLembra quando comeÃ§amos falando sobre tokens no MÃ³dulo 4? Ou quando desvendamos os mistÃ©rios do Transformer no MÃ³dulo 3? Agora vamos ver o que vem por aÃ­ no mundo dos LLMs!\n\nBora explorar as tecnologias que vÃ£o revolucionar ainda mais esse universo nos prÃ³ximos anos!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ O Que Vamos Aprender\n\nNeste mÃ³dulo final, vamos mergulhar nos tÃ³picos mais avanÃ§ados:\n\n- **Retrieval Augmented Generation (RAG)**: Como dar \"superpoderes\" aos LLMs\n- **Multimodalidade**: LLMs que \"veem\" e \"ouvem\"\n- **Agentes AutÃ´nomos**: IA que age no mundo real\n- **TÃ©cnicas de OtimizaÃ§Ã£o**: Como deixar tudo mais rÃ¡pido\n- **O Futuro dos LLMs**: O que vem por aÃ­\n\n**Dica do Pedro**: Este mÃ³dulo Ã© como o \"pÃ³s-crÃ©ditos\" de um filme da Marvel - aqui vocÃª vai ver o que estÃ¡ vindo por aÃ­! ğŸ¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup inicial - importando as bibliotecas para nossa jornada avanÃ§ada\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ConfiguraÃ§Ã£o dos grÃ¡ficos\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"ğŸš€ Ambiente configurado! Bora para os tÃ³picos avanÃ§ados!\")\n",
        "print(f\"ğŸ“… Data de inÃ­cio da aventura: {datetime.now().strftime('%d/%m/%Y %H:%M')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ” RAG (Retrieval Augmented Generation)\n\n### O Que Ã© RAG? Ã‰ Como Dar um Google Pro ao seu LLM!\n\nTÃ¡, mas o que Ã© RAG? Imagine que vocÃª tem um amigo superinteligente (o LLM), mas que sÃ³ sabe das coisas atÃ© 2021. DaÃ­ vocÃª dÃ¡ um celular pra ele (o sistema de retrieval) para ele pesquisar informaÃ§Ãµes atuais antes de responder.\n\n**Ã‰ isso que o RAG faz!**\n\n### Como Funciona?\n\n1. **Pergunta chega**: \"Qual foi o Ãºltimo lanÃ§amento da Tesla?\"\n2. **Sistema busca**: Vai em uma base de dados atualizada\n3. **Encontra informaÃ§Ã£o**: Dados recentes sobre Tesla\n4. **LLM responde**: Usando tanto seu conhecimento quanto a info nova\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introduÃ§Ã£o-Ã -llms-modulo-13_img_01.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulando um sistema RAG simples\n",
        "class SimpleRAG:\n",
        "    def __init__(self):\n",
        "        # Base de conhecimento simulada (seria um vetor database na vida real)\n",
        "        self.knowledge_base = {\n",
        "            \"python\": \"Python Ã© uma linguagem de programaÃ§Ã£o de alto nÃ­vel, lanÃ§ada em 1991\",\n",
        "            \"machine learning\": \"ML Ã© um subcampo da IA que permite sistemas aprenderem automaticamente\",\n",
        "            \"transformer\": \"Arquitetura revolucionÃ¡ria apresentada no paper 'Attention is All You Need'\",\n",
        "            \"tokens\": \"Unidades bÃ¡sicas de texto processadas pelos modelos de linguagem\"\n",
        "        }\n",
        "    \n",
        "    def retrieve(self, query):\n",
        "        \"\"\"Simula a busca por informaÃ§Ã£o relevante\"\"\"\n",
        "        query_lower = query.lower()\n",
        "        \n",
        "        # Busca simples por palavras-chave\n",
        "        for key, value in self.knowledge_base.items():\n",
        "            if key in query_lower:\n",
        "                return value\n",
        "        \n",
        "        return \"InformaÃ§Ã£o nÃ£o encontrada na base de conhecimento\"\n",
        "    \n",
        "    def generate_response(self, query, retrieved_info):\n",
        "        \"\"\"Simula a geraÃ§Ã£o de resposta do LLM\"\"\"\n",
        "        if \"nÃ£o encontrada\" in retrieved_info:\n",
        "            return f\"Desculpe, nÃ£o tenho informaÃ§Ãµes especÃ­ficas sobre: {query}\"\n",
        "        \n",
        "        return f\"Com base nas informaÃ§Ãµes mais recentes: {retrieved_info}. Isso responde sua pergunta sobre {query}.\"\n",
        "    \n",
        "    def ask(self, query):\n",
        "        \"\"\"Pipeline completo RAG\"\"\"\n",
        "        print(f\"ğŸ” Pergunta: {query}\")\n",
        "        \n",
        "        # Passo 1: Retrieval\n",
        "        retrieved = self.retrieve(query)\n",
        "        print(f\"ğŸ“š InformaÃ§Ã£o encontrada: {retrieved}\")\n",
        "        \n",
        "        # Passo 2: Generation\n",
        "        response = self.generate_response(query, retrieved)\n",
        "        print(f\"ğŸ¤– Resposta final: {response}\\n\")\n",
        "        \n",
        "        return response\n",
        "\n",
        "# Testando nosso RAG\n",
        "rag_system = SimpleRAG()\n",
        "\n",
        "# Perguntas de teste\n",
        "perguntas = [\n",
        "    \"O que Ã© Python?\",\n",
        "    \"Explique machine learning\",\n",
        "    \"Como funcionam os tokens?\"\n",
        "]\n",
        "\n",
        "print(\"ğŸ¯ Testando nosso sistema RAG simples:\\n\")\n",
        "for pergunta in perguntas:\n",
        "    rag_system.ask(pergunta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Arquitetura RAG em Detalhes\n\nVamos visualizar como funciona um sistema RAG completo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando o pipeline RAG\n",
        "fig, ax = plt.subplots(figsize=(14, 10))\n",
        "\n",
        "# Dados para o fluxo RAG\n",
        "steps = ['Query\\nUsuÃ¡rio', 'Embedding\\nQuery', 'Busca\\nVetorial', 'Retrieval\\nDocumentos', \n",
        "         'Context\\nAugmentation', 'LLM\\nGeneration', 'Resposta\\nFinal']\n",
        "times = [0, 50, 200, 300, 350, 800, 900]  # Tempos simulados em ms\n",
        "complexities = [1, 3, 5, 4, 6, 9, 8]  # Complexidade computacional\n",
        "\n",
        "# GrÃ¡fico de linha para tempo\n",
        "ax2 = ax.twinx()\n",
        "line1 = ax.plot(steps, times, 'bo-', linewidth=3, markersize=8, label='Tempo (ms)')\n",
        "line2 = ax2.plot(steps, complexities, 'ro-', linewidth=3, markersize=8, label='Complexidade')\n",
        "\n",
        "# ConfiguraÃ§Ã£o dos eixos\n",
        "ax.set_xlabel('Etapas do Pipeline RAG', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('Tempo (ms)', fontsize=14, fontweight='bold', color='blue')\n",
        "ax2.set_ylabel('Complexidade Computacional', fontsize=14, fontweight='bold', color='red')\n",
        "\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.tick_params(axis='y', labelcolor='blue')\n",
        "ax2.tick_params(axis='y', labelcolor='red')\n",
        "\n",
        "# TÃ­tulo e grid\n",
        "ax.set_title('Pipeline RAG: Tempo vs Complexidade por Etapa', fontsize=16, fontweight='bold', pad=20)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Legenda\n",
        "lines1, labels1 = ax.get_legend_handles_labels()\n",
        "lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "ax.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ“Š ObservaÃ§Ãµes importantes:\")\n",
        "print(\"â€¢ A geraÃ§Ã£o pelo LLM Ã© o passo mais demorado\")\n",
        "print(\"â€¢ A busca vetorial Ã© super rÃ¡pida mas complexa\")\n",
        "print(\"â€¢ O context augmentation Ã© crucial para qualidade\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Dica do Pedro**: RAG Ã© como ter uma biblioteca infinita + um bibliotecÃ¡rio super inteligente. O bibliotecÃ¡rio (LLM) nÃ£o precisa decorar todos os livros, sÃ³ precisa saber onde encontrar a informaÃ§Ã£o! ğŸ“š"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ‘ï¸ Multimodalidade: LLMs que Veem, Ouvem e Sentem\n\n### AlÃ©m do Texto: A RevoluÃ§Ã£o Sensorial dos LLMs\n\nLembra quando falamos sobre tokens no MÃ³dulo 4? Pois Ã©, agora os \"tokens\" podem ser:\n- **Pixels de imagem** ğŸ–¼ï¸\n- **FrequÃªncias de Ã¡udio** ğŸµ  \n- **Coordenadas 3D** ğŸ®\n- **Sinais de vÃ­deo** ğŸ¬\n\nÃ‰ como se o LLM ganhasse olhos, ouvidos e tato!\n\n### Tipos de Modalidades\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introduÃ§Ã£o-Ã -llms-modulo-13_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulando processamento multimodal\n",
        "class MultimodalProcessor:\n",
        "    def __init__(self):\n",
        "        self.modalities = {\n",
        "            'texto': {'dimensao': 768, 'tipo': 'sequencial'},\n",
        "            'imagem': {'dimensao': 2048, 'tipo': 'espacial'},\n",
        "            'audio': {'dimensao': 1024, 'tipo': 'temporal'},\n",
        "            'video': {'dimensao': 3072, 'tipo': 'espaco-temporal'}\n",
        "        }\n",
        "    \n",
        "    def process_modality(self, modality_type, input_size):\n",
        "        \"\"\"Simula o processamento de diferentes modalidades\"\"\"\n",
        "        config = self.modalities[modality_type]\n",
        "        \n",
        "        # SimulaÃ§Ã£o de embedding para cada modalidade\n",
        "        embedding_dim = config['dimensao']\n",
        "        processing_type = config['tipo']\n",
        "        \n",
        "        # Tempo de processamento varia por modalidade\n",
        "        processing_times = {\n",
        "            'texto': input_size * 0.1,\n",
        "            'imagem': input_size * 0.5,\n",
        "            'audio': input_size * 0.3,\n",
        "            'video': input_size * 1.0\n",
        "        }\n",
        "        \n",
        "        return {\n",
        "            'embedding_dim': embedding_dim,\n",
        "            'processing_type': processing_type,\n",
        "            'processing_time': processing_times[modality_type],\n",
        "            'output_tokens': input_size // 4  # CompressÃ£o simulada\n",
        "        }\n",
        "    \n",
        "    def fuse_modalities(self, modalities_data):\n",
        "        \"\"\"Simula a fusÃ£o de mÃºltiplas modalidades\"\"\"\n",
        "        total_tokens = sum(data['output_tokens'] for data in modalities_data.values())\n",
        "        total_time = sum(data['processing_time'] for data in modalities_data.values())\n",
        "        \n",
        "        return {\n",
        "            'total_tokens': total_tokens,\n",
        "            'total_processing_time': total_time,\n",
        "            'fusion_complexity': len(modalities_data) ** 2\n",
        "        }\n\n",
        "# Testando processamento multimodal\n",
        "processor = MultimodalProcessor()\n\n",
        "# Simulando diferentes inputs\n",
        "inputs = {\n",
        "    'texto': 100,      # 100 tokens de texto\n",
        "    'imagem': 1000,    # 1000 pixels processados\n",
        "    'audio': 500,      # 500 samples de Ã¡udio\n",
        "    'video': 2000      # 2000 frames de vÃ­deo\n",
        "}\n\n",
        "print(\"ğŸ¯ Processamento Multimodal em AÃ§Ã£o!\\n\")\n\n",
        "results = {}\n",
        "for modality, input_size in inputs.items():\n",
        "    result = processor.process_modality(modality, input_size)\n",
        "    results[modality] = result\n",
        "    \n",
        "    print(f\"ğŸ“Š {modality.upper()}:\")\n",
        "    print(f\"   â€¢ DimensÃ£o embedding: {result['embedding_dim']}\")\n",
        "    print(f\"   â€¢ Tipo processamento: {result['processing_type']}\")\n",
        "    print(f\"   â€¢ Tempo: {result['processing_time']:.2f}ms\")\n",
        "    print(f\"   â€¢ Tokens output: {result['output_tokens']}\\n\")\n\n",
        "# FusÃ£o multimodal\n",
        "fusion_result = processor.fuse_modalities(results)\n",
        "print(\"ğŸ”¥ FUSÃƒO MULTIMODAL:\")\n",
        "print(f\"   â€¢ Total de tokens: {fusion_result['total_tokens']}\")\n",
        "print(f\"   â€¢ Tempo total: {fusion_result['total_processing_time']:.2f}ms\")\n",
        "print(f\"   â€¢ Complexidade fusÃ£o: {fusion_result['fusion_complexity']}x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Arquitetura de Attention Multimodal\n\nLembra do mecanismo de attention que vimos no MÃ³dulo 3? Agora ele precisa funcionar entre diferentes modalidades!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando attention multimodal\n",
        "def create_multimodal_attention_matrix():\n",
        "    # Simulando matriz de attention entre modalidades\n",
        "    modalities = ['Texto', 'Imagem', 'Ãudio', 'VÃ­deo']\n",
        "    n_mod = len(modalities)\n",
        "    \n",
        "    # Criando matriz de attention simulada\n",
        "    attention_matrix = np.random.rand(n_mod, n_mod)\n",
        "    \n",
        "    # Fazendo a matriz simÃ©trica e normalizando\n",
        "    attention_matrix = (attention_matrix + attention_matrix.T) / 2\n",
        "    attention_matrix = attention_matrix / attention_matrix.sum(axis=1, keepdims=True)\n",
        "    \n",
        "    return attention_matrix, modalities\n\n",
        "# Criando e visualizando\n",
        "attention_matrix, modalities = create_multimodal_attention_matrix()\n\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n",
        "# Heatmap da matriz de attention\n",
        "im1 = ax1.imshow(attention_matrix, cmap='Blues', aspect='equal')\n",
        "ax1.set_title('Matriz de Attention Multimodal', fontsize=14, fontweight='bold')\n",
        "ax1.set_xticks(range(len(modalities)))\n",
        "ax1.set_yticks(range(len(modalities)))\n",
        "ax1.set_xticklabels(modalities)\n",
        "ax1.set_yticklabels(modalities)\n\n",
        "# Adicionando valores na matriz\n",
        "for i in range(len(modalities)):\n",
        "    for j in range(len(modalities)):\n",
        "        text = ax1.text(j, i, f'{attention_matrix[i, j]:.2f}',\n",
        "                       ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n\n",
        "plt.colorbar(im1, ax=ax1)\n\n",
        "# GrÃ¡fico de barras das modalidades\n",
        "modal_importance = attention_matrix.mean(axis=0)\n",
        "bars = ax2.bar(modalities, modal_importance, \n",
        "               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
        "ax2.set_title('ImportÃ¢ncia MÃ©dia por Modalidade', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylabel('Score de Attention')\n",
        "ax2.set_ylim(0, max(modal_importance) * 1.1)\n\n",
        "# Adicionando valores nas barras\n",
        "for bar, value in zip(bars, modal_importance):\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n\n",
        "plt.tight_layout()\n",
        "plt.show()\n\n",
        "print(\"ğŸ¯ Insights sobre Attention Multimodal:\")\n",
        "print(f\"â€¢ Modalidade mais 'atenta': {modalities[np.argmax(modal_importance)]}\")\n",
        "print(f\"â€¢ Modalidade menos 'atenta': {modalities[np.argmin(modal_importance)]}\")\n",
        "print(\"â€¢ Cada modalidade 'conversa' com as outras atravÃ©s do attention!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¤– Agentes AutÃ´nomos: LLMs que Agem no Mundo Real\n\n### Da Conversa para a AÃ§Ã£o!\n\nImagina um LLM que nÃ£o sÃ³ responde suas perguntas, mas tambÃ©m:\n- **Agenda suas reuniÃµes** ğŸ“…\n- **Faz compras online** ğŸ›’\n- **Controla sua casa inteligente** ğŸ \n- **Programa cÃ³digo e deploya** ğŸ’»\n\n**Isso sÃ£o os Agentes AutÃ´nomos!**\n\n### Arquitetura de um Agente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\ngraph TD\n    A[Entrada do UsuÃ¡rio] --> B[LLM Reasoning]\n    B --> C{Precisa de AÃ§Ã£o?}\n    C -->|Sim| D[SeleÃ§Ã£o de Tool]\n    C -->|NÃ£o| H[Resposta Direta]\n    D --> E[ExecuÃ§Ã£o da AÃ§Ã£o]\n    E --> F[Resultado da AÃ§Ã£o]\n    F --> G[LLM Processamento]\n    G --> H[Resposta Final]\n    H --> I[SaÃ­da para UsuÃ¡rio]\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sistema de Agente AutÃ´nomo Simples\n",
        "import json\n",
        "from datetime import datetime, timedelta\n\n",
        "class AutonomousAgent:\n",
        "    def __init__(self):\n",
        "        self.tools = {\n",
        "            'calculadora': self.calculator,\n",
        "            'agenda': self.schedule_meeting,\n",
        "            'clima': self.get_weather,\n",
        "            'busca': self.web_search\n",
        "        }\n",
        "        \n",
        "        self.memory = []  # MemÃ³ria das aÃ§Ãµes\n",
        "    \n",
        "    def calculator(self, expression):\n",
        "        \"\"\"Tool: Calculadora segura\"\"\"\n",
        "        try:\n",
        "            # AvaliaÃ§Ã£o segura apenas de expressÃµes matemÃ¡ticas\n",
        "            allowed_chars = '0123456789+-*/.() '\n",
        "            if all(c in allowed_chars for c in expression):\n",
        "                result = eval(expression)\n",
        "                return f\"Resultado: {result}\"\n",
        "            else:\n",
        "                return \"Erro: ExpressÃ£o invÃ¡lida\"\n",
        "        except:\n",
        "            return \"Erro no cÃ¡lculo\"\n",
        "    \n",
        "    def schedule_meeting(self, details):\n",
        "        \"\"\"Tool: Agendamento de reuniÃ£o\"\"\"\n",
        "        meeting_time = datetime.now() + timedelta(days=1)\n",
        "        return f\"ReuniÃ£o '{details}' agendada para {meeting_time.strftime('%d/%m/%Y %H:%M')}\"\n",
        "    \n",
        "    def get_weather(self, location):\n",
        "        \"\"\"Tool: PrevisÃ£o do tempo (simulada)\"\"\"\n",
        "        weathers = ['Ensolarado', 'Nublado', 'Chuvoso', 'Parcialmente nublado']\n",
        "        temp = np.random.randint(15, 35)\n",
        "        weather = np.random.choice(weathers)\n",
        "        return f\"Em {location}: {weather}, {temp}Â°C\"\n",
        "    \n",
        "    def web_search(self, query):\n",
        "        \"\"\"Tool: Busca web (simulada)\"\"\"\n",
        "        results = [\n",
        "            f\"Encontrei 3 resultados relevantes sobre '{query}'\",\n",
        "            f\"Principais fontes sobre {query}: Wikipedia, artigos cientÃ­ficos\",\n",
        "            f\"InformaÃ§Ãµes mais recentes sobre {query} de fontes confiÃ¡veis\"\n",
        "        ]\n",
        "        return np.random.choice(results)\n",
        "    \n",
        "    def parse_intent(self, user_input):\n",
        "        \"\"\"Analisa a intenÃ§Ã£o do usuÃ¡rio e identifica tool necessÃ¡rio\"\"\"\n",
        "        input_lower = user_input.lower()\n",
        "        \n",
        "        if any(word in input_lower for word in ['calcular', 'soma', 'multiplicar', '+', '-', '*', '/']):\n",
        "            return 'calculadora'\n",
        "        elif any(word in input_lower for word in ['agendar', 'reuniÃ£o', 'meeting']):\n",
        "            return 'agenda'\n",
        "        elif any(word in input_lower for word in ['clima', 'tempo', 'temperatura']):\n",
        "            return 'clima'\n",
        "        elif any(word in input_lower for word in ['buscar', 'procurar', 'pesquisar']):\n",
        "            return 'busca'\n",
        "        else:\n",
        "            return 'conversa'  # Resposta conversacional\n",
        "    \n",
        "    def extract_parameters(self, user_input, tool_type):\n",
        "        \"\"\"Extrai parÃ¢metros para cada tipo de tool\"\"\"\n",
        "        if tool_type == 'calculadora':\n",
        "            # Procura por expressÃ£o matemÃ¡tica\n",
        "            import re\n",
        "            math_expr = re.search(r'[0-9+\\-*/().\\s]+', user_input)\n",
        "            return math_expr.group() if math_expr else \"2+2\"\n",
        "        \n",
        "        elif tool_type == 'agenda':\n",
        "            # Extrai detalhes da reuniÃ£o\n",
        "            return user_input.split('agendar')[-1].strip()\n",
        "        \n",
        "        elif tool_type == 'clima':\n",
        "            # Procura por nome de cidade\n",
        "            cities = ['SÃ£o Paulo', 'Rio de Janeiro', 'BrasÃ­lia', 'Salvador']\n",
        "            for city in cities:\n",
        "                if city.lower() in user_input.lower():\n",
        "                    return city\n",
        "            return \"SÃ£o Paulo\"  # PadrÃ£o\n",
        "        \n",
        "        elif tool_type == 'busca':\n",
        "            # Extrai termo de busca\n",
        "            search_terms = user_input.replace('buscar', '').replace('procurar', '').strip()\n",
        "            return search_terms\n",
        "        \n",
        "        return user_input\n",
        "    \n",
        "    def process_request(self, user_input):\n",
        "        \"\"\"Pipeline principal do agente\"\"\"\n",
        "        print(f\"ğŸ‘¤ UsuÃ¡rio: {user_input}\")\n",
        "        \n",
        "        # 1. AnÃ¡lise de intenÃ§Ã£o\n",
        "        intent = self.parse_intent(user_input)\n",
        "        print(f\"ğŸ§  IntenÃ§Ã£o detectada: {intent}\")\n",
        "        \n",
        "        # 2. Se for conversa simples\n",
        "        if intent == 'conversa':\n",
        "            response = \"Entendi! Como posso ajudar vocÃª hoje? Posso calcular, agendar, verificar clima ou buscar informaÃ§Ãµes.\"\n",
        "            print(f\"ğŸ¤– Resposta: {response}\\n\")\n",
        "            return response\n",
        "        \n",
        "        # 3. ExtraÃ§Ã£o de parÃ¢metros\n",
        "        params = self.extract_parameters(user_input, intent)\n",
        "        print(f\"âš™ï¸  ParÃ¢metros: {params}\")\n",
        "        \n",
        "        # 4. ExecuÃ§Ã£o do tool\n",
        "        if intent in self.tools:\n",
        "            tool_result = self.tools[intent](params)\n",
        "            print(f\"ğŸ”§ Resultado do tool: {tool_result}\")\n",
        "            \n",
        "            # 5. Salvar na memÃ³ria\n",
        "            self.memory.append({\n",
        "                'timestamp': datetime.now(),\n",
        "                'input': user_input,\n",
        "                'intent': intent,\n",
        "                'result': tool_result\n",
        "            })\n",
        "            \n",
        "            # 6. Resposta final\n",
        "            final_response = f\"Pronto! {tool_result}\"\n",
        "            print(f\"ğŸ¯ Resposta final: {final_response}\\n\")\n",
        "            return final_response\n\n",
        "# Testando nosso agente\n",
        "agent = AutonomousAgent()\n\n",
        "# Casos de teste\n",
        "test_cases = [\n",
        "    \"Calcular 15 * 8 + 32\",\n",
        "    \"Agendar reuniÃ£o com equipe de desenvolvimento\",\n",
        "    \"Como estÃ¡ o clima em SÃ£o Paulo?\",\n",
        "    \"Buscar informaÃ§Ãµes sobre machine learning\",\n",
        "    \"OlÃ¡, como vocÃª estÃ¡?\"\n",
        "]\n\n",
        "print(\"ğŸš€ Testando Agente AutÃ´nomo:\\n\")\n",
        "for test in test_cases:\n",
        "    agent.process_request(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Dica do Pedro**: Agentes autÃ´nomos sÃ£o como ter um assistente pessoal que nunca dorme, nunca esquece e estÃ¡ sempre aprendendo. Ã‰ o futuro da automaÃ§Ã£o inteligente! ğŸ¤–âœ¨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš¡ TÃ©cnicas de OtimizaÃ§Ã£o: Deixando Tudo Mais RÃ¡pido\n\n### O Problema da Velocidade\n\nLLMs sÃ£o poderosos, mas... cara, como sÃ£o lentos Ã s vezes! ğŸŒ\n\nLembra da arquitetura Transformer que vimos no MÃ³dulo 3? Ela tem algumas \"pegadinhas\" de performance:\n\n### Principais Gargalos:\n1. **Attention QuadrÃ¡tica**: O(nÂ²) - cresce muito rÃ¡pido!\n2. **Tamanho dos Modelos**: BilhÃµes de parÃ¢metros\n3. **Autoregressive Generation**: Uma palavra por vez\n4. **Memory Bandwidth**: MovimentaÃ§Ã£o de dados\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introduÃ§Ã£o-Ã -llms-modulo-13_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparando diferentes tÃ©cnicas de otimizaÃ§Ã£o\n",
        "class OptimizationTechniques:\n",
        "    def __init__(self):\n",
        "        self.techniques = {\n",
        "            'vanilla_transformer': {'speed': 1.0, 'memory': 1.0, 'quality': 1.0},\n",
        "            'quantization_int8': {'speed': 1.8, 'memory': 0.5, 'quality': 0.98},\n",
        "            'pruning': {'speed': 2.2, 'memory': 0.3, 'quality': 0.95},\n",
        "            'distillation': {'speed': 3.5, 'memory': 0.2, 'quality': 0.92},\n",
        "            'linear_attention': {'speed': 2.8, 'memory': 0.4, 'quality': 0.96},\n",
        "            'speculative_decoding': {'speed': 4.2, 'memory': 1.2, 'quality': 1.0},\n",
        "            'flash_attention': {'speed': 2.1, 'memory': 0.6, 'quality': 1.0}\n",
        "        }\n",
        "    \n",
        "    def benchmark_sequence_lengths(self):\n",
        "        \"\"\"Simula performance vs tamanho da sequÃªncia\"\"\"\n",
        "        sequence_lengths = [128, 512, 1024, 2048, 4096, 8192]\n",
        "        \n",
        "        results = {}\n",
        "        for technique, metrics in self.techniques.items():\n",
        "            times = []\n",
        "            for seq_len in sequence_lengths:\n",
        "                # SimulaÃ§Ã£o de tempo baseado na complexidade\n",
        "                if 'linear' in technique:\n",
        "                    base_time = seq_len * 0.001  # O(n)\n",
        "                else:\n",
        "                    base_time = (seq_len ** 1.8) * 0.000001  # Aproximadamente O(nÂ²)\n",
        "                \n",
        "                optimized_time = base_time / metrics['speed']\n",
        "                times.append(optimized_time)\n",
        "            \n",
        "            results[technique] = times\n",
        "        \n",
        "        return sequence_lengths, results\n\n",
        "# Executando benchmark\n",
        "optimizer = OptimizationTechniques()\n",
        "seq_lengths, performance_results = optimizer.benchmark_sequence_lengths()\n\n",
        "# Visualizando resultados\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n\n",
        "# 1. Performance vs Sequence Length\n",
        "colors = plt.cm.Set3(np.linspace(0, 1, len(performance_results)))\n",
        "for i, (technique, times) in enumerate(performance_results.items()):\n",
        "    if technique in ['vanilla_transformer', 'quantization_int8', 'flash_attention', 'speculative_decoding']:\n",
        "        ax1.plot(seq_lengths, times, 'o-', linewidth=2, \n",
        "                label=technique.replace('_', ' ').title(), color=colors[i])\n\n",
        "ax1.set_xlabel('Tamanho da SequÃªncia')\n",
        "ax1.set_ylabel('Tempo de Processamento (s)')\n",
        "ax1.set_title('Performance vs Tamanho da SequÃªncia')\n",
        "ax1.set_yscale('log')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n\n",
        "# 2. Speed vs Quality Trade-off\n",
        "techniques_list = list(optimizer.techniques.keys())\n",
        "speeds = [optimizer.techniques[t]['speed'] for t in techniques_list]\n",
        "qualities = [optimizer.techniques[t]['quality'] for t in techniques_list]\n",
        "\n",
        "scatter = ax2.scatter(speeds, qualities, s=100, c=range(len(techniques_list)), \n",
        "                    cmap='viridis', alpha=0.7)\n",
        "ax2.set_xlabel('Speedup (x times faster)')\n",
        "ax2.set_ylabel('Quality Retention')\n",
        "ax2.set_title('Speed vs Quality Trade-off')\n",
        "ax2.grid(True, alpha=0.3)\n\n",
        "# Adicionando labels\n",
        "for i, technique in enumerate(techniques_list):\n",
        "    ax2.annotate(technique.replace('_', '\\n'), (speeds[i], qualities[i]), \n",
        "                xytext=(5, 5), textcoords='offset points', fontsize=8)\n\n",
        "# 3. Memory Usage Comparison\n",
        "memory_usage = [optimizer.techniques[t]['memory'] for t in techniques_list]\n",
        "bars = ax3.bar(range(len(techniques_list)), memory_usage, \n",
        "               color=colors[:len(techniques_list)])\n",
        "ax3.set_xlabel('TÃ©cnicas de OtimizaÃ§Ã£o')\n",
        "ax3.set_ylabel('Uso de MemÃ³ria (relativo)')\n",
        "ax3.set_title('ComparaÃ§Ã£o de Uso de MemÃ³ria')\n",
        "ax3.set_xticks(range(len(techniques_list)))\n",
        "ax3.set_xticklabels([t.replace('_', '\\n') for t in techniques_list], rotation=45)\n",
        "\n",
        "# 4. Radar Chart - ComparaÃ§Ã£o Geral\n",
        "from math import pi\n\n",
        "categories = ['Speed', 'Memory Efficiency', 'Quality']\n",
        "N = len(categories)\n",
        "\n",
        "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
        "angles += angles[:1]\n\n",
        "# Comparando 3 tÃ©cnicas principais\n",
        "compare_techniques = ['vanilla_transformer', 'quantization_int8', 'speculative_decoding']\n",
        "colors_radar = ['red', 'blue', 'green']\n\n",
        "for i, technique in enumerate(compare_techniques):\n",
        "    metrics = optimizer.techniques[technique]\n",
        "    values = [metrics['speed'], 1/metrics['memory'], metrics['quality']]\n",
        "    values += values[:1]\n",
        "    \n",
        "    ax4.plot(angles, values, 'o-', linewidth=2, label=technique.replace('_', ' ').title(),\n",
        "             color=colors_radar[i])\n",
        "    ax4.fill(angles, values, alpha=0.25, color=colors_radar[i])\n\n",
        "ax4.set_xticks(angles[:-1])\n",
        "ax4.set_xticklabels(categories)\n",
        "ax4.set_title('ComparaÃ§Ã£o Multidimensional')\n",
        "ax4.legend()\n",
        "ax4.grid(True)\n\n",
        "plt.tight_layout()\n",
        "plt.show()\n\n",
        "print(\"ğŸ¯ Principais Insights de OtimizaÃ§Ã£o:\")\n",
        "print(\"â€¢ Speculative Decoding: Melhor speedup mantendo qualidade\")\n",
        "print(\"â€¢ Quantization: Boa reduÃ§Ã£o de memÃ³ria com pouca perda\")\n",
        "print(\"â€¢ Flash Attention: OtimizaÃ§Ã£o 'gratuita' sem perda de qualidade\")\n",
        "print(\"â€¢ Trade-off sempre existe: speed vs quality vs memory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TÃ©cnicas de OtimizaÃ§Ã£o Detalhadas\n\n**1. Quantization (QuantizaÃ§Ã£o)**\n- Reduz precisÃ£o: FP32 â†’ INT8 â†’ INT4\n- Economiza 4-8x memÃ³ria\n- Speedup significativo\n\n**2. Pruning (Poda)**\n- Remove conexÃµes \"desnecessÃ¡rias\"\n- Modelo esparso (sparse)\n- MantÃ©m performance com menos parÃ¢metros\n\n**3. Distillation (DestilaÃ§Ã£o)**\n- Professor (modelo grande) â†’ Aluno (modelo pequeno)\n- Transfere conhecimento\n- Modelo final muito mais rÃ¡pido\n\n**Dica do Pedro**: Ã‰ como fazer um carro de FÃ³rmula 1 - vocÃª otimiza cada componente para extrair mÃ¡xima performance! ğŸï¸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”® O Futuro dos LLMs: O Que Vem Por AÃ­\n\n### TendÃªncias para os PrÃ³ximos Anos\n\nBaseado em tudo que aprendemos neste curso, vamos dar uma espiada no que o futuro reserva:\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introduÃ§Ã£o-Ã -llms-modulo-13_img_04.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ProjeÃ§Ãµes para o futuro dos LLMs\n",
        "import pandas as pd\n\n",
        "# Dados das tendÃªncias futuras\n",
        "future_trends = {\n",
        "    'Ano': [2024, 2025, 2026, 2027, 2028, 2029, 2030],\n",
        "    'ParÃ¢metros (TrilhÃµes)': [1.8, 5.0, 15.0, 50.0, 100.0, 200.0, 500.0],\n",
        "    'EficiÃªncia EnergÃ©tica (x)': [1.0, 2.5, 6.0, 15.0, 40.0, 80.0, 150.0],\n",
        "    'Modalidades Suportadas': [4, 6, 8, 12, 16, 20, 25],\n",
        "    'LatÃªncia (ms)': [500, 300, 150, 75, 40, 20, 10],\n",
        "    'Custo por Token ($/M)': [20, 12, 6, 3, 1.5, 0.8, 0.4]\n",
        "}\n\n",
        "df_future = pd.DataFrame(future_trends)\n\n",
        "# Visualizando as tendÃªncias\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.ravel()\n\n",
        "metrics = [\n",
        "    ('ParÃ¢metros (TrilhÃµes)', 'EvoluÃ§Ã£o do Tamanho dos Modelos', 'green'),\n",
        "    ('EficiÃªncia EnergÃ©tica (x)', 'Melhoria na EficiÃªncia EnergÃ©tica', 'blue'),\n",
        "    ('Modalidades Suportadas', 'ExpansÃ£o Multimodal', 'orange'),\n",
        "    ('LatÃªncia (ms)', 'ReduÃ§Ã£o da LatÃªncia', 'red'),\n",
        "    ('Custo por Token ($/M)', 'DemocratizaÃ§Ã£o dos Custos', 'purple')\n",
        "]\n\n",
        "for i, (metric, title, color) in enumerate(metrics):\n",
        "    axes[i].plot(df_future['Ano'], df_future[metric], 'o-', \n",
        "                linewidth=3, markersize=8, color=color)\n",
        "    axes[i].set_title(title, fontsize=12, fontweight='bold')\n",
        "    axes[i].set_xlabel('Ano')\n",
        "    axes[i].set_ylabel(metric)\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Destacando valores especÃ­ficos\n",
        "    for j, (year, value) in enumerate(zip(df_future['Ano'], df_future[metric])):\n",
        "        if j % 2 == 0:  # A cada 2 anos\n",
        "            axes[i].annotate(f'{value}', (year, value), \n",
        "                           xytext=(0, 10), textcoords='offset points',\n",
        "                           ha='center', fontweight='bold')\n\n",
        "# GrÃ¡fico combinado na Ãºltima posiÃ§Ã£o\n",
        "ax_combined = axes[5]\n",
        "\n",
        "# Normalizando mÃ©tricas para comparaÃ§Ã£o\n",
        "normalized_data = {\n",
        "    'ParÃ¢metros': df_future['ParÃ¢metros (TrilhÃµes)'] / df_future['ParÃ¢metros (TrilhÃµes)'].iloc[0],\n",
        "    'EficiÃªncia': df_future['EficiÃªncia EnergÃ©tica (x)'],\n",
        "    'Modalidades': df_future['Modalidades Suportadas'] / df_future['Modalidades Suportadas'].iloc[0]\n",
        "}\n\n",
        "for metric, data in normalized_data.items():\n",
        "    ax_combined.plot(df_future['Ano'], data, 'o-', linewidth=2, \n",
        "                    markersize=6, label=metric)\n\n",
        "ax_combined.set_title('Crescimento Comparativo (Normalizado)', fontsize=12, fontweight='bold')\n",
        "ax_combined.set_xlabel('Ano')\n",
        "ax_combined.set_ylabel('Crescimento Relativo (x vezes)')\n",
        "ax_combined.legend()\n",
        "ax_combined.grid(True, alpha=0.3)\n",
        "ax_combined.set_yscale('log')\n\n",
        "plt.tight_layout()\n",
        "plt.show()\n\n",
        "print(\"ğŸ”® PREVISÃ•ES PARA O FUTURO DOS LLMs:\\n\")\n",
        "print(\"ğŸ“Š Crescimento Exponencial:\")\n",
        "print(f\"â€¢ 2024â†’2030: {df_future['ParÃ¢metros (TrilhÃµes)'].iloc[-1]/df_future['ParÃ¢metros (TrilhÃµes)'].iloc[0]:.0f}x mais parÃ¢metros\")\n",
        "print(f\"â€¢ EficiÃªncia: {df_future['EficiÃªncia EnergÃ©tica (x)'].iloc[-1]:.0f}x mais eficiente\")\n",
        "print(f\"â€¢ LatÃªncia: {df_future['LatÃªncia (ms)'].iloc[0]/df_future['LatÃªncia (ms)'].iloc[-1]:.0f}x mais rÃ¡pido\")\n",
        "print(f\"â€¢ Custo: {df_future['Custo por Token ($/M)'].iloc[0]/df_future['Custo por Token ($/M)'].iloc[-1]:.0f}x mais barato\")\n\n",
        "print(\"\\nğŸš€ Marcos Importantes:\")\n",
        "print(\"â€¢ 2025: Primeiros modelos verdadeiramente multimodais\")\n",
        "print(\"â€¢ 2026: LLMs com raciocÃ­nio cientÃ­fico avanÃ§ado\")\n",
        "print(\"â€¢ 2027: Agentes autÃ´nomos em massa\")\n",
        "print(\"â€¢ 2028: Modelos auto-melhorantes\")\n",
        "print(\"â€¢ 2030: IA Geral Artificial? ğŸ¤”\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tecnologias Emergentes\n\n**1. Neuromorphic Computing** ğŸ§ \n- Hardware que imita o cÃ©rebro\n- EficiÃªncia energÃ©tica extrema\n- Processamento em tempo real\n\n**2. Quantum-Enhanced LLMs** âš›ï¸\n- ComputaÃ§Ã£o quÃ¢ntica para attention\n- Speedup exponencial em problemas especÃ­ficos\n- Nova classe de algoritmos\n\n**3. Continual Learning** ğŸ“š\n- Modelos que aprendem continuamente\n- Sem \"esquecer\" conhecimento anterior\n- AdaptaÃ§Ã£o em tempo real\n\n**4. Causal Reasoning** ğŸ”—\n- Entendimento de causa e efeito\n- RaciocÃ­nio cientÃ­fico avanÃ§ado\n- PrevisÃµes mais confiÃ¡veis\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ ExercÃ­cio PrÃ¡tico: Monte seu LLM do Futuro!\n\nAgora Ã© sua vez! Vamos projetar um LLM futurÃ­stico com tudo que aprendemos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERCÃCIO 1: Design de LLM FuturÃ­stico\n",
        "class FutureLLMDesigner:\n",
        "    def __init__(self):\n",
        "        self.design_choices = {\n",
        "            'arquitetura': ['Transformer', 'Mamba', 'Hybrid', 'Quantum-Enhanced'],\n",
        "            'modalidades': ['Texto', 'Imagem', 'Audio', 'Video', '3D', 'Sensores'],\n",
        "            'otimizacoes': ['Quantization', 'Pruning', 'Distillation', 'Flash-Attention'],\n",
        "            'capabilities': ['RAG', 'Agentes', 'Reasoning', 'Continual-Learning']\n",
        "        }\n",
        "        \n",
        "        self.design_metrics = {\n",
        "            'performance_score': 0,\n",
        "            'efficiency_score': 0,\n",
        "            'innovation_score': 0,\n",
        "            'total_score': 0\n",
        "        }\n",
        "    \n",
        "    def calculate_design_score(self, user_design):\n",
        "        \"\"\"Calcula score baseado nas escolhas do usuÃ¡rio\"\"\"\n",
        "        \n",
        "        # PontuaÃ§Ã£o por arquitetura\n",
        "        arch_scores = {\n",
        "            'Transformer': 7, 'Mamba': 8, 'Hybrid': 9, 'Quantum-Enhanced': 10\n",
        "        }\n",
        "        \n",
        "        # PontuaÃ§Ã£o por modalidades (mais = melhor, mas com diminishing returns)\n",
        "        modal_score = min(len(user_design.get('modalidades', [])) * 2, 10)\n",
        "        \n",
        "        # PontuaÃ§Ã£o por otimizaÃ§Ãµes\n",
        "        optim_score = len(user_design.get('otimizacoes', [])) * 1.5\n",
        "        \n",
        "        # PontuaÃ§Ã£o por capabilities\n",
        "        cap_score = len(user_design.get('capabilities', [])) * 2\n",
        "        \n",
        "        # Calculando scores\n",
        "        performance = arch_scores.get(user_design.get('arquitetura', 'Transformer'), 7) + modal_score\n",
        "        efficiency = optim_score * 2\n",
        "        innovation = cap_score + (1 if user_design.get('arquitetura') == 'Quantum-Enhanced' else 0)\n",
        "        \n",
        "        total = (performance + efficiency + innovation) / 3\n",
        "        \n",
        "        return {\n",
        "            'performance_score': round(performance, 1),\n",
        "            'efficiency_score': round(efficiency, 1),\n",
        "            'innovation_score': round(innovation, 1),\n",
        "            'total_score': round(total, 1)\n",
        "        }\n",
        "    \n",
        "    def generate_feedback(self, design, scores):\n",
        "        \"\"\"Gera feedback personalizado\"\"\"\n",
        "        feedback = [\"\\nğŸ¯ FEEDBACK DO SEU DESIGN:\\n\"]\n",
        "        \n",
        "        if scores['total_score'] >= 15:\n",
        "            feedback.append(\"ğŸš€ INCRÃVEL! Seu LLM estÃ¡ no nÃ­vel 'Futuro Chegou!'\")\n",
        "        elif scores['total_score'] >= 12:\n",
        "            feedback.append(\"â­ MUITO BOM! Design sÃ³lido e inovador!\")\n",
        "        elif scores['total_score'] >= 9:\n",
        "            feedback.append(\"ğŸ‘ BOM! Com algumas melhorias, vai ficar perfeito!\")\n",
        "        else:\n",
        "            feedback.append(\"ğŸ’¡ POTENCIAL! Que tal explorar mais opÃ§Ãµes?\")\n",
        "        \n",
        "        # Feedback especÃ­fico por Ã¡rea\n",
        "        if scores['performance_score'] < 10:\n",
        "            feedback.append(\"â€¢ Performance: Considere arquitetura mais avanÃ§ada ou mais modalidades\")\n",
        "        \n",
        "        if scores['efficiency_score'] < 8:\n",
        "            feedback.append(\"â€¢ EficiÃªncia: Adicione mais tÃ©cnicas de otimizaÃ§Ã£o\")\n",
        "        \n",
        "        if scores['innovation_score'] < 6:\n",
        "            feedback.append(\"â€¢ InovaÃ§Ã£o: Explore capabilities mais avanÃ§adas\")\n",
        "        \n",
        "        return \"\\n\".join(feedback)\n\n",
        "# Seu turno! FaÃ§a seu design\n",
        "designer = FutureLLMDesigner()\n\n",
        "print(\"ğŸ¨ DESIGN SEU LLM DO FUTURO!\\n\")\n",
        "print(\"OpÃ§Ãµes disponÃ­veis:\")\n",
        "for category, options in designer.design_choices.items():\n",
        "    print(f\"â€¢ {category.upper()}: {', '.join(options)}\")\n\n",
        "# Exemplo de design (vocÃª pode modificar!)\n",
        "meu_design = {\n",
        "    'arquitetura': 'Hybrid',  # Mude aqui!\n",
        "    'modalidades': ['Texto', 'Imagem', 'Audio', '3D'],  # Adicione/remova modalidades!\n",
        "    'otimizacoes': ['Quantization', 'Flash-Attention'],  # Escolha suas otimizaÃ§Ãµes!\n",
        "    'capabilities': ['RAG', 'Agentes', 'Reasoning']  # Que superpoderes seu LLM terÃ¡?\n",
        "}\n\n",
        "print(\"\\nğŸ”§ SEU DESIGN ATUAL:\")\n",
        "for key, value in meu_design.items():\n",
        "    print(f\"â€¢ {key.upper()}: {value}\")\n\n",
        "# Calculando e mostrando resultados\n",
        "scores = designer.calculate_design_score(meu_design)\n",
        "feedback = designer.generate_feedback(meu_design, scores)\n\n",
        "print(\"\\nğŸ“Š SCORES DO SEU LLM:\")\n",
        "for metric, score in scores.items():\n",
        "    print(f\"â€¢ {metric.replace('_', ' ').title()}: {score}/20\")\n\n",
        "print(feedback)\n\n",
        "print(\"\\nğŸ’¡ DESAFIO: Modifique o 'meu_design' acima e rode novamente para melhorar seus scores!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ ExercÃ­cio Final: Jornada Completa\n\nVamos revisar tudo que aprendemos neste curso inteiro!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERCÃCIO 2: Quiz Final - Jornada Completa do Curso\n",
        "class CourseJourneyQuiz:\n",
        "    def __init__(self):\n",
        "        self.modules_knowledge = {\n",
        "            'MÃ³dulo 2 - LLMs Basics': {\n",
        "                'question': \"Qual a principal caracterÃ­stica dos LLMs?\",\n",
        "                'answer': \"Predizer prÃ³xima palavra baseado em contexto\"\n",
        "            },\n",
        "            'MÃ³dulo 3 - Transformer': {\n",
        "                'question': \"Qual o mecanismo fundamental do Transformer?\", \n",
        "                'answer': \"Attention mechanism\"\n",
        "            },\n",
        "            'MÃ³dulo 4 - Tokens': {\n",
        "                'question': \"Como o texto Ã© processado pelos LLMs?\",\n",
        "                'answer': \"Dividido em tokens menores\"\n",
        "            },\n",
        "            'MÃ³dulo 5 - Embeddings': {\n",
        "                'question': \"Como palavras viram nÃºmeros?\",\n",
        "                'answer': \"AtravÃ©s de embeddings vetoriais\"\n",
        "            },\n",
        "            'MÃ³dulo 8 - Prompting': {\n",
        "                'question': \"Qual tÃ©cnica melhora respostas sem treinar?\",\n",
        "                'answer': \"Engenharia de prompts\"\n",
        "            },\n",
        "            'MÃ³dulo 9 - AvaliaÃ§Ã£o': {\n",
        "                'question': \"Como medimos qualidade de LLMs?\",\n",
        "                'answer': \"MÃ©tricas como BLEU, ROUGE, avaliaÃ§Ã£o humana\"\n",
        "            },\n",
        "            'MÃ³dulo 13 - AvanÃ§ados': {\n",
        "                'question': \"Qual tÃ©cnica dÃ¡ conhecimento atualizado aos LLMs?\",\n",
        "                'answer': \"RAG - Retrieval Augmented Generation\"\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        self.journey_milestones = [\n",
        "            \"ğŸš€ Descobriu o que sÃ£o LLMs\",\n",
        "            \"ğŸ§  Entendeu a arquitetura Transformer\", \n",
        "            \"ğŸ”¤ Dominou tokens e tokenizaÃ§Ã£o\",\n",
        "            \"ğŸ“Š Compreendeu embeddings\",\n",
        "            \"ğŸ¯ Aprendeu prompting avanÃ§ado\",\n",
        "            \"ğŸ“ Sabe avaliar modelos\",\n",
        "            \"ğŸ”® Explorou o futuro dos LLMs\"\n",
        "        ]\n",
        "    \n",
        "    def generate_certificate(self, student_name=\"Estudante\"):\n",
        "        \"\"\"Gera certificado de conclusÃ£o\"\"\"\n",
        "        certificate = f\"\"\"\n",
        "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "    â•‘                    ğŸ“ CERTIFICADO DE CONCLUSÃƒO ğŸ“            â•‘\n",
        "    â•‘                                                              â•‘\n",
        "    â•‘        Curso: IntroduÃ§Ã£o Ã  LLMs - TÃ³picos AvanÃ§ados         â•‘\n",
        "    â•‘                                                              â•‘\n",
        "    â•‘                Estudante: {student_name:^30}                â•‘\n",
        "    â•‘                                                              â•‘\n",
        "    â•‘    Concluiu com sucesso todos os 13 mÃ³dulos do curso,        â•‘\n",
        "    â•‘    demonstrando conhecimento em:                             â•‘\n",
        "    â•‘                                                              â•‘\n",
        "    â•‘    âœ… Fundamentos de Large Language Models                   â•‘\n",
        "    â•‘    âœ… Arquitetura Transformer & Attention                    â•‘\n",
        "    â•‘    âœ… TokenizaÃ§Ã£o e Embeddings                               â•‘\n",
        "    â•‘    âœ… Engenharia de Prompts                                  â•‘\n",
        "    â•‘    âœ… AvaliaÃ§Ã£o de Modelos                                   â•‘\n",
        "    â•‘    âœ… RAG e Multimodalidade                                  â•‘\n",
        "    â•‘    âœ… Agentes AutÃ´nomos                                      â•‘\n",
        "    â•‘    âœ… OtimizaÃ§Ã£o e Futuro dos LLMs                          â•‘\n",
        "    â•‘                                                              â•‘\n",
        "    â•‘            Instrutor: Pedro Nunes Guth                      â•‘\n",
        "    â•‘            Data: {datetime.now().strftime('%d/%m/%Y'):^34}              â•‘\n",
        "    â•‘                                                              â•‘\n",
        "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        \"\"\"\n",
        "        return certificate\n",
        "    \n",
        "    def show_journey_summary(self):\n",
        "        \"\"\"Mostra resumo da jornada\"\"\"\n",
        "        print(\"ğŸ¯ SUA JORNADA PELOS LLMs - RESUMO COMPLETO:\\n\")\n",
        "        \n",
        "        for i, milestone in enumerate(self.journey_milestones, 1):\n",
        "            print(f\"MÃ³dulo {i}: {milestone}\")\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ğŸ† PARABÃ‰NS! VocÃª agora Ã© um Expert em LLMs!\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        return True\n\n",
        "# Executando o quiz final\n",
        "quiz = CourseJourneyQuiz()\n",
        "\n",
        "# Mostrando jornada completa\n",
        "quiz.show_journey_summary()\n\n",
        "# Gerando certificado\n",
        "certificate = quiz.generate_certificate(\"Future AI Expert\")  # Coloque seu nome aqui!\n",
        "print(certificate)\n",
        "\n",
        "print(\"\\nğŸš€ O QUE VOCÃŠ PODE FAZER AGORA:\")\n",
        "print(\"â€¢ Implementar sistemas RAG em produÃ§Ã£o\")\n",
        "print(\"â€¢ Criar agentes autÃ´nomos inteligentes\")\n",
        "print(\"â€¢ Otimizar LLMs para performance\")\n",
        "print(\"â€¢ Avaliar e comparar diferentes modelos\")\n",
        "print(\"â€¢ Estar preparado para as prÃ³ximas inovaÃ§Ãµes\")\n",
        "\n",
        "print(\"\\nğŸ’¡ PRÃ“XIMOS PASSOS SUGERIDOS:\")\n",
        "print(\"â€¢ Implemente um projeto real usando RAG\")\n",
        "print(\"â€¢ Experimente com modelos multimodais\")\n",
        "print(\"â€¢ Contribua para projetos open-source\")\n",
        "print(\"â€¢ Continue aprendendo - o campo evolui rapidamente!\")\n",
        "\n",
        "print(\"\\nğŸ‰ LIIIIINDO! VocÃª chegou ao fim da jornada! ğŸ‰\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸŠ ConclusÃ£o: O Fim Ã© SÃ³ o ComeÃ§o!\n\n### Recapitulando Nossa Jornada Ã‰pica\n\nCara, que viagem foi essa! ğŸš€\n\nComeÃ§amos lÃ¡ no **MÃ³dulo 1** configurando ambiente, passamos pela teoria fundamental nos **MÃ³dulos 2-5**, mergulhamos na prÃ¡tica nos **MÃ³dulos 6-9**, exploramos seguranÃ§a e limitaÃ§Ãµes nos **MÃ³dulos 10-11**, fizemos um projeto completo no **MÃ³dulo 12**, e agora terminamos explorando o futuro!\n\n### Principais Aprendizados Deste MÃ³dulo:\n\nâœ… **RAG**: Como dar \"superpoderes\" de conhecimento atualizado aos LLMs\n\nâœ… **Multimodalidade**: LLMs que \"veem\", \"ouvem\" e processam mÃºltiplas modalidades\n\nâœ… **Agentes AutÃ´nomos**: IA que age no mundo real, nÃ£o sÃ³ conversa\n\nâœ… **OtimizaÃ§Ã£o**: TÃ©cnicas para deixar tudo mais rÃ¡pido e eficiente\n\nâœ… **Futuro**: TendÃªncias e tecnologias emergentes\n\n### Dica Final do Pedro:\n\nO campo de LLMs evolui na velocidade da luz! ğŸŒŸ O que aprendemos hoje Ã© a base sÃ³lida, mas mantenha-se sempre curioso e continue aprendendo.\n\n**Lembre-se**: VocÃª agora tem todas as ferramentas para entender, avaliar e implementar qualquer nova tecnologia que apareÃ§a no mundo dos LLMs!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introduÃ§Ã£o-Ã -llms-modulo-13_img_06.png)\n\n---\n\n### ğŸš€ Continue a Jornada:\n\n- **GitHub**: Contribua para projetos open-source\n- **Papers**: Leia os Ãºltimos papers em arXiv\n- **Comunidade**: Participe de discussÃµes e eventos\n- **PrÃ¡tica**: Implemente projetos reais\n\n**Bora mudar o mundo com IA! ğŸŒâœ¨**"
      ]
    }
  ]
}