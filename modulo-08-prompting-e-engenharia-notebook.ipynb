{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ Prompting e Engenharia: A Arte de Conversar com IAs\n\n## M√≥dulo 8 - Introdu√ß√£o √† LLMs\n### Por Pedro Nunes Guth\n\n---\n\nFala galera! Chegamos no m√≥dulo que eu considero **O MAIS PR√ÅTICO** de todo o curso! üöÄ\n\nT√°, mas o que √© Prompt Engineering? Imagina que voc√™ t√° pedindo um lanche no drive-thru. Se voc√™ falar \"quero um lanche\", pode vir qualquer coisa. Mas se voc√™ falar \"quero um Big Mac, sem cebola, com batata m√©dia e Coca-Cola gelada\", a√≠ sim voc√™ vai receber exatamente o que quer!\n\nCom LLMs √© a mesma coisa. A forma como voc√™ pergunta define a qualidade da resposta!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introdu√ß√£o-√†-llms-modulo-08_img_01.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bora configurar nosso ambiente!\n",
        "import openai\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from IPython.display import display, Markdown\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configura√ß√µes visuais\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"üéØ Ambiente configurado! Bora dominar o Prompt Engineering!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Fundamentos do Prompting\n\nLembra dos **tokens** que estudamos no M√≥dulo 4? E das **embeddings** do M√≥dulo 5? Tudo isso influencia como o modelo interpreta seu prompt!\n\n### O que √© um Prompt?\n\nUm **prompt** √© literalmente a entrada que voc√™ d√° para o modelo. Mas n√£o √© s√≥ texto jogado aleatoriamente - √© uma **instru√ß√£o estruturada** que guia o comportamento da IA.\n\n### Anatomia de um Bom Prompt:\n\n1. **Contexto**: \"Voc√™ √© um expert em...\"\n2. **Tarefa**: \"Sua miss√£o √©...\"\n3. **Formato**: \"Responda em forma de...\"\n4. **Exemplos**: \"Por exemplo...\"\n5. **Restri√ß√µes**: \"N√£o fa√ßa...\"\n\n**Dica do Pedro**: Pense no prompt como uma receita de bolo. Quanto mais espec√≠fica, melhor o resultado! üë®‚Äçüç≥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos simular diferentes tipos de prompts\n",
        "prompts_examples = {\n",
        "    \"Ruim\": \"Explique IA\",\n",
        "    \"M√©dio\": \"Explique o que √© intelig√™ncia artificial\",\n",
        "    \"Bom\": \"Voc√™ √© um professor de tecnologia. Explique intelig√™ncia artificial para um aluno de ensino m√©dio, usando analogias simples e exemplos do cotidiano. Responda em at√© 3 par√°grafos.\",\n",
        "    \"Excelente\": \"Contexto: Voc√™ √© um professor experiente de tecnologia com 15 anos de ensino.\\nTarefa: Explique intelig√™ncia artificial para um estudante de ensino m√©dio que nunca ouviu falar do assunto.\\nFormato: 3 par√°grafos com analogias brasileiras.\\nTom: Informal e did√°tico.\\nExemplo: Use compara√ß√µes com futebol ou comida brasileira.\\nRestri√ß√£o: Evite termos t√©cnicos complexos.\"\n",
        "}\n",
        "\n",
        "# Visualizando a evolu√ß√£o da qualidade\n",
        "qualidade_scores = [2, 5, 7, 10]\n",
        "tipos = list(prompts_examples.keys())\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "bars = plt.bar(tipos, qualidade_scores, color=['red', 'orange', 'lightblue', 'green'])\n",
        "plt.title('Evolu√ß√£o da Qualidade dos Prompts', fontsize=16, fontweight='bold')\n",
        "plt.ylabel('Score de Qualidade')\n",
        "plt.ylim(0, 11)\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for bar, score in zip(bars, qualidade_scores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
        "             str(score), ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Viu a diferen√ßa? A estrutura do prompt impacta DIRETAMENTE na qualidade!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõ†Ô∏è T√©cnicas Essenciais de Prompt Engineering\n\nAgora vamos pro que interessa! As t√©cnicas que v√£o fazer voc√™ virar um **mestre dos prompts**!\n\n### 1. Zero-Shot Prompting\n√â quando voc√™ pede algo sem dar exemplos. Tipo chegar no restaurante e pedir \"me surpreenda\".\n\n### 2. Few-Shot Prompting  \nAqui voc√™ d√° alguns exemplos. √â como mostrar fotos do prato que voc√™ quer antes de pedir.\n\n### 3. Chain-of-Thought (CoT)\nVoc√™ pede para o modelo \"pensar em voz alta\". √â tipo pedir para o GPS te explicar por que escolheu aquela rota.\n\n### 4. Role Prompting\nVoc√™ define um \"papel\" para a IA. \"Voc√™ √© um chef italiano com 30 anos de experi√™ncia...\"\n\n**Dica do Pedro**: Combine essas t√©cnicas! √â como temperos na comida - cada um adiciona um sabor especial! üßÇ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulando diferentes t√©cnicas de prompting\n",
        "def simular_resposta_llm(prompt, tecnica):\n",
        "    \"\"\"Simula respostas de LLM para diferentes t√©cnicas\"\"\"\n",
        "    \n",
        "    respostas_simuladas = {\n",
        "        \"zero_shot\": \"Resposta direta e b√°sica\",\n",
        "        \"few_shot\": \"Resposta seguindo padr√µes dos exemplos\", \n",
        "        \"chain_of_thought\": \"Resposta com racioc√≠nio passo a passo\",\n",
        "        \"role_prompting\": \"Resposta personalizada conforme o papel definido\"\n",
        "    }\n",
        "    \n",
        "    return respostas_simuladas.get(tecnica, \"T√©cnica n√£o reconhecida\")\n",
        "\n",
        "# Exemplos pr√°ticos de cada t√©cnica\n",
        "exemplos_tecnicas = {\n",
        "    \"Zero-Shot\": {\n",
        "        \"prompt\": \"Traduza para ingl√™s: Bom dia!\",\n",
        "        \"qualidade\": 6\n",
        "    },\n",
        "    \"Few-Shot\": {\n",
        "        \"prompt\": \"Traduza para ingl√™s:\\nOl√° -> Hello\\nObrigado -> Thank you\\nBom dia -> ?\",\n",
        "        \"qualidade\": 8\n",
        "    },\n",
        "    \"Chain-of-Thought\": {\n",
        "        \"prompt\": \"Pense passo a passo e traduza 'Bom dia' para ingl√™s. Primeiro, identifique o significado, depois encontre o equivalente.\",\n",
        "        \"qualidade\": 9\n",
        "    },\n",
        "    \"Role + CoT\": {\n",
        "        \"prompt\": \"Voc√™ √© um tradutor profissional. Explique seu processo de tradu√ß√£o e traduza 'Bom dia' para ingl√™s.\",\n",
        "        \"qualidade\": 10\n",
        "    }\n",
        "}\n",
        "\n",
        "# Visualizando a efic√°cia das t√©cnicas\n",
        "tecnicas = list(exemplos_tecnicas.keys())\n",
        "qualidades = [exemplos_tecnicas[t][\"qualidade\"] for t in tecnicas]\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "colors = ['lightcoral', 'lightsalmon', 'lightblue', 'lightgreen']\n",
        "bars = plt.bar(tecnicas, qualidades, color=colors)\n",
        "plt.title('Efic√°cia das T√©cnicas de Prompting', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Score de Qualidade')\n",
        "plt.ylim(0, 11)\n",
        "\n",
        "for bar, score in zip(bars, qualidades):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
        "             str(score), ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Gr√°fico de complexidade vs resultado\n",
        "plt.subplot(2, 1, 2)\n",
        "complexidade = [2, 4, 7, 9]\n",
        "plt.scatter(complexidade, qualidades, s=200, c=colors, alpha=0.7)\n",
        "plt.plot(complexidade, qualidades, 'k--', alpha=0.5)\n",
        "\n",
        "for i, txt in enumerate(tecnicas):\n",
        "    plt.annotate(txt, (complexidade[i], qualidades[i]), \n",
        "                xytext=(5, 5), textcoords='offset points')\n",
        "\n",
        "plt.xlabel('Complexidade do Prompt')\n",
        "plt.ylabel('Qualidade da Resposta')\n",
        "plt.title('Rela√ß√£o: Complexidade vs Qualidade')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üéØ Moral da hist√≥ria: Mais estrutura = Melhores resultados!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé≠ Role Prompting na Pr√°tica\n\nAgora vamos mergulhar numa das t√©cnicas mais poderosas: o **Role Prompting**!\n\n√â como dar uma \"personalidade profissional\" para a IA. Lembra dos **tipos de modelos** que vimos no M√≥dulo 6? Cada um tem suas caracter√≠sticas, mas com Role Prompting voc√™ pode \"moldar\" o comportamento!\n\n### Por que funciona?\n\nOs LLMs foram treinados com milh√µes de textos (lembra do **pr√©-treinamento** do M√≥dulo 7?). Eles \"conhecem\" como diferentes profissionais se comunicam!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introdu√ß√£o-√†-llms-modulo-08_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Biblioteca de roles para diferentes contextos\n",
        "roles_library = {\n",
        "    \"professor\": {\n",
        "        \"prompt\": \"Voc√™ √© um professor experiente e did√°tico. Explique conceitos complexos de forma simples, use analogias e sempre verifique se o aluno entendeu.\",\n",
        "        \"caracteristicas\": [\"Did√°tico\", \"Paciente\", \"Usa analogias\", \"Confirma entendimento\"]\n",
        "    },\n",
        "    \"consultor\": {\n",
        "        \"prompt\": \"Voc√™ √© um consultor s√™nior de neg√≥cios. Analise problemas estrategicamente, apresente solu√ß√µes pr√°ticas e sempre considere ROI e viabilidade.\",\n",
        "        \"caracteristicas\": [\"Estrat√©gico\", \"Pr√°tico\", \"Foca em resultados\", \"Anal√≠tico\"]\n",
        "    },\n",
        "    \"desenvolvedor\": {\n",
        "        \"prompt\": \"Voc√™ √© um desenvolvedor s√™nior com 10+ anos de experi√™ncia. Escreva c√≥digo limpo, comente bem e sempre considere boas pr√°ticas e performance.\",\n",
        "        \"caracteristicas\": [\"T√©cnico\", \"Detalhista\", \"Segue padr√µes\", \"Performance-oriented\"]\n",
        "    },\n",
        "    \"criativo\": {\n",
        "        \"prompt\": \"Voc√™ √© um diretor criativo premiado. Pense fora da caixa, use refer√™ncias culturais e sempre busque solu√ß√µes inovadoras e impactantes.\",\n",
        "        \"caracteristicas\": [\"Inovador\", \"Cultural\", \"Impactante\", \"N√£o-convencional\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "def construir_prompt_com_role(role, tarefa, contexto=\"\"):\n",
        "    \"\"\"Constr√≥i um prompt estruturado com role definido\"\"\"\n",
        "    \n",
        "    if role not in roles_library:\n",
        "        return f\"Role '{role}' n√£o encontrado na biblioteca!\"\n",
        "    \n",
        "    role_prompt = roles_library[role][\"prompt\"]\n",
        "    \n",
        "    prompt_final = f\"\"\"\n",
        "ROLE: {role_prompt}\n",
        "\n",
        "CONTEXTO: {contexto if contexto else 'Contexto geral de trabalho.'}\n",
        "\n",
        "TAREFA: {tarefa}\n",
        "\n",
        "INSTRU√á√ïES ADICIONAIS:\n",
        "- Mantenha o tom profissional mas acess√≠vel\n",
        "- Use exemplos pr√°ticos quando poss√≠vel\n",
        "- Seja espec√≠fico e acion√°vel\n",
        "\"\"\"\n",
        "    \n",
        "    return prompt_final.strip()\n",
        "\n",
        "# Testando a fun√ß√£o\n",
        "exemplo_tarefa = \"Explique o conceito de Machine Learning\"\n",
        "exemplo_contexto = \"Para uma equipe de marketing que quer entender como usar ML em campanhas\"\n",
        "\n",
        "prompt_professor = construir_prompt_com_role(\"professor\", exemplo_tarefa, exemplo_contexto)\n",
        "prompt_consultor = construir_prompt_com_role(\"consultor\", exemplo_tarefa, exemplo_contexto)\n",
        "\n",
        "print(\"üé≠ EXEMPLO - Prompt com Role de Professor:\")\n",
        "print(\"=\" * 50)\n",
        "print(prompt_professor)\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"\\nüéØ Viu como o mesmo pedido fica completamente diferente com roles espec√≠ficos?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† Chain-of-Thought: Ensinando a IA a Pensar\n\nT√°, mas o que √© esse tal de Chain-of-Thought? √â literalmente ensinar a IA a \"mostrar o racioc√≠nio\"!\n\nImagine que voc√™ t√° resolvendo uma equa√ß√£o matem√°tica. Em vez de s√≥ dar a resposta, voc√™ mostra:\n1. \"Primeiro eu fa√ßo isso...\"\n2. \"Depois eu calculo aquilo...\"\n3. \"Por fim chego na resposta...\"\n\n### Por que isso funciona?\n\nLembra da **arquitetura Transformer** do M√≥dulo 3? O mecanismo de **aten√ß√£o** permite que o modelo \"conecte\" diferentes partes do texto. Quando pedimos para \"pensar passo a passo\", criamos mais conex√µes!\n\n### Tipos de CoT:\n- **Manual**: Voc√™ escreve os passos\n- **Autom√°tico**: \"Pense passo a passo\"\n- **Com exemplos**: Mostra como fazer primeiro\n\n**Dica do Pedro**: CoT √© especialmente poderoso para problemas de l√≥gica, matem√°tica e an√°lise! üßÆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrando Chain-of-Thought na pr√°tica\n",
        "def criar_prompt_cot(problema, tipo=\"automatico\", exemplos=None):\n",
        "    \"\"\"Cria prompts usando Chain-of-Thought\"\"\"\n",
        "    \n",
        "    if tipo == \"automatico\":\n",
        "        return f\"\"\"\n",
        "Resolva o seguinte problema passo a passo:\n",
        "\n",
        "{problema}\n",
        "\n",
        "Pense passo a passo e explique seu racioc√≠nio antes de dar a resposta final.\n",
        "\"\"\".strip()\n",
        "    \n",
        "    elif tipo == \"manual\":\n",
        "        return f\"\"\"\n",
        "Para resolver este problema, siga estes passos:\n",
        "\n",
        "Problema: {problema}\n",
        "\n",
        "Passo 1: Identifique as informa√ß√µes importantes\n",
        "Passo 2: Determine que c√°lculos/an√°lises s√£o necess√°rios\n",
        "Passo 3: Execute os c√°lculos\n",
        "Passo 4: Verifique se a resposta faz sentido\n",
        "Passo 5: Apresente a resposta final\n",
        "\"\"\".strip()\n",
        "    \n",
        "    elif tipo == \"com_exemplos\" and exemplos:\n",
        "        exemplo_texto = \"\\n\".join([f\"Exemplo {i+1}: {ex}\" for i, ex in enumerate(exemplos)])\n",
        "        return f\"\"\"\n",
        "Veja como resolver problemas similares:\n",
        "\n",
        "{exemplo_texto}\n",
        "\n",
        "Agora resolva seguindo o mesmo racioc√≠nio:\n",
        "{problema}\n",
        "\"\"\".strip()\n",
        "    \n",
        "    return \"Tipo de CoT n√£o reconhecido!\"\n",
        "\n",
        "# Comparando efic√°cia do CoT\n",
        "problema_exemplo = \"Uma empresa tem 150 funcion√°rios. 60% trabalham remotamente e 25% dos remotos s√£o desenvolvedores. Quantos desenvolvedores remotos h√° na empresa?\"\n",
        "\n",
        "# Simulando accuracy para diferentes abordagens\n",
        "abordagens = {\n",
        "    \"Sem CoT\": 65,\n",
        "    \"CoT Autom√°tico\": 85,\n",
        "    \"CoT Manual\": 90,\n",
        "    \"CoT + Exemplos\": 95\n",
        "}\n",
        "\n",
        "# Visualiza√ß√£o comparativa\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Gr√°fico de barras\n",
        "bars = ax1.bar(abordagens.keys(), abordagens.values(), \n",
        "               color=['red', 'orange', 'lightblue', 'green'])\n",
        "ax1.set_title('Accuracy por Tipo de Prompt', fontweight='bold')\n",
        "ax1.set_ylabel('Accuracy (%)')\n",
        "ax1.set_ylim(0, 100)\n",
        "\n",
        "for bar, acc in zip(bars, abordagens.values()):\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
        "             f'{acc}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Gr√°fico de linha mostrando evolu√ß√£o\n",
        "x_pos = range(len(abordagens))\n",
        "ax2.plot(x_pos, list(abordagens.values()), 'bo-', linewidth=2, markersize=8)\n",
        "ax2.set_xticks(x_pos)\n",
        "ax2.set_xticklabels(abordagens.keys(), rotation=45)\n",
        "ax2.set_title('Evolu√ß√£o da Performance', fontweight='bold')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_ylim(60, 100)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Mostrando exemplo de CoT\n",
        "print(\"üß† EXEMPLO DE CHAIN-OF-THOUGHT:\")\n",
        "print(\"=\" * 60)\n",
        "cot_exemplo = criar_prompt_cot(problema_exemplo, \"manual\")\n",
        "print(cot_exemplo)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üéØ O CoT for√ßa o modelo a ser mais met√≥dico e preciso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé® Few-Shot Learning: Aprendendo com Exemplos\n\nAgora vamos falar de uma das t√©cnicas mais poderosas: **Few-Shot Learning**!\n\n√â como ensinar algu√©m a fazer um prato novo mostrando algumas receitas parecidas primeiro. O modelo \"pega o padr√£o\" e aplica no seu caso!\n\n### Como funciona?\n\nLembra das **embeddings** do M√≥dulo 5? O modelo cria representa√ß√µes dos seus exemplos e usa essas representa√ß√µes para entender o que voc√™ quer!\n\n### Estrutura do Few-Shot:\n```\nExemplo 1: Input ‚Üí Output\nExemplo 2: Input ‚Üí Output  \nExemplo 3: Input ‚Üí Output\nSeu caso: Input ‚Üí ?\n```\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introdu√ß√£o-√†-llms-modulo-08_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Construtor de prompts Few-Shot\n",
        "class FewShotBuilder:\n",
        "    def __init__(self, task_description=\"\"):\n",
        "        self.task_description = task_description\n",
        "        self.examples = []\n",
        "        \n",
        "    def add_example(self, input_text, output_text, explanation=\"\"):\n",
        "        \"\"\"Adiciona um exemplo ao prompt\"\"\"\n",
        "        self.examples.append({\n",
        "            'input': input_text,\n",
        "            'output': output_text,\n",
        "            'explanation': explanation\n",
        "        })\n",
        "        \n",
        "    def build_prompt(self, new_input):\n",
        "        \"\"\"Constr√≥i o prompt final com todos os exemplos\"\"\"\n",
        "        prompt = f\"{self.task_description}\\n\\n\" if self.task_description else \"\"\n",
        "        \n",
        "        # Adiciona exemplos\n",
        "        for i, example in enumerate(self.examples, 1):\n",
        "            prompt += f\"Exemplo {i}:\\n\"\n",
        "            prompt += f\"Input: {example['input']}\\n\"\n",
        "            prompt += f\"Output: {example['output']}\\n\"\n",
        "            if example['explanation']:\n",
        "                prompt += f\"Explica√ß√£o: {example['explanation']}\\n\"\n",
        "            prompt += \"\\n\"\n",
        "        \n",
        "        # Adiciona o caso novo\n",
        "        prompt += f\"Agora fa√ßa o mesmo para:\\n\"\n",
        "        prompt += f\"Input: {new_input}\\n\"\n",
        "        prompt += f\"Output:\"\n",
        "        \n",
        "        return prompt\n",
        "    \n",
        "    def get_stats(self):\n",
        "        \"\"\"Retorna estat√≠sticas dos exemplos\"\"\"\n",
        "        if not self.examples:\n",
        "            return \"Nenhum exemplo adicionado ainda!\"\n",
        "        \n",
        "        return {\n",
        "            'num_examples': len(self.examples),\n",
        "            'avg_input_length': np.mean([len(ex['input']) for ex in self.examples]),\n",
        "            'avg_output_length': np.mean([len(ex['output']) for ex in self.examples]),\n",
        "            'has_explanations': sum(1 for ex in self.examples if ex['explanation']) > 0\n",
        "        }\n",
        "\n",
        "# Exemplo pr√°tico: Classifica√ß√£o de sentimentos\n",
        "sentiment_builder = FewShotBuilder(\n",
        "    \"Classifique o sentimento das frases como: POSITIVO, NEGATIVO ou NEUTRO\"\n",
        ")\n",
        "\n",
        "# Adicionando exemplos\n",
        "sentiment_builder.add_example(\n",
        "    \"Adorei o filme, muito emocionante!\", \n",
        "    \"POSITIVO\",\n",
        "    \"Palavras como 'adorei' e 'emocionante' indicam sentimento positivo\"\n",
        ")\n",
        "\n",
        "sentiment_builder.add_example(\n",
        "    \"O restaurante estava terr√≠vel, comida fria.\", \n",
        "    \"NEGATIVO\",\n",
        "    \"'Terr√≠vel' e 'fria' s√£o indicadores negativos\"\n",
        ")\n",
        "\n",
        "sentiment_builder.add_example(\n",
        "    \"O evento acontece √†s 14h.\", \n",
        "    \"NEUTRO\",\n",
        "    \"Informa√ß√£o factual sem carga emocional\"\n",
        ")\n",
        "\n",
        "# Testando com nova frase\n",
        "nova_frase = \"A pizza estava deliciosa, recomendo!\"\n",
        "prompt_final = sentiment_builder.build_prompt(nova_frase)\n",
        "\n",
        "print(\"üéØ EXEMPLO DE FEW-SHOT PROMPT:\")\n",
        "print(\"=\" * 70)\n",
        "print(prompt_final)\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "# Estat√≠sticas\n",
        "stats = sentiment_builder.get_stats()\n",
        "print(f\"\\nüìä ESTAT√çSTICAS DOS EXEMPLOS:\")\n",
        "print(f\"N√∫mero de exemplos: {stats['num_examples']}\")\n",
        "print(f\"Tamanho m√©dio do input: {stats['avg_input_length']:.1f} caracteres\")\n",
        "print(f\"Tamanho m√©dio do output: {stats['avg_output_length']:.1f} caracteres\")\n",
        "print(f\"Tem explica√ß√µes: {'Sim' if stats['has_explanations'] else 'N√£o'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Fluxo Completo de Prompt Engineering\n\nAgora vamos juntar tudo que aprendemos num **fluxo completo**! √â como uma linha de produ√ß√£o de prompts de alta qualidade!\n\n### O Processo Pedro Guth de Prompt Engineering:\n\n1. **Definir Objetivo** ‚Üí O que eu quero?\n2. **Escolher T√©cnica** ‚Üí Zero-shot, Few-shot, CoT?\n3. **Definir Role** ‚Üí Quem √© o \"especialista\"?\n4. **Estruturar Prompt** ‚Üí Contexto + Tarefa + Formato\n5. **Testar e Iterar** ‚Üí Sempre pode melhorar!\n\n**Dica do Pedro**: Prompt Engineering √© iterativo! O primeiro nunca √© o melhor - √© como fazer um a√ßa√≠, voc√™ vai ajustando at√© ficar perfeito! üçπ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando o fluxo completo\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Criando um diagrama do processo\n",
        "processo_steps = [\n",
        "    \"Definir Objetivo\",\n",
        "    \"Escolher T√©cnica\", \n",
        "    \"Definir Role\",\n",
        "    \"Estruturar Prompt\",\n",
        "    \"Testar & Iterar\"\n",
        "]\n",
        "\n",
        "# Simulando m√©tricas de melhoria por itera√ß√£o\n",
        "iteracoes = range(1, 6)\n",
        "qualidade = [4, 6, 7.5, 8.5, 9.2]\n",
        "tempo_gasto = [5, 10, 15, 20, 25]  # minutos\n",
        "satisfacao = [40, 60, 75, 85, 92]\n",
        "\n",
        "# Gr√°fico do processo de melhoria\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Gr√°fico 1: Evolu√ß√£o da qualidade\n",
        "ax1.plot(iteracoes, qualidade, 'bo-', linewidth=3, markersize=8)\n",
        "ax1.set_title('Evolu√ß√£o da Qualidade por Itera√ß√£o', fontweight='bold')\n",
        "ax1.set_xlabel('Itera√ß√£o')\n",
        "ax1.set_ylabel('Score de Qualidade')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim(0, 10)\n",
        "\n",
        "# Gr√°fico 2: Investimento de tempo\n",
        "ax2.bar(iteracoes, tempo_gasto, color='orange', alpha=0.7)\n",
        "ax2.set_title('Tempo Investido por Itera√ß√£o', fontweight='bold')\n",
        "ax2.set_xlabel('Itera√ß√£o')\n",
        "ax2.set_ylabel('Tempo (minutos)')\n",
        "\n",
        "# Gr√°fico 3: ROI (Qualidade vs Tempo)\n",
        "roi = [q/t for q, t in zip(qualidade, tempo_gasto)]\n",
        "ax3.plot(iteracoes, roi, 'go-', linewidth=2, markersize=8)\n",
        "ax3.set_title('ROI: Qualidade por Minuto Investido', fontweight='bold')\n",
        "ax3.set_xlabel('Itera√ß√£o')\n",
        "ax3.set_ylabel('Qualidade/Minuto')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Gr√°fico 4: Satisfa√ß√£o geral\n",
        "colors = ['red', 'orange', 'yellow', 'lightgreen', 'green']\n",
        "bars = ax4.bar(iteracoes, satisfacao, color=colors)\n",
        "ax4.set_title('Satisfa√ß√£o com o Resultado', fontweight='bold')\n",
        "ax4.set_xlabel('Itera√ß√£o')\n",
        "ax4.set_ylabel('Satisfa√ß√£o (%)')\n",
        "ax4.set_ylim(0, 100)\n",
        "\n",
        "for bar, sat in zip(bars, satisfacao):\n",
        "    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
        "             f'{sat}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìà Insights do Processo:\")\n",
        "print(f\"‚Ä¢ Qualidade final: {qualidade[-1]}/10\")\n",
        "print(f\"‚Ä¢ Tempo total investido: {sum(tempo_gasto)} minutos\")\n",
        "print(f\"‚Ä¢ Melhoria total: {qualidade[-1] - qualidade[0]:.1f} pontos\")\n",
        "print(f\"‚Ä¢ ROI da √∫ltima itera√ß√£o: {roi[-1]:.2f} pontos/minuto\")\n",
        "print(\"\\nüéØ Li√ß√£o: Investir tempo em iterar VALE A PENA!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classe completa para Prompt Engineering\n",
        "class PromptEngineer:\n",
        "    def __init__(self):\n",
        "        self.prompt_history = []\n",
        "        self.templates = self._load_templates()\n",
        "    \n",
        "    def _load_templates(self):\n",
        "        return {\n",
        "            \"analise\": {\n",
        "                \"role\": \"Voc√™ √© um analista experiente especializado em {dominio}.\",\n",
        "                \"task\": \"Analise {input} considerando {criterios}.\",\n",
        "                \"format\": \"Apresente sua an√°lise em {formato}.\",\n",
        "                \"constraints\": \"Limite-se a {limite} e foque em {foco}.\"\n",
        "            },\n",
        "            \"criacao\": {\n",
        "                \"role\": \"Voc√™ √© um {profissional} criativo com {experiencia} anos de experi√™ncia.\",\n",
        "                \"task\": \"Crie {produto} para {publico}.\",\n",
        "                \"format\": \"Entregue em formato {formato}.\",\n",
        "                \"constraints\": \"Considere {restricoes}.\"\n",
        "            },\n",
        "            \"educacional\": {\n",
        "                \"role\": \"Voc√™ √© um professor especialista em {materia}.\",\n",
        "                \"task\": \"Ensine {conceito} para {nivel}.\",\n",
        "                \"format\": \"Use {metodo} e exemplos pr√°ticos.\",\n",
        "                \"constraints\": \"Mantenha linguagem {linguagem}.\"\n",
        "            }\n",
        "        }\n",
        "    \n",
        "    def build_prompt(self, template_type, **kwargs):\n",
        "        \"\"\"Constr√≥i prompt usando template\"\"\"\n",
        "        if template_type not in self.templates:\n",
        "            return \"Template n√£o encontrado!\"\n",
        "        \n",
        "        template = self.templates[template_type]\n",
        "        prompt_parts = []\n",
        "        \n",
        "        for section, text in template.items():\n",
        "            try:\n",
        "                formatted_text = text.format(**kwargs)\n",
        "                prompt_parts.append(f\"{section.upper()}: {formatted_text}\")\n",
        "            except KeyError as e:\n",
        "                prompt_parts.append(f\"{section.upper()}: {text} [PAR√ÇMETRO {e} FALTANDO]\")\n",
        "        \n",
        "        final_prompt = \"\\n\\n\".join(prompt_parts)\n",
        "        \n",
        "        # Salva no hist√≥rico\n",
        "        self.prompt_history.append({\n",
        "            'template': template_type,\n",
        "            'params': kwargs,\n",
        "            'prompt': final_prompt,\n",
        "            'timestamp': pd.Timestamp.now()\n",
        "        })\n",
        "        \n",
        "        return final_prompt\n",
        "    \n",
        "    def get_history_stats(self):\n",
        "        \"\"\"Estat√≠sticas do hist√≥rico de prompts\"\"\"\n",
        "        if not self.prompt_history:\n",
        "            return \"Nenhum prompt criado ainda!\"\n",
        "        \n",
        "        df_history = pd.DataFrame(self.prompt_history)\n",
        "        \n",
        "        stats = {\n",
        "            'total_prompts': len(self.prompt_history),\n",
        "            'templates_usados': df_history['template'].nunique(),\n",
        "            'template_mais_usado': df_history['template'].mode()[0],\n",
        "            'tamanho_medio': df_history['prompt'].str.len().mean()\n",
        "        }\n",
        "        \n",
        "        return stats\n",
        "\n",
        "# Testando a classe\n",
        "engineer = PromptEngineer()\n",
        "\n",
        "# Exemplo 1: Prompt educacional\n",
        "prompt_edu = engineer.build_prompt(\n",
        "    \"educacional\",\n",
        "    materia=\"Machine Learning\",\n",
        "    conceito=\"Redes Neurais\",\n",
        "    nivel=\"iniciantes em programa√ß√£o\", \n",
        "    metodo=\"analogias do cotidiano\",\n",
        "    linguagem=\"simples e did√°tica\"\n",
        ")\n",
        "\n",
        "print(\"üéì PROMPT EDUCACIONAL GERADO:\")\n",
        "print(\"=\" * 60)\n",
        "print(prompt_edu)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Exemplo 2: Prompt de an√°lise\n",
        "prompt_analise = engineer.build_prompt(\n",
        "    \"analise\",\n",
        "    dominio=\"marketing digital\",\n",
        "    input=\"os dados de campanha do √∫ltimo trimestre\", \n",
        "    criterios=\"ROI, engajamento e convers√£o\",\n",
        "    formato=\"relat√≥rio executivo com gr√°ficos\",\n",
        "    limite=\"m√°ximo 2 p√°ginas\",\n",
        "    foco=\"insights acion√°veis\"\n",
        ")\n",
        "\n",
        "print(\"\\nüìä PROMPT DE AN√ÅLISE GERADO:\")\n",
        "print(\"=\" * 60)\n",
        "print(prompt_analise)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Estat√≠sticas\n",
        "stats = engineer.get_history_stats()\n",
        "print(f\"\\nüìà ESTAT√çSTICAS:\")\n",
        "for key, value in stats.items():\n",
        "    print(f\"‚Ä¢ {key}: {value}\")\n",
        "\n",
        "print(\"\\nüéØ Liiindo! Agora voc√™ tem um sistema completo de Prompt Engineering!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üö® Armadilhas Comuns e Como Evitar\n\nAgora vamos falar das **pegadinhas** que todo mundo cai no in√≠cio! √â tipo aqueles erros cl√°ssicos que a gente comete quando t√° aprendendo a dirigir.\n\n### As 7 Armadilhas Mortais do Prompting:\n\n1. **Prompt Amb√≠guo** ‚Üí \"Faz um relat√≥rio\" (relat√≥rio de qu√™? como? para quem?)\n2. **Contexto Insuficiente** ‚Üí Esquece de dar background\n3. **Exemplos Ruins** ‚Üí No Few-Shot, usa exemplos inconsistentes\n4. **Sobrecarga de Informa√ß√£o** ‚Üí Prompt gigante que confunde\n5. **N√£o Definir Formato** ‚Üí IA n√£o sabe como estruturar a resposta\n6. **Linguagem T√©cnica Demais** ‚Üí Para tarefas simples\n7. **N√£o Testar Varia√ß√µes** ‚Üí Fica no primeiro prompt que \"funcionou\"\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introdu√ß√£o-√†-llms-modulo-08_img_04.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sistema de valida√ß√£o de prompts\n",
        "class PromptValidator:\n",
        "    def __init__(self):\n",
        "        self.checks = {\n",
        "            'comprimento': self._check_length,\n",
        "            'clareza': self._check_clarity,\n",
        "            'estrutura': self._check_structure,\n",
        "            'contexto': self._check_context,\n",
        "            'formato': self._check_format\n",
        "        }\n",
        "    \n",
        "    def _check_length(self, prompt):\n",
        "        \"\"\"Verifica se o prompt n√£o √© muito longo nem muito curto\"\"\"\n",
        "        length = len(prompt)\n",
        "        if length < 20:\n",
        "            return {'score': 2, 'msg': 'Prompt muito curto - falta contexto'}\n",
        "        elif length > 2000:\n",
        "            return {'score': 4, 'msg': 'Prompt muito longo - pode confundir'}\n",
        "        else:\n",
        "            return {'score': 8, 'msg': 'Comprimento adequado'}\n",
        "    \n",
        "    def _check_clarity(self, prompt):\n",
        "        \"\"\"Verifica clareza do prompt\"\"\"\n",
        "        ambiguous_words = ['alguma coisa', 'isso', 'aquilo', 'algo', 'faz a√≠']\n",
        "        found_ambiguous = [word for word in ambiguous_words if word.lower() in prompt.lower()]\n",
        "        \n",
        "        if found_ambiguous:\n",
        "            return {'score': 3, 'msg': f'Palavras amb√≠guas encontradas: {\", \".join(found_ambiguous)}'}\n",
        "        else:\n",
        "            return {'score': 9, 'msg': 'Linguagem clara e espec√≠fica'}\n",
        "    \n",
        "    def _check_structure(self, prompt):\n",
        "        \"\"\"Verifica se tem estrutura clara\"\"\"\n",
        "        structure_indicators = ['contexto:', 'tarefa:', 'formato:', 'voc√™ √©', 'objetivo:']\n",
        "        found_indicators = sum(1 for indicator in structure_indicators \n",
        "                              if indicator.lower() in prompt.lower())\n",
        "        \n",
        "        if found_indicators >= 2:\n",
        "            return {'score': 9, 'msg': 'Boa estrutura identificada'}\n",
        "        elif found_indicators == 1:\n",
        "            return {'score': 6, 'msg': 'Estrutura parcial - pode melhorar'}\n",
        "        else:\n",
        "            return {'score': 4, 'msg': 'Falta estrutura clara'}\n",
        "    \n",
        "    def _check_context(self, prompt):\n",
        "        \"\"\"Verifica se h√° contexto suficiente\"\"\"\n",
        "        context_words = ['porque', 'para', 'considerando', 'dado que', 'contexto']\n",
        "        has_context = any(word.lower() in prompt.lower() for word in context_words)\n",
        "        \n",
        "        if has_context:\n",
        "            return {'score': 8, 'msg': 'Contexto presente'}\n",
        "        else:\n",
        "            return {'score': 5, 'msg': 'Pode adicionar mais contexto'}\n",
        "    \n",
        "    def _check_format(self, prompt):\n",
        "        \"\"\"Verifica se especifica formato de sa√≠da\"\"\"\n",
        "        format_words = ['formato', 'lista', 'tabela', 'json', 'markdown', 'estruture', 'organize']\n",
        "        has_format = any(word.lower() in prompt.lower() for word in format_words)\n",
        "        \n",
        "        if has_format:\n",
        "            return {'score': 8, 'msg': 'Formato de sa√≠da especificado'}\n",
        "        else:\n",
        "            return {'score': 6, 'msg': 'Considere especificar formato de sa√≠da'}\n",
        "    \n",
        "    def validate(self, prompt):\n",
        "        \"\"\"Executa todas as valida√ß√µes\"\"\"\n",
        "        results = {}\n",
        "        total_score = 0\n",
        "        \n",
        "        for check_name, check_func in self.checks.items():\n",
        "            result = check_func(prompt)\n",
        "            results[check_name] = result\n",
        "            total_score += result['score']\n",
        "        \n",
        "        # Score final (0-10)\n",
        "        final_score = total_score / len(self.checks)\n",
        "        \n",
        "        # Classifica√ß√£o\n",
        "        if final_score >= 8:\n",
        "            classification = \"EXCELENTE üåü\"\n",
        "        elif final_score >= 6:\n",
        "            classification = \"BOM üëç\"\n",
        "        elif final_score >= 4:\n",
        "            classification = \"M√âDIO ‚ö†Ô∏è\"\n",
        "        else:\n",
        "            classification = \"PRECISA MELHORAR ‚ùå\"\n",
        "        \n",
        "        return {\n",
        "            'score': final_score,\n",
        "            'classification': classification,\n",
        "            'details': results,\n",
        "            'prompt_length': len(prompt)\n",
        "        }\n",
        "\n",
        "# Testando prompts bons e ruins\n",
        "validator = PromptValidator()\n",
        "\n",
        "# Prompt ruim\n",
        "prompt_ruim = \"Faz um relat√≥rio\"\n",
        "\n",
        "# Prompt bom\n",
        "prompt_bom = \"\"\"Contexto: Voc√™ √© um analista de dados experiente trabalhando para uma empresa de e-commerce.\n",
        "\n",
        "Tarefa: Analise os dados de vendas do √∫ltimo trimestre e identifique tend√™ncias, oportunidades e riscos.\n",
        "\n",
        "Formato: Estruture sua an√°lise em:\n",
        "1. Resumo executivo (3 linhas)\n",
        "2. Principais insights (lista com 5 pontos)\n",
        "3. Recomenda√ß√µes acion√°veis (3 a√ß√µes priorit√°rias)\n",
        "\n",
        "Considera√ß√µes: Foque em dados que impactem diretamente a receita e mantenha linguagem executiva.\"\"\"\n",
        "\n",
        "# Validando ambos\n",
        "resultado_ruim = validator.validate(prompt_ruim)\n",
        "resultado_bom = validator.validate(prompt_bom)\n",
        "\n",
        "# Visualizando compara√ß√£o\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
        "\n",
        "# Gr√°fico radar para prompt ruim\n",
        "categories = list(resultado_ruim['details'].keys())\n",
        "scores_ruim = [resultado_ruim['details'][cat]['score'] for cat in categories]\n",
        "scores_bom = [resultado_bom['details'][cat]['score'] for cat in categories]\n",
        "\n",
        "# Gr√°fico de barras comparativo\n",
        "x_pos = np.arange(len(categories))\n",
        "width = 0.35\n",
        "\n",
        "ax1.bar(x_pos - width/2, scores_ruim, width, label='Prompt Ruim', color='red', alpha=0.7)\n",
        "ax1.bar(x_pos + width/2, scores_bom, width, label='Prompt Bom', color='green', alpha=0.7)\n",
        "\n",
        "ax1.set_xlabel('Crit√©rios de Avalia√ß√£o')\n",
        "ax1.set_ylabel('Score (0-10)')\n",
        "ax1.set_title('Compara√ß√£o: Prompt Ruim vs Bom')\n",
        "ax1.set_xticks(x_pos)\n",
        "ax1.set_xticklabels(categories, rotation=45)\n",
        "ax1.legend()\n",
        "ax1.set_ylim(0, 10)\n",
        "\n",
        "# Score final\n",
        "ax2.bar(['Prompt Ruim', 'Prompt Bom'], \n",
        "        [resultado_ruim['score'], resultado_bom['score']], \n",
        "        color=['red', 'green'], alpha=0.7)\n",
        "ax2.set_ylabel('Score Final')\n",
        "ax2.set_title('Avalia√ß√£o Geral')\n",
        "ax2.set_ylim(0, 10)\n",
        "\n",
        "# Adicionando scores nas barras\n",
        "ax2.text(0, resultado_ruim['score'] + 0.1, f\"{resultado_ruim['score']:.1f}\", \n",
        "         ha='center', va='bottom', fontweight='bold')\n",
        "ax2.text(1, resultado_bom['score'] + 0.1, f\"{resultado_bom['score']:.1f}\", \n",
        "         ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üîç RELAT√ìRIO DE VALIDA√á√ÉO:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Prompt Ruim: {resultado_ruim['score']:.1f}/10 - {resultado_ruim['classification']}\")\n",
        "print(f\"Prompt Bom: {resultado_bom['score']:.1f}/10 - {resultado_bom['classification']}\")\n",
        "print(\"\\nüéØ A diferen√ßa √© gritante! Estrutura importa MUITO!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exerc√≠cio Pr√°tico: Criando Prompts Profissionais\n\nBora colocar a m√£o na massa! Chegou a hora de voc√™ criar seus pr√≥prios prompts profissionais!\n\n### Desafio 1: Prompt para An√°lise de Dados\n\n**Cen√°rio**: Voc√™ trabalha numa startup de delivery e precisa analisar dados de pedidos para identificar padr√µes de comportamento dos clientes.\n\n**Sua miss√£o**: Criar um prompt que combine:\n- Role prompting (definir expertise)\n- Chain-of-thought (processo de an√°lise)\n- Formato espec√≠fico de sa√≠da\n\n**Dica do Pedro**: Lembre-se do que aprendemos sobre **tokens** (M√≥dulo 4) - seja espec√≠fico mas conciso!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO 1: Complete o prompt abaixo\n",
        "def criar_prompt_analise_dados():\n",
        "    \"\"\"\n",
        "    Crie um prompt profissional para an√°lise de dados de delivery\n",
        "    \n",
        "    Deve incluir:\n",
        "    - Role (quem √© o analista)\n",
        "    - Contexto (sobre a startup)\n",
        "    - Tarefa espec√≠fica\n",
        "    - Metodologia (chain-of-thought)\n",
        "    - Formato de sa√≠da\n",
        "    \"\"\"\n",
        "    \n",
        "    # SEU C√ìDIGO AQUI!\n",
        "    prompt = \"\"\"\n",
        "    # Complete este prompt seguindo as boas pr√°ticas que aprendemos\n",
        "    \n",
        "    ROLE: \n",
        "    \n",
        "    CONTEXTO:\n",
        "    \n",
        "    TAREFA:\n",
        "    \n",
        "    METODOLOGIA:\n",
        "    \n",
        "    FORMATO DE SA√çDA:\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    return prompt.strip()\n",
        "\n",
        "# Teste seu prompt\n",
        "meu_prompt = criar_prompt_analise_dados()\n",
        "print(\"üéØ SEU PROMPT:\")\n",
        "print(\"=\" * 50)\n",
        "print(meu_prompt)\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "\n",
        "# Valida√ß√£o autom√°tica\n",
        "validator = PromptValidator()\n",
        "resultado = validator.validate(meu_prompt)\n",
        "\n",
        "print(f\"\\nüìä AVALIA√á√ÉO: {resultado['score']:.1f}/10 - {resultado['classification']}\")\n",
        "\n",
        "print(\"\\nüîç DETALHES:\")\n",
        "for criterio, info in resultado['details'].items():\n",
        "    print(f\"‚Ä¢ {criterio.title()}: {info['score']}/10 - {info['msg']}\")\n",
        "\n",
        "# Dicas para melhoria\n",
        "if resultado['score'] < 7:\n",
        "    print(\"\\nüí° DICAS PARA MELHORAR:\")\n",
        "    print(\"‚Ä¢ Adicione mais contexto sobre a empresa\")\n",
        "    print(\"‚Ä¢ Especifique o formato de sa√≠da (lista, tabela, etc.)\")\n",
        "    print(\"‚Ä¢ Defina claramente o papel do analista\")\n",
        "    print(\"‚Ä¢ Use Chain-of-Thought ('analise passo a passo')\")\n",
        "else:\n",
        "    print(\"\\nüåü Parab√©ns! Seu prompt est√° no n√≠vel profissional!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèÜ Exerc√≠cio Avan√ßado: Few-Shot para Classifica√ß√£o\n\nAgora um desafio mais avan√ßado! Vamos criar um sistema de **classifica√ß√£o de feedback** usando Few-Shot Learning.\n\n### Desafio 2: Sistema de Classifica√ß√£o de Reviews\n\n**Cen√°rio**: Voc√™ precisa classificar reviews de um app em categorias: ELOGIO, RECLAMA√á√ÉO, SUGEST√ÉO, BUG.\n\n**Sua miss√£o**: \n1. Criar exemplos de Few-Shot para cada categoria\n2. Estruturar um prompt que ensine o padr√£o\n3. Testar com novos casos\n\n**Conex√£o com o curso**: Isso prepara voc√™s para o **M√≥dulo 9 - Avalia√ß√£o de Modelos**, onde vamos medir a performance desses sistemas!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO 2: Sistema de Classifica√ß√£o Few-Shot\n",
        "class ReviewClassifier:\n",
        "    def __init__(self):\n",
        "        self.categories = ['ELOGIO', 'RECLAMA√á√ÉO', 'SUGEST√ÉO', 'BUG']\n",
        "        self.examples = []\n",
        "    \n",
        "    def add_example(self, review_text, category, explanation=\"\"):\n",
        "        \"\"\"Adiciona exemplo para Few-Shot Learning\"\"\"\n",
        "        if category not in self.categories:\n",
        "            print(f\"Categoria {category} n√£o √© v√°lida!\")\n",
        "            return False\n",
        "        \n",
        "        self.examples.append({\n",
        "            'text': review_text,\n",
        "            'category': category,\n",
        "            'explanation': explanation\n",
        "        })\n",
        "        return True\n",
        "    \n",
        "    def build_classification_prompt(self, new_review):\n",
        "        \"\"\"Constr√≥i prompt Few-Shot para classifica√ß√£o\"\"\"\n",
        "        \n",
        "        # SEU C√ìDIGO AQUI!\n",
        "        # Construa um prompt que:\n",
        "        # 1. Explique a tarefa\n",
        "        # 2. Liste as categorias\n",
        "        # 3. Mostre os exemplos\n",
        "        # 4. Pe√ßa para classificar o novo review\n",
        "        \n",
        "        prompt = f\"\"\"\n",
        "        # Complete este prompt Few-Shot\n",
        "        \n",
        "        TAREFA: \n",
        "        \n",
        "        CATEGORIAS:\n",
        "        \n",
        "        EXEMPLOS:\n",
        "        \n",
        "        \n",
        "        NOVO REVIEW PARA CLASSIFICAR:\n",
        "        \"{new_review}\"\n",
        "        \n",
        "        CLASSIFICA√á√ÉO:\n",
        "        \"\"\"\n",
        "        \n",
        "        return prompt.strip()\n",
        "\n",
        "# Configure o classificador\n",
        "classifier = ReviewClassifier()\n",
        "\n",
        "# ADICIONE SEUS EXEMPLOS AQUI!\n",
        "# Dica: Crie pelo menos 1 exemplo para cada categoria\n",
        "\n",
        "# Exemplo de ELOGIO\n",
        "classifier.add_example(\n",
        "    \"App perfeito! Interface linda e muito f√°cil de usar. Parab√©ns!\",\n",
        "    \"ELOGIO\",\n",
        "    \"Express√µes positivas como 'perfeito', 'linda' indicam satisfa√ß√£o\"\n",
        ")\n",
        "\n",
        "# ADICIONE MAIS EXEMPLOS:\n",
        "# - Um exemplo de RECLAMA√á√ÉO\n",
        "# - Um exemplo de SUGEST√ÉO  \n",
        "# - Um exemplo de BUG\n",
        "\n",
        "# Teste com um novo review\n",
        "novo_review = \"O app trava toda vez que tento fazer login. Muito frustrante!\"\n",
        "\n",
        "prompt_final = classifier.build_classification_prompt(novo_review)\n",
        "\n",
        "print(\"üéØ SEU PROMPT FEW-SHOT:\")\n",
        "print(\"=\" * 60)\n",
        "print(prompt_final)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Estat√≠sticas\n",
        "print(f\"\\nüìä ESTAT√çSTICAS:\")\n",
        "print(f\"‚Ä¢ Total de exemplos: {len(classifier.examples)}\")\n",
        "print(f\"‚Ä¢ Categorias com exemplos: {len(set(ex['category'] for ex in classifier.examples))}\")\n",
        "print(f\"‚Ä¢ Tamanho do prompt: {len(prompt_final)} caracteres\")\n",
        "\n",
        "# Valida√ß√£o\n",
        "if len(classifier.examples) >= 4:\n",
        "    print(\"\\n‚úÖ Parab√©ns! Voc√™ criou um sistema Few-Shot completo!\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  Adicione mais {4 - len(classifier.examples)} exemplos para completar!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÆ Prompting Avan√ßado: Preparando para o Futuro\n\nAgora vamos falar de t√©cnicas mais avan√ßadas que voc√™s v√£o usar em projetos reais!\n\n### T√©cnicas Avan√ßadas:\n\n1. **Multi-Modal Prompting** ‚Üí Texto + Imagem + C√≥digo\n2. **Prompt Chaining** ‚Üí Um prompt alimenta o outro\n3. **Dynamic Prompting** ‚Üí Prompt se adapta baseado na resposta\n4. **Meta-Prompting** ‚Üí Prompts que geram prompts\n\n### Preparando para os Pr√≥ximos M√≥dulos:\n\n- **M√≥dulo 9 (Avalia√ß√£o)**: Como medir se seus prompts est√£o funcionando?\n- **M√≥dulo 10 (Seguran√ßa)**: Como evitar que prompts sejam \"hackeados\"?\n- **M√≥dulo 11 (Limita√ß√µes)**: Quando o prompting n√£o √© suficiente?\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introdu√ß√£o-√†-llms-modulo-08_img_05.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sistema de Prompt Chaining - T√©cnica Avan√ßada\n",
        "class PromptChain:\n",
        "    def __init__(self):\n",
        "        self.chain_steps = []\n",
        "        self.results = []\n",
        "    \n",
        "    def add_step(self, step_name, prompt_template, depends_on=None):\n",
        "        \"\"\"Adiciona um passo na cadeia de prompts\"\"\"\n",
        "        self.chain_steps.append({\n",
        "            'name': step_name,\n",
        "            'prompt': prompt_template,\n",
        "            'depends_on': depends_on,\n",
        "            'completed': False\n",
        "        })\n",
        "    \n",
        "    def execute_chain(self, initial_input):\n",
        "        \"\"\"Executa a cadeia de prompts (simulado)\"\"\"\n",
        "        current_input = initial_input\n",
        "        \n",
        "        for step in self.chain_steps:\n",
        "            # Simula execu√ß√£o do prompt\n",
        "            if step['depends_on'] and self.results:\n",
        "                # Usa resultado do passo anterior\n",
        "                previous_result = self.results[-1]['output']\n",
        "                formatted_prompt = step['prompt'].format(\n",
        "                    input=current_input, \n",
        "                    previous=previous_result\n",
        "                )\n",
        "            else:\n",
        "                formatted_prompt = step['prompt'].format(input=current_input)\n",
        "            \n",
        "            # Simula resposta (em produ√ß√£o, chamaria a API do LLM)\n",
        "            simulated_output = f\"Resultado simulado para {step['name']}\"\n",
        "            \n",
        "            self.results.append({\n",
        "                'step': step['name'],\n",
        "                'prompt': formatted_prompt,\n",
        "                'output': simulated_output\n",
        "            })\n",
        "            \n",
        "            current_input = simulated_output\n",
        "            step['completed'] = True\n",
        "        \n",
        "        return self.results\n",
        "    \n",
        "    def visualize_chain(self):\n",
        "        \"\"\"Visualiza o fluxo da cadeia\"\"\"\n",
        "        print(\"üîó CADEIA DE PROMPTS:\")\n",
        "        print(\"=\" * 50)\n",
        "        \n",
        "        for i, step in enumerate(self.chain_steps, 1):\n",
        "            status = \"‚úÖ\" if step['completed'] else \"‚è≥\"\n",
        "            print(f\"{status} Passo {i}: {step['name']}\")\n",
        "            \n",
        "            if step['depends_on']:\n",
        "                print(f\"   ‚îî‚îÄ Depende de: {step['depends_on']}\")\n",
        "        \n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "\n",
        "# Exemplo: Cadeia para An√°lise de Produto\n",
        "product_chain = PromptChain()\n",
        "\n",
        "# Passo 1: An√°lise inicial\n",
        "product_chain.add_step(\n",
        "    \"an√°lise_inicial\",\n",
        "    \"Analise este produto e identifique suas principais caracter√≠sticas: {input}\"\n",
        ")\n",
        "\n",
        "# Passo 2: Identificar p√∫blico-alvo\n",
        "product_chain.add_step(\n",
        "    \"p√∫blico_alvo\",\n",
        "    \"Com base nesta an√°lise: {previous}, identifique o p√∫blico-alvo ideal\",\n",
        "    depends_on=\"an√°lise_inicial\"\n",
        ")\n",
        "\n",
        "# Passo 3: Estrat√©gia de marketing\n",
        "product_chain.add_step(\n",
        "    \"estrat√©gia_marketing\",\n",
        "    \"Considerando o p√∫blico: {previous}, crie uma estrat√©gia de marketing\",\n",
        "    depends_on=\"p√∫blico_alvo\"\n",
        ")\n",
        "\n",
        "# Passo 4: M√©tricas de sucesso\n",
        "product_chain.add_step(\n",
        "    \"m√©tricas\",\n",
        "    \"Para esta estrat√©gia: {previous}, defina KPIs e m√©tricas de sucesso\",\n",
        "    depends_on=\"estrat√©gia_marketing\"\n",
        ")\n",
        "\n",
        "# Visualizar antes da execu√ß√£o\n",
        "product_chain.visualize_chain()\n",
        "\n",
        "# Executar a cadeia\n",
        "input_produto = \"Smartphone com c√¢mera de 108MP e bateria de 5000mAh\"\n",
        "resultados = product_chain.execute_chain(input_produto)\n",
        "\n",
        "print(\"\\nüöÄ EXECU√á√ÉO COMPLETA:\")\n",
        "product_chain.visualize_chain()\n",
        "\n",
        "# Visualiza√ß√£o do fluxo\n",
        "steps = [r['step'] for r in resultados]\n",
        "complexity = [1, 2, 3, 4]  # Complexidade crescente\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(complexity, range(len(steps)), 'bo-', linewidth=3, markersize=10)\n",
        "\n",
        "for i, (step, comp) in enumerate(zip(steps, complexity)):\n",
        "    plt.annotate(step.replace('_', ' ').title(), \n",
        "                (comp, i), \n",
        "                xytext=(10, 0), \n",
        "                textcoords='offset points',\n",
        "                ha='left',\n",
        "                fontsize=10,\n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.7))\n",
        "\n",
        "plt.xlabel('Complexidade do Processamento')\n",
        "plt.ylabel('Sequ√™ncia dos Passos')\n",
        "plt.title('Fluxo de Prompt Chaining', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüéØ Prompt Chaining permite an√°lises complexas e estruturadas!\")\n",
        "print(\"üí° No M√≥dulo 12 (Projeto Final), voc√™s v√£o usar essa t√©cnica!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Resumo e Pr√≥ximos Passos\n\nLiiindo! Chegamos no final de mais um m√≥dulo √©pico! üéâ\n\n### O que Aprendemos Hoje:\n\n‚úÖ **Fundamentos do Prompting**: A arte de \"conversar\" com IAs  \n‚úÖ **T√©cnicas Essenciais**: Zero-shot, Few-shot, Chain-of-Thought, Role Prompting  \n‚úÖ **Prompt Engineering Profissional**: Estruturas, templates e valida√ß√£o  \n‚úÖ **Armadilhas Comuns**: Como evitar os erros mais frequentes  \n‚úÖ **T√©cnicas Avan√ßadas**: Prompt Chaining e sistemas complexos  \n\n### Conex√µes com M√≥dulos Anteriores:\n- **Tokens** (M√≥dulo 4) ‚Üí Influenciam como construir prompts eficientes\n- **Embeddings** (M√≥dulo 5) ‚Üí Base para Few-Shot Learning\n- **Arquitetura Transformer** (M√≥dulo 3) ‚Üí Por que Chain-of-Thought funciona\n- **Tipos de Modelos** (M√≥dulo 6) ‚Üí Cada tipo responde diferente a prompts\n\n### Prepara√ß√£o para Pr√≥ximos M√≥dulos:\n- **M√≥dulo 9 - Avalia√ß√£o**: Como medir a qualidade dos seus prompts\n- **M√≥dulo 10 - Seguran√ßa**: Prompt injection e como se proteger\n- **M√≥dulo 12 - Projeto Final**: Aplica√ß√£o pr√°tica de tudo!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introdu√ß√£o-√†-llms-modulo-08_img_06.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dashboard Final - Resumo do seu aprendizado\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Dados do progresso no curso\n",
        "modulos_completos = [\n",
        "    \"Setup Inicial\", \"O que s√£o LLMs\", \"Arquitetura Transformer\", \n",
        "    \"Tokens e Tokeniza√ß√£o\", \"Embeddings\", \"Tipos de Modelos\", \n",
        "    \"Treinamento\", \"Prompting (ATUAL)\"\n",
        "]\n",
        "\n",
        "modulos_futuros = [\n",
        "    \"Avalia√ß√£o\", \"Seguran√ßa\", \"Limita√ß√µes\", \"Projeto Final\", \"T√≥picos Avan√ßados\"\n",
        "]\n",
        "\n",
        "# Habilidades adquiridas neste m√≥dulo\n",
        "habilidades = {\n",
        "    \"Prompt B√°sico\": 9,\n",
        "    \"Few-Shot\": 8,\n",
        "    \"Chain-of-Thought\": 8,\n",
        "    \"Role Prompting\": 9,\n",
        "    \"Valida√ß√£o\": 7,\n",
        "    \"Prompt Chaining\": 6\n",
        "}\n",
        "\n",
        "# Visualiza√ß√£o do progresso\n",
        "fig = plt.figure(figsize=(16, 10))\n",
        "\n",
        "# Subplot 1: Progresso no curso\n",
        "ax1 = plt.subplot(2, 2, 1)\n",
        "total_modulos = len(modulos_completos) + len(modulos_futuros)\n",
        "progresso = len(modulos_completos) / total_modulos * 100\n",
        "\n",
        "# Gr√°fico de pizza do progresso\n",
        "ax1.pie([progresso, 100-progresso], \n",
        "        labels=[f'Completo\\n{len(modulos_completos)}/{total_modulos}', f'Restante\\n{len(modulos_futuros)}'],\n",
        "        colors=['lightgreen', 'lightgray'],\n",
        "        autopct='%1.1f%%',\n",
        "        startangle=90)\n",
        "ax1.set_title('Progresso no Curso', fontweight='bold')\n",
        "\n",
        "# Subplot 2: Habilidades em Prompting\n",
        "ax2 = plt.subplot(2, 2, 2)\n",
        "skills = list(habilidades.keys())\n",
        "scores = list(habilidades.values())\n",
        "colors = plt.cm.RdYlGn([score/10 for score in scores])\n",
        "\n",
        "bars = ax2.barh(skills, scores, color=colors)\n",
        "ax2.set_xlabel('N√≠vel de Dom√≠nio (0-10)')\n",
        "ax2.set_title('Suas Habilidades em Prompting', fontweight='bold')\n",
        "ax2.set_xlim(0, 10)\n",
        "\n",
        "for bar, score in zip(bars, scores):\n",
        "    ax2.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2, \n",
        "             str(score), va='center', fontweight='bold')\n",
        "\n",
        "# Subplot 3: Linha do tempo do curso\n",
        "ax3 = plt.subplot(2, 1, 2)\n",
        "ax3.set_xlim(0, total_modulos + 1)\n",
        "ax3.set_ylim(-0.5, 1.5)\n",
        "\n",
        "# M√≥dulos completos\n",
        "for i, modulo in enumerate(modulos_completos):\n",
        "    color = 'green' if i < len(modulos_completos) - 1 else 'gold'  # Atual em dourado\n",
        "    ax3.scatter(i + 1, 1, s=200, c=color, zorder=3)\n",
        "    ax3.annotate(modulo, (i + 1, 1), xytext=(0, 20), \n",
        "                textcoords='offset points', ha='center', \n",
        "                rotation=45, fontsize=8)\n",
        "\n",
        "# M√≥dulos futuros\n",
        "for i, modulo in enumerate(modulos_futuros):\n",
        "    pos = len(modulos_completos) + i + 1\n",
        "    ax3.scatter(pos, 1, s=200, c='lightgray', zorder=3)\n",
        "    ax3.annotate(modulo, (pos, 1), xytext=(0, 20), \n",
        "                textcoords='offset points', ha='center', \n",
        "                rotation=45, fontsize=8, alpha=0.6)\n",
        "\n",
        "# Linha conectando\n",
        "ax3.plot(range(1, total_modulos + 1), [1] * total_modulos, 'k-', alpha=0.3, zorder=1)\n",
        "\n",
        "ax3.set_title('Jornada no Curso: Introdu√ß√£o √† LLMs', fontweight='bold', fontsize=14)\n",
        "ax3.set_xlabel('M√≥dulos')\n",
        "ax3.set_yticks([])\n",
        "ax3.spines['left'].set_visible(False)\n",
        "ax3.spines['right'].set_visible(False)\n",
        "ax3.spines['top'].set_visible(False)\n",
        "\n",
        "# Adicionando legenda\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [\n",
        "    Patch(facecolor='green', label='M√≥dulos Completos'),\n",
        "    Patch(facecolor='gold', label='M√≥dulo Atual'),\n",
        "    Patch(facecolor='lightgray', label='Pr√≥ximos M√≥dulos')\n",
        "]\n",
        "ax3.legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Mensagem final motivacional\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéØ PARAB√âNS! VOC√ä DOMINOU O PROMPT ENGINEERING!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"‚úÖ Progresso no curso: {progresso:.1f}%\")\n",
        "print(f\"‚úÖ Habilidades desenvolvidas: {len(habilidades)}\")\n",
        "print(f\"‚úÖ Score m√©dio em Prompting: {np.mean(list(habilidades.values())):.1f}/10\")\n",
        "print(\"\\nüöÄ PR√ìXIMOS PASSOS:\")\n",
        "print(\"‚Ä¢ M√≥dulo 9: Aprenda a AVALIAR seus prompts\")\n",
        "print(\"‚Ä¢ M√≥dulo 10: Descubra como proteger seus sistemas\")\n",
        "print(\"‚Ä¢ M√≥dulo 12: Aplique tudo no PROJETO FINAL!\")\n",
        "print(\"\\nüí° DICA FINAL DO PEDRO:\")\n",
        "print(\"Prompting √© como tocar viol√£o - quanto mais pratica, melhor fica!\")\n",
        "print(\"Continue experimentando e iterando. Voc√™ t√° no caminho certo! üé∏\")\n",
        "print(\"=\"*60)"
      ]
    }
  ]
}