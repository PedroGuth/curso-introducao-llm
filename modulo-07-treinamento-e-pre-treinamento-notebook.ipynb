{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ‹ï¸â€â™‚ï¸ MÃ³dulo 7: Treinamento e PrÃ©-treinamento - A Academia dos LLMs!\n\n**Por Pedro Nunes Guth** ğŸš€\n\n---\n\nFala, pessoal! Chegamos no mÃ³dulo mais suado do nosso curso! ğŸ’ª\n\nTÃ¡, mas o que Ã© treinamento e prÃ©-treinamento? Imagina que vocÃª vai aprender a jogar futebol. Primeiro vocÃª precisa aprender o bÃ¡sico: chutar, correr, dominar a bola (isso Ã© o **prÃ©-treinamento**). Depois, vocÃª treina para jogar numa posiÃ§Ã£o especÃ­fica: atacante, zagueiro, goleiro (isso Ã© o **fine-tuning**).\n\nCom LLMs Ã© a mesma coisa! Primeiro eles aprendem a \"entender\" linguagem em geral, depois sÃ£o especializados para tarefas especÃ­ficas.\n\n**Bora entender como funciona essa academia dos modelos!** ğŸ¯\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introduÃ§Ã£o-Ã -llms-modulo-07_img_01.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup inicial - Importando as bibliotecas que vamos usar\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from IPython.display import Markdown, display\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ConfiguraÃ§Ãµes para os grÃ¡ficos ficarem liiindos!\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"ğŸ”¥ Setup pronto! Bora treinar alguns modelos!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Numpy version: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ O que Ã© PrÃ©-treinamento?\n\nLembra dos **embeddings** e **tokens** que vimos nos mÃ³dulos anteriores? Agora vamos ver como o modelo aprende a criar essas representaÃ§Ãµes!\n\nO **prÃ©-treinamento** Ã© como ensinar uma crianÃ§a a ler. VocÃª nÃ£o comeÃ§a ensinando Shakespeare, nÃ©? ComeÃ§a com \"O gato subiu no telhado\". \n\n### As 3 Fases do PrÃ©-treinamento:\n\n1. **Coleta de Dados**: Pegamos MUUUITO texto da internet (livros, artigos, Wikipedia...)\n2. **TokenizaÃ§Ã£o**: Transformamos texto em nÃºmeros (jÃ¡ vimos isso no MÃ³dulo 4!)\n3. **Treinamento Auto-supervisionado**: O modelo aprende a prever a prÃ³xima palavra\n\n**Dica do Pedro**: O prÃ©-treinamento Ã© caro pra caramba! O GPT-3 custou uns 4.6 milhÃµes de dÃ³lares para treinar. Por isso que a galera usa modelos jÃ¡ prÃ©-treinados! ğŸ’°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos simular um dataset de prÃ©-treinamento simples\n",
        "# Imagina que estamos treinando um modelo para entender portuguÃªs\n",
        "\n",
        "# Dados de exemplo (bem simplificado!)\n",
        "textos_pretreinamento = [\n",
        "    \"O gato subiu no telhado\",\n",
        "    \"O cachorro late muito alto\", \n",
        "    \"A chuva molha a rua\",\n",
        "    \"O sol brilha no cÃ©u\",\n",
        "    \"As flores crescem no jardim\",\n",
        "    \"O pÃ¡ssaro voa livre\",\n",
        "    \"A lua ilumina a noite\",\n",
        "    \"O vento balanÃ§a as Ã¡rvores\"\n",
        "]\n",
        "\n",
        "# Vamos criar um vocabulÃ¡rio simples\n",
        "todas_palavras = []\n",
        "for texto in textos_pretreinamento:\n",
        "    palavras = texto.lower().split()\n",
        "    todas_palavras.extend(palavras)\n",
        "\n",
        "# Criando vocabulÃ¡rio Ãºnico\n",
        "vocabulario = list(set(todas_palavras))\n",
        "vocab_size = len(vocabulario)\n",
        "\n",
        "# Mapeamento palavra -> Ã­ndice\n",
        "palavra_para_id = {palavra: i for i, palavra in enumerate(vocabulario)}\n",
        "id_para_palavra = {i: palavra for palavra, i in palavra_para_id.items()}\n",
        "\n",
        "print(f\"ğŸ“š VocabulÃ¡rio criado com {vocab_size} palavras Ãºnicas\")\n",
        "print(f\"Primeiras 10 palavras: {vocabulario[:10]}\")\n",
        "print(f\"\\nğŸ”¢ Exemplo de tokenizaÃ§Ã£o:\")\n",
        "print(f\"'{textos_pretreinamento[0]}' -> {[palavra_para_id[palavra] for palavra in textos_pretreinamento[0].lower().split()]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§  Como Funciona o Treinamento Auto-supervisionado?\n\nTÃ¡, mas como o modelo aprende sem ninguÃ©m dizer o que tÃ¡ certo ou errado?\n\nÃ‰ aÃ­ que entra a **mÃ¡gica**: o modelo tenta adivinhar a prÃ³xima palavra! Ã‰ como completar a frase:\n\n- \"O gato subiu no ___\" (resposta: telhado)\n- \"Hoje estÃ¡ fazendo muito ___\" (resposta: calor/frio/sol)\n\n### O Processo:\n1. **Input**: \"O gato subiu no\"\n2. **PrediÃ§Ã£o**: Modelo chuta \"telhado\" (70% confianÃ§a)\n3. **Target**: A palavra real Ã© \"telhado\"\n4. **Erro**: Se acertou, erro baixo. Se errou, erro alto\n5. **Backpropagation**: Ajusta os pesos para acertar na prÃ³xima\n\nEsse processo se repete trilhÃµes de vezes! ğŸ”„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar um modelo simples para demonstrar o conceito\n",
        "class ModeloSimples(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=64, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        # Camada de embedding (lembra do MÃ³dulo 5?)\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM para capturar sequÃªncias\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        \n",
        "        # Camada final para prever a prÃ³xima palavra\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, sequence_length]\n",
        "        embedded = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
        "        lstm_out, _ = self.lstm(embedded)  # [batch_size, seq_len, hidden_dim]\n",
        "        output = self.fc(lstm_out)  # [batch_size, seq_len, vocab_size]\n",
        "        return output\n",
        "\n",
        "# Criando o modelo\n",
        "modelo = ModeloSimples(vocab_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(modelo.parameters(), lr=0.001)\n",
        "\n",
        "print(f\"ğŸ¤– Modelo criado!\")\n",
        "print(f\"ParÃ¢metros: {sum(p.numel() for p in modelo.parameters())}\")\n",
        "print(f\"\\nğŸ“ Arquitetura:\")\n",
        "print(modelo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos preparar os dados para treinamento\n",
        "def preparar_dados(textos, palavra_para_id, seq_length=3):\n",
        "    X, y = [], []\n",
        "    \n",
        "    for texto in textos:\n",
        "        palavras = texto.lower().split()\n",
        "        ids = [palavra_para_id[palavra] for palavra in palavras]\n",
        "        \n",
        "        # Criando sequÃªncias de entrada e saÃ­da\n",
        "        for i in range(len(ids) - seq_length):\n",
        "            X.append(ids[i:i+seq_length])\n",
        "            y.append(ids[i+seq_length])\n",
        "    \n",
        "    return torch.tensor(X), torch.tensor(y)\n",
        "\n",
        "# Preparando dados\n",
        "X_train, y_train = preparar_dados(textos_pretreinamento, palavra_para_id)\n",
        "\n",
        "print(f\"ğŸ“Š Dados preparados:\")\n",
        "print(f\"Formato X: {X_train.shape} (batch_size, seq_length)\")\n",
        "print(f\"Formato y: {y_train.shape} (batch_size,)\")\n",
        "print(f\"\\nğŸ” Exemplo de treino:\")\n",
        "print(f\"Input: {[id_para_palavra[id.item()] for id in X_train[0]]} -> Target: {id_para_palavra[y_train[0].item()]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Agora vamos treinar nosso modelo! ğŸ‹ï¸â€â™‚ï¸\n",
        "def treinar_modelo(modelo, X, y, epochs=100):\n",
        "    losses = []\n",
        "    modelo.train()\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Forward pass\n",
        "        outputs = modelo(X)  # [batch_size, seq_len, vocab_size]\n",
        "        # Pegamos sÃ³ a Ãºltima posiÃ§Ã£o da sequÃªncia\n",
        "        outputs = outputs[:, -1, :]  # [batch_size, vocab_size]\n",
        "        \n",
        "        # Calculando perda\n",
        "        loss = criterion(outputs, y)\n",
        "        \n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        if epoch % 20 == 0:\n",
        "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item():.4f}\")\n",
        "    \n",
        "    return losses\n",
        "\n",
        "print(\"ğŸ”¥ Iniciando treinamento...\")\n",
        "losses = treinar_modelo(modelo, X_train, y_train)\n",
        "print(\"\\nâœ… Treinamento concluÃ­do! Liiindo!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando o progresso do treinamento\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(losses, linewidth=2, color='#e74c3c')\n",
        "plt.title('ğŸ“‰ EvoluÃ§Ã£o da Loss Durante o Treinamento', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Epochs', fontsize=12)\n",
        "plt.ylabel('Loss (Cross Entropy)', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"ğŸ“Š Loss inicial: {losses[0]:.4f}\")\n",
        "print(f\"ğŸ“Š Loss final: {losses[-1]:.4f}\")\n",
        "print(f\"ğŸ“Š Melhoria: {((losses[0] - losses[-1]) / losses[0] * 100):.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ­ Fine-tuning: Especializando o Modelo\n\nAgora que nosso modelo \"aprendeu portuguÃªs bÃ¡sico\", vamos especializÃ¡-lo!\n\nÃ‰ como um mÃ©dico: primeiro ele estuda medicina geral (prÃ©-treinamento), depois se especializa em cardiologia, pediatria, etc. (fine-tuning).\n\n### Tipos de Fine-tuning:\n\n1. **Supervised Fine-tuning (SFT)**: Com exemplos rotulados\n2. **Instruction Tuning**: Ensinando a seguir instruÃ§Ãµes\n3. **RLHF (Reinforcement Learning from Human Feedback)**: Aprendendo com feedback humano\n\n**Dica do Pedro**: Fine-tuning Ã© muito mais barato que prÃ©-treinamento! Ã‰ como customizar um carro em vez de construir do zero! ğŸš—"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos simular um fine-tuning para classificaÃ§Ã£o de sentimentos\n",
        "# Dados para fine-tuning (classificaÃ§Ã£o de sentimentos)\n",
        "dados_sentimento = [\n",
        "    (\"Que dia lindo hoje\", \"positivo\"),\n",
        "    (\"Estou muito feliz\", \"positivo\"), \n",
        "    (\"Adoro esse lugar\", \"positivo\"),\n",
        "    (\"Que dia terrÃ­vel\", \"negativo\"),\n",
        "    (\"Estou muito triste\", \"negativo\"),\n",
        "    (\"Detesto essa situaÃ§Ã£o\", \"negativo\"),\n",
        "    (\"O tempo estÃ¡ normal\", \"neutro\"),\n",
        "    (\"Ã‰ apenas um dia comum\", \"neutro\")\n",
        "]\n",
        "\n",
        "# Mapeamento de sentimentos\n",
        "sentimento_para_id = {\"positivo\": 0, \"negativo\": 1, \"neutro\": 2}\n",
        "id_para_sentimento = {0: \"positivo\", 1: \"negativo\", 2: \"neutro\"}\n",
        "\n",
        "print(\"ğŸ­ Dados para Fine-tuning (AnÃ¡lise de Sentimentos):\")\n",
        "for i, (texto, sentimento) in enumerate(dados_sentimento[:3]):\n",
        "    print(f\"  {i+1}. '{texto}' -> {sentimento}\")\n",
        "print(\"  ...\")\n",
        "\n",
        "print(f\"\\nğŸ“Š Classes: {list(sentimento_para_id.keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modelo para classificaÃ§Ã£o (usando o prÃ©-treinado como base)\n",
        "class ModeloClassificacao(nn.Module):\n",
        "    def __init__(self, modelo_pretreinado, num_classes=3):\n",
        "        super().__init__()\n",
        "        # Usando as camadas do modelo prÃ©-treinado\n",
        "        self.embedding = modelo_pretreinado.embedding\n",
        "        self.lstm = modelo_pretreinado.lstm\n",
        "        \n",
        "        # Nova cabeÃ§a para classificaÃ§Ã£o\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128, 64),  # 128 Ã© o hidden_dim do LSTM\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "        \n",
        "        # Congelando parÃ¢metros do modelo base (opcional)\n",
        "        # for param in self.embedding.parameters():\n",
        "        #     param.requires_grad = False\n",
        "        \n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        lstm_out, (hidden, _) = self.lstm(embedded)\n",
        "        # Usando o Ãºltimo estado hidden para classificaÃ§Ã£o\n",
        "        output = self.classifier(hidden[-1])  # [batch_size, num_classes]\n",
        "        return output\n",
        "\n",
        "# Criando modelo de classificaÃ§Ã£o baseado no prÃ©-treinado\n",
        "modelo_classificacao = ModeloClassificacao(modelo)\n",
        "criterion_class = nn.CrossEntropyLoss()\n",
        "optimizer_class = optim.Adam(modelo_classificacao.parameters(), lr=0.001)\n",
        "\n",
        "print(\"ğŸ¯ Modelo de classificaÃ§Ã£o criado!\")\n",
        "print(f\"ParÃ¢metros totais: {sum(p.numel() for p in modelo_classificacao.parameters())}\")\n",
        "print(f\"ParÃ¢metros treinÃ¡veis: {sum(p.numel() for p in modelo_classificacao.parameters() if p.requires_grad)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Comparando EstratÃ©gias de Treinamento\n\nExistem vÃ¡rias formas de treinar um modelo. Vamos ver as principais:\n\n### 1. **Training from Scratch** (Do Zero)\n- âœ… Controle total\n- âŒ Muito caro e demorado\n\n### 2. **Fine-tuning Completo**\n- âœ… Melhor performance\n- âŒ Pode \"esquecer\" conhecimento anterior (catastrophic forgetting)\n\n### 3. **Feature Extraction** (Congelando camadas)\n- âœ… RÃ¡pido e barato\n- âŒ Menos flexÃ­vel\n\n### 4. **LoRA (Low-Rank Adaptation)**\n- âœ… Eficiente em memÃ³ria\n- âœ… MantÃ©m conhecimento original\n- âŒ Mais complexo de implementar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando as diferentes estratÃ©gias de treinamento\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "fig.suptitle('ğŸ¯ EstratÃ©gias de Treinamento de LLMs', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Dados simulados para comparaÃ§Ã£o\n",
        "estrategias = ['From Scratch', 'Fine-tuning\\nCompleto', 'Feature\\nExtraction', 'LoRA']\n",
        "custo = [100, 30, 5, 15]  # Custo relativo\n",
        "tempo = [100, 25, 3, 12]  # Tempo relativo\n",
        "performance = [95, 90, 75, 88]  # Performance relativa\n",
        "memoria = [100, 100, 20, 45]  # Uso de memÃ³ria relativo\n",
        "\n",
        "# GrÃ¡fico de custo\n",
        "axes[0,0].bar(estrategias, custo, color=['#e74c3c', '#f39c12', '#27ae60', '#3498db'])\n",
        "axes[0,0].set_title('ğŸ’° Custo Relativo')\n",
        "axes[0,0].set_ylabel('Custo (%)')\n",
        "\n",
        "# GrÃ¡fico de tempo\n",
        "axes[0,1].bar(estrategias, tempo, color=['#e74c3c', '#f39c12', '#27ae60', '#3498db'])\n",
        "axes[0,1].set_title('â±ï¸ Tempo de Treinamento')\n",
        "axes[0,1].set_ylabel('Tempo (%)')\n",
        "\n",
        "# GrÃ¡fico de performance\n",
        "axes[1,0].bar(estrategias, performance, color=['#e74c3c', '#f39c12', '#27ae60', '#3498db'])\n",
        "axes[1,0].set_title('ğŸ¯ Performance')\n",
        "axes[1,0].set_ylabel('Accuracy (%)')\n",
        "\n",
        "# GrÃ¡fico de memÃ³ria\n",
        "axes[1,1].bar(estrategias, memoria, color=['#e74c3c', '#f39c12', '#27ae60', '#3498db'])\n",
        "axes[1,1].set_title('ğŸ§  Uso de MemÃ³ria')\n",
        "axes[1,1].set_ylabel('MemÃ³ria (%)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ“Š ComparaÃ§Ã£o das estratÃ©gias:\")\n",
        "print(\"â€¢ From Scratch: MÃ¡xima performance, mÃ¡ximo custo\")\n",
        "print(\"â€¢ Fine-tuning: Bom equilÃ­brio geral\")\n",
        "print(\"â€¢ Feature Extraction: Mais barato, menor performance\")\n",
        "print(\"â€¢ LoRA: Meio termo eficiente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ—ï¸ Arquitetura do Processo de Treinamento\n\nVamos visualizar como funciona todo o pipeline de treinamento de um LLM:\n\n```mermaid\ngraph TD\n    A[ğŸ“š Coleta de Dados] --> B[ğŸ”¤ TokenizaÃ§Ã£o]\n    B --> C[ğŸ¯ PrÃ©-treinamento]\n    C --> D[ğŸ’¾ Modelo Base]\n    D --> E[ğŸ­ Fine-tuning]\n    E --> F[ğŸ§ª AvaliaÃ§Ã£o]\n    F --> G{âœ… Performance OK?}\n    G -->|NÃ£o| H[âš™ï¸ Ajustar HiperparÃ¢metros]\n    H --> E\n    G -->|Sim| I[ğŸš€ Modelo Final]\n    \n    style A fill:#3498db\n    style D fill:#e74c3c\n    style I fill:#27ae60\n```\n\n**Dica do Pedro**: Esse processo pode levar meses! O GPT-4 provavelmente levou mais de 6 meses para ficar pronto. PaciÃªncia Ã© fundamental! â°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos simular mÃ©tricas de diferentes fases do treinamento\n",
        "import pandas as pd\n",
        "\n",
        "# Simulando dados de treinamento ao longo do tempo\n",
        "fases = ['Semana 1', 'Semana 2', 'Semana 4', 'Semana 8', 'Semana 12', 'Semana 16']\n",
        "pre_training_loss = [4.2, 3.8, 3.2, 2.9, 2.7, 2.6]\n",
        "fine_tuning_acc = [None, None, None, None, 0.65, 0.82]\n",
        "validation_loss = [4.5, 4.1, 3.4, 3.0, 2.8, 2.7]\n",
        "\n",
        "# Criando DataFrame\n",
        "df_metrics = pd.DataFrame({\n",
        "    'Fase': fases,\n",
        "    'Pre-training Loss': pre_training_loss,\n",
        "    'Fine-tuning Accuracy': fine_tuning_acc,\n",
        "    'Validation Loss': validation_loss\n",
        "})\n",
        "\n",
        "# VisualizaÃ§Ã£o das mÃ©tricas\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# GrÃ¡fico de Loss\n",
        "ax1.plot(fases, pre_training_loss, marker='o', linewidth=3, label='Pre-training Loss', color='#e74c3c')\n",
        "ax1.plot(fases, validation_loss, marker='s', linewidth=3, label='Validation Loss', color='#f39c12')\n",
        "ax1.set_title('ğŸ“‰ EvoluÃ§Ã£o da Loss', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
        "\n",
        "# GrÃ¡fico de Accuracy (apenas fine-tuning)\n",
        "fine_tune_fases = ['Semana 12', 'Semana 16']\n",
        "fine_tune_acc = [0.65, 0.82]\n",
        "ax2.plot(fine_tune_fases, fine_tune_acc, marker='D', linewidth=3, color='#27ae60', markersize=8)\n",
        "ax2.set_title('ğŸ¯ Accuracy do Fine-tuning', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.set_ylim(0, 1)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ“ˆ ObservaÃ§Ãµes importantes:\")\n",
        "print(\"â€¢ Loss de prÃ©-treinamento diminui gradualmente\")\n",
        "print(\"â€¢ Fine-tuning comeÃ§a apÃ³s prÃ©-treinamento\")\n",
        "print(\"â€¢ Validation loss acompanha training loss (sem overfitting)\")\n",
        "print(\"â€¢ Accuracy melhora rapidamente no fine-tuning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš¡ TÃ©cnicas AvanÃ§adas: LoRA e QLoRA\n\nTÃ¡, mas e se eu quiser fazer fine-tuning de um modelo gigante como o Llama-2 70B? Meu computador vai explodir! ğŸ’¥\n\nÃ‰ aÃ­ que entram as tÃ©cnicas modernas:\n\n### **LoRA (Low-Rank Adaptation)**\n- Em vez de atualizar todos os pesos, criamos matrizes pequenas\n- Reduz parÃ¢metros treinÃ¡veis em 90%+\n- MantÃ©m performance similar\n\n### **QLoRA (Quantized LoRA)**\n- LoRA + QuantizaÃ§Ã£o (4-bit)\n- Permite treinar modelos 65B numa GPU 24GB!\n- RevoluÃ§Ã£o democrÃ¡tica do fine-tuning\n\n**Analogia do Pedro**: Ã‰ como reformar sua casa. Em vez de demolir tudo (fine-tuning completo), vocÃª sÃ³ troca alguns mÃ³veis (LoRA). Muito mais barato e rÃ¡pido! ğŸ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SimulaÃ§Ã£o simples de LoRA\n",
        "class LoRALayer(nn.Module):\n",
        "    def __init__(self, original_layer, rank=8):\n",
        "        super().__init__()\n",
        "        self.original_layer = original_layer\n",
        "        \n",
        "        # Congelando a camada original\n",
        "        for param in self.original_layer.parameters():\n",
        "            param.requires_grad = False\n",
        "        \n",
        "        # Criando matrizes LoRA pequenas\n",
        "        in_features = original_layer.in_features\n",
        "        out_features = original_layer.out_features\n",
        "        \n",
        "        self.lora_A = nn.Linear(in_features, rank, bias=False)\n",
        "        self.lora_B = nn.Linear(rank, out_features, bias=False)\n",
        "        self.scaling = 0.1  # Fator de escala\n",
        "        \n",
        "        # InicializaÃ§Ã£o\n",
        "        nn.init.kaiming_uniform_(self.lora_A.weight)\n",
        "        nn.init.zeros_(self.lora_B.weight)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # SaÃ­da original + adaptaÃ§Ã£o LoRA\n",
        "        original_out = self.original_layer(x)\n",
        "        lora_out = self.lora_B(self.lora_A(x)) * self.scaling\n",
        "        return original_out + lora_out\n",
        "\n",
        "# Exemplo de uso\n",
        "camada_original = nn.Linear(512, 256)\n",
        "camada_lora = LoRALayer(camada_original, rank=16)\n",
        "\n",
        "# Comparando nÃºmero de parÃ¢metros\n",
        "params_original = sum(p.numel() for p in camada_original.parameters())\n",
        "params_lora = sum(p.numel() for p in camada_lora.parameters() if p.requires_grad)\n",
        "params_total = sum(p.numel() for p in camada_lora.parameters())\n",
        "\n",
        "print(\"ğŸ” ComparaÃ§Ã£o LoRA vs Normal:\")\n",
        "print(f\"ParÃ¢metros originais: {params_original:,}\")\n",
        "print(f\"ParÃ¢metros LoRA (treinÃ¡veis): {params_lora:,}\")\n",
        "print(f\"ParÃ¢metros totais: {params_total:,}\")\n",
        "print(f\"ReduÃ§Ã£o: {(1 - params_lora/params_original)*100:.1f}%\")\n",
        "print(f\"\\nğŸ’¡ LoRA permite treinar com {params_lora/params_original*100:.1f}% dos parÃ¢metros!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando a eficiÃªncia do LoRA\n",
        "ranks = [1, 2, 4, 8, 16, 32, 64]\n",
        "reducao_params = []\n",
        "memoria_estimada = []\n",
        "\n",
        "in_features, out_features = 4096, 4096  # Tamanho tÃ­pico de um LLM\n",
        "params_full = in_features * out_features\n",
        "\n",
        "for rank in ranks:\n",
        "    params_lora = (in_features * rank) + (rank * out_features)\n",
        "    reducao = (1 - params_lora/params_full) * 100\n",
        "    reducao_params.append(reducao)\n",
        "    \n",
        "    # Estimativa de memÃ³ria (assumindo float16)\n",
        "    memoria_mb = (params_lora * 2) / (1024 * 1024)  # 2 bytes por parÃ¢metro\n",
        "    memoria_estimada.append(memoria_mb)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# GrÃ¡fico de reduÃ§Ã£o de parÃ¢metros\n",
        "ax1.plot(ranks, reducao_params, marker='o', linewidth=3, color='#e74c3c', markersize=8)\n",
        "ax1.set_title('ğŸ“Š ReduÃ§Ã£o de ParÃ¢metros com LoRA', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Rank')\n",
        "ax1.set_ylabel('ReduÃ§Ã£o (%)')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim(95, 100)\n",
        "\n",
        "# GrÃ¡fico de uso de memÃ³ria\n",
        "ax2.plot(ranks, memoria_estimada, marker='s', linewidth=3, color='#3498db', markersize=8)\n",
        "ax2.set_title('ğŸ§  Uso de MemÃ³ria (ParÃ¢metros LoRA)', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Rank')\n",
        "ax2.set_ylabel('MemÃ³ria (MB)')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"ğŸ¯ Para uma camada 4096x4096:\")\n",
        "print(f\"â€¢ ParÃ¢metros completos: {params_full:,}\")\n",
        "print(f\"â€¢ Com rank=16: {(in_features * 16) + (16 * out_features):,} parÃ¢metros\")\n",
        "print(f\"â€¢ ReduÃ§Ã£o: {reducao_params[4]:.2f}%\")\n",
        "print(f\"â€¢ MemÃ³ria LoRA: {memoria_estimada[4]:.1f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ ExercÃ­cio PrÃ¡tico 1: Implementando um Mini Fine-tuning\n\nAgora Ã© sua vez! Vamos implementar um fine-tuning simples para classificaÃ§Ã£o de texto.\n\n**Seu desafio**:\n1. Complete a funÃ§Ã£o de preparaÃ§Ã£o dos dados\n2. Implemente o loop de treinamento\n3. Calcule a acurÃ¡cia no final\n\n**Dica do Pedro**: Use os exemplos anteriores como base. VocÃª consegue! ğŸ’ª"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ‹ï¸â€â™‚ï¸ EXERCÃCIO 1: Complete o cÃ³digo abaixo\n",
        "\n",
        "# Dados para o exercÃ­cio\n",
        "dados_exercicio = [\n",
        "    (\"Amo programar em Python\", \"positivo\"),\n",
        "    (\"Machine Learning Ã© fascinante\", \"positivo\"),\n",
        "    (\"Adoro aprender coisas novas\", \"positivo\"),\n",
        "    (\"Odeio bugs no cÃ³digo\", \"negativo\"),\n",
        "    (\"Esse erro Ã© muito chato\", \"negativo\"),\n",
        "    (\"Estou frustrado com isso\", \"negativo\"),\n",
        "    (\"O cÃ³digo funciona normal\", \"neutro\"),\n",
        "    (\"Ã‰ apenas uma funÃ§Ã£o comum\", \"neutro\")\n",
        "]\n",
        "\n",
        "def preparar_dados_exercicio(dados, palavra_para_id, sentimento_para_id):\n",
        "    X, y = [], []\n",
        "    \n",
        "    for texto, sentimento in dados:\n",
        "        # TODO: Tokenizar o texto e converter para IDs\n",
        "        palavras = texto.lower().split()\n",
        "        \n",
        "        # Filtrar palavras que nÃ£o estÃ£o no vocabulÃ¡rio\n",
        "        ids = []\n",
        "        for palavra in palavras:\n",
        "            if palavra in palavra_para_id:\n",
        "                ids.append(palavra_para_id[palavra])\n",
        "        \n",
        "        if len(ids) > 0:  # SÃ³ adicionar se tiver palavras vÃ¡lidas\n",
        "            # TODO: Fazer padding ou truncar para tamanho fixo\n",
        "            max_len = 5\n",
        "            if len(ids) < max_len:\n",
        "                ids.extend([0] * (max_len - len(ids)))  # Padding com 0\n",
        "            else:\n",
        "                ids = ids[:max_len]  # Truncar\n",
        "            \n",
        "            X.append(ids)\n",
        "            y.append(sentimento_para_id[sentimento])\n",
        "    \n",
        "    return torch.tensor(X), torch.tensor(y)\n",
        "\n",
        "# Preparar dados\n",
        "X_exercise, y_exercise = preparar_dados_exercicio(dados_exercicio, palavra_para_id, sentimento_para_id)\n",
        "\n",
        "print(f\"âœ… Dados preparados para exercÃ­cio:\")\n",
        "print(f\"Shape X: {X_exercise.shape}\")\n",
        "print(f\"Shape y: {y_exercise.shape}\")\n",
        "print(f\"Exemplo: {X_exercise[0]} -> {id_para_sentimento[y_exercise[0].item()]}\")\n",
        "\n",
        "# TODO: Agora complete o treinamento!\n",
        "# Dica: Use o modelo_classificacao que criamos anteriormente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš¨ Desafios do Treinamento de LLMs\n\nNem tudo sÃ£o flores no mundo dos LLMs! Existem vÃ¡rios desafios:\n\n### ğŸ”¥ **Principais Problemas:**\n\n1. **Catastrophic Forgetting**: Modelo \"esquece\" conhecimento anterior\n2. **Data Contamination**: Dados de teste \"vazam\" no treinamento\n3. **Bias e Toxicidade**: Modelo replica preconceitos dos dados\n4. **Hallucination**: Modelo \"inventa\" informaÃ§Ãµes\n5. **Custo Computacional**: Treinar Ã© carÃ­ssimo!\n\n### ğŸ’¡ **SoluÃ§Ãµes:**\n- **RegularizaÃ§Ã£o**: Para evitar overfitting\n- **Curriculum Learning**: Treinar do fÃ¡cil para o difÃ­cil\n- **Data Filtering**: Limpar dados de treinamento\n- **Constitutional AI**: Ensinar princÃ­pios Ã©ticos\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introduÃ§Ã£o-Ã -llms-modulo-07_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulando o problema de Catastrophic Forgetting\n",
        "import numpy as np\n",
        "\n",
        "# SimulaÃ§Ã£o de performance em diferentes tarefas\n",
        "tarefas = ['Tarefa A\\n(Original)', 'Tarefa B\\n(Fine-tuning)', 'Tarefa A\\n(ApÃ³s B)', 'Tarefa C\\n(Fine-tuning)', 'Tarefa A\\n(ApÃ³s C)']\n",
        "performance_sem_estrategia = [85, 90, 60, 88, 45]  # Com catastrophic forgetting\n",
        "performance_com_estrategia = [85, 88, 82, 86, 80]  # Com regularizaÃ§Ã£o\n",
        "\n",
        "x = np.arange(len(tarefas))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "bars1 = ax.bar(x - width/2, performance_sem_estrategia, width, label='Sem EstratÃ©gia', color='#e74c3c', alpha=0.8)\n",
        "bars2 = ax.bar(x + width/2, performance_com_estrategia, width, label='Com RegularizaÃ§Ã£o', color='#27ae60', alpha=0.8)\n",
        "\n",
        "ax.set_title('ğŸ§  Catastrophic Forgetting em AÃ§Ã£o', fontsize=16, fontweight='bold')\n",
        "ax.set_ylabel('Performance (%)')\n",
        "ax.set_xlabel('SequÃªncia de Treinamento')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(tarefas)\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate(f'{height}%',\n",
        "                   xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                   xytext=(0, 3),\n",
        "                   textcoords=\"offset points\",\n",
        "                   ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ” ObservaÃ§Ãµes:\")\n",
        "print(\"â€¢ Performance na Tarefa A cai drasticamente sem estratÃ©gias\")\n",
        "print(\"â€¢ RegularizaÃ§Ã£o ajuda a manter conhecimento anterior\")\n",
        "print(\"â€¢ Ã‰ um trade-off entre aprender novo e manter antigo\")\n",
        "print(\"\\nğŸ’¡ SoluÃ§Ãµes: EWC, L2 regularization, rehearsal learning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”® Pipeline Completo: Do Texto Bruto ao Modelo\n\nVamos ver todo o processo completo, do comeÃ§o ao fim:\n\n```mermaid\ngraph TB\n    subgraph \"ğŸ“š Dados\"\n        A[Web Scraping] --> B[Livros]\n        C[Wikipedia] --> B\n        D[Artigos] --> B\n        B --> E[Dataset Bruto]\n    end\n    \n    subgraph \"ğŸ§¹ PrÃ©-processamento\"\n        E --> F[Limpeza]\n        F --> G[DeduplicaÃ§Ã£o]\n        G --> H[TokenizaÃ§Ã£o]\n    end\n    \n    subgraph \"ğŸ‹ï¸ Treinamento\"\n        H --> I[PrÃ©-treinamento]\n        I --> J[Modelo Base]\n        J --> K[Fine-tuning]\n        K --> L[RLHF]\n    end\n    \n    subgraph \"ğŸ¯ Resultado\"\n        L --> M[Modelo Final]\n    end\n    \n    style E fill:#3498db\n    style J fill:#f39c12\n    style M fill:#27ae60\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estimativas de recursos para diferentes tamanhos de modelo\n",
        "modelos = ['GPT-2\\n(1.5B)', 'GPT-3\\n(175B)', 'PaLM\\n(540B)', 'GPT-4\\n(~1T)']\n",
        "parametros = [1.5, 175, 540, 1000]  # Em bilhÃµes\n",
        "custo_treinamento = [50000, 4600000, 15000000, 100000000]  # Em dÃ³lares (estimativa)\n",
        "gpus_necessarias = [8, 1024, 3000, 10000]  # GPUs A100\n",
        "tempo_treinamento = [7, 30, 45, 90]  # Em dias\n",
        "\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('ğŸ’° Recursos NecessÃ¡rios por Tamanho de Modelo', fontsize=16, fontweight='bold')\n",
        "\n",
        "colors = ['#3498db', '#e74c3c', '#f39c12', '#9b59b6']\n",
        "\n",
        "# ParÃ¢metros\n",
        "bars1 = ax1.bar(modelos, parametros, color=colors)\n",
        "ax1.set_title('ğŸ“Š NÃºmero de ParÃ¢metros')\n",
        "ax1.set_ylabel('BilhÃµes de ParÃ¢metros')\n",
        "ax1.set_yscale('log')\n",
        "\n",
        "# Custo\n",
        "bars2 = ax2.bar(modelos, custo_treinamento, color=colors)\n",
        "ax2.set_title('ğŸ’¸ Custo de Treinamento')\n",
        "ax2.set_ylabel('DÃ³lares (USD)')\n",
        "ax2.set_yscale('log')\n",
        "\n",
        "# GPUs\n",
        "bars3 = ax3.bar(modelos, gpus_necessarias, color=colors)\n",
        "ax3.set_title('ğŸ–¥ï¸ GPUs NecessÃ¡rias')\n",
        "ax3.set_ylabel('NÃºmero de GPUs A100')\n",
        "ax3.set_yscale('log')\n",
        "\n",
        "# Tempo\n",
        "bars4 = ax4.bar(modelos, tempo_treinamento, color=colors)\n",
        "ax4.set_title('â° Tempo de Treinamento')\n",
        "ax4.set_ylabel('Dias')\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for ax, values in [(ax1, parametros), (ax2, custo_treinamento), (ax3, gpus_necessarias), (ax4, tempo_treinamento)]:\n",
        "    bars = ax.patches\n",
        "    for bar, value in zip(bars, values):\n",
        "        height = bar.get_height()\n",
        "        if ax == ax2:  # Custo em milhÃµes\n",
        "            label = f'${value/1000000:.1f}M' if value >= 1000000 else f'${value/1000:.0f}K'\n",
        "        elif ax == ax1:  # ParÃ¢metros\n",
        "            label = f'{value}B'\n",
        "        else:\n",
        "            label = f'{value}'\n",
        "        \n",
        "        ax.annotate(label,\n",
        "                   xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                   xytext=(0, 3),\n",
        "                   textcoords=\"offset points\",\n",
        "                   ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ¤¯ Fatos impressionantes:\")\n",
        "print(f\"â€¢ GPT-4 custou ~$100M para treinar (estimativa)\")\n",
        "print(f\"â€¢ Precisou de ~10,000 GPUs A100 por 3 meses\")\n",
        "print(f\"â€¢ Isso Ã© mais que o PIB de alguns paÃ­ses pequenos!\")\n",
        "print(f\"â€¢ Por isso que fine-tuning Ã© tÃ£o importante! ğŸ’¡\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ ExercÃ­cio Final: AnÃ¡lise de EstratÃ©gias\n\n**CenÃ¡rio**: VocÃª trabalha numa startup e precisa criar um chatbot para atendimento ao cliente. VocÃª tem:\n- OrÃ§amento: $10,000\n- Prazo: 2 semanas \n- Hardware: 1 GPU A100\n- Dataset: 50,000 conversas de atendimento\n\n**Sua missÃ£o**: Escolha a melhor estratÃ©gia e justifique!\n\n**OpÃ§Ãµes**:\n1. Treinar do zero um modelo pequeno\n2. Fine-tuning completo do Llama-2 7B\n3. LoRA fine-tuning do Llama-2 13B\n4. Prompt engineering com GPT-4 via API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¤” EXERCÃCIO FINAL: AnÃ¡lise de estratÃ©gias\n",
        "# Complete a anÃ¡lise abaixo!\n",
        "\n",
        "estrategias_analise = {\n",
        "    'Treinar do Zero': {\n",
        "        'custo': 8000,\n",
        "        'tempo_dias': 10,\n",
        "        'performance_estimada': 70,\n",
        "        'controle': 100,\n",
        "        'risco': 80\n",
        "    },\n",
        "    'Fine-tuning Llama-2 7B': {\n",
        "        'custo': 2000,\n",
        "        'tempo_dias': 3,\n",
        "        'performance_estimada': 85,\n",
        "        'controle': 80,\n",
        "        'risco': 30\n",
        "    },\n",
        "    'LoRA Llama-2 13B': {\n",
        "        'custo': 1500,\n",
        "        'tempo_dias': 2,\n",
        "        'performance_estimada': 88,\n",
        "        'controle': 70,\n",
        "        'risco': 20\n",
        "    },\n",
        "    'GPT-4 API': {\n",
        "        'custo': 5000,  # Custo mensal estimado\n",
        "        'tempo_dias': 1,\n",
        "        'performance_estimada': 92,\n",
        "        'controle': 30,\n",
        "        'risco': 40  # DependÃªncia externa\n",
        "    }\n",
        "}\n",
        "\n",
        "# VisualizaÃ§Ã£o da anÃ¡lise\n",
        "import pandas as pd\n",
        "\n",
        "df_estrategias = pd.DataFrame(estrategias_analise).T\n",
        "print(\"ğŸ“Š AnÃ¡lise das EstratÃ©gias:\")\n",
        "print(df_estrategias)\n",
        "\n",
        "# TODO: Complete sua anÃ¡lise aqui!\n",
        "print(\"\\nğŸ¤” Minha escolha seria: ___________\")\n",
        "print(\"\\nâœ… Justificativa:\")\n",
        "print(\"1. ___________\")\n",
        "print(\"2. ___________\")\n",
        "print(\"3. ___________\")\n",
        "\n",
        "# Dica do Pedro: Considere o trade-off entre custo, tempo, performance e controle!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VisualizaÃ§Ã£o final da anÃ¡lise de estratÃ©gias\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Criando scatter plot\n",
        "for i, (nome, dados) in enumerate(estrategias_analise.items()):\n",
        "    # Plotando custo vs performance, com tamanho do ponto = inverso do tempo\n",
        "    size = 1000 / dados['tempo_dias']  # Quanto menor o tempo, maior o ponto\n",
        "    ax.scatter(dados['custo'], dados['performance_estimada'], \n",
        "              s=size, alpha=0.7, label=nome)\n",
        "    \n",
        "    # Adicionando rÃ³tulos\n",
        "    ax.annotate(nome, \n",
        "               (dados['custo'], dados['performance_estimada']),\n",
        "               xytext=(10, 10), textcoords='offset points',\n",
        "               fontsize=10, fontweight='bold')\n",
        "\n",
        "ax.set_xlabel('ğŸ’° Custo (USD)', fontsize=12)\n",
        "ax.set_ylabel('ğŸ¯ Performance Estimada (%)', fontsize=12)\n",
        "ax.set_title('âš–ï¸ Trade-off: Custo vs Performance\\n(Tamanho do ponto = Velocidade)', \n",
        "            fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.legend()\n",
        "\n",
        "# Adicionando linhas de referÃªncia\n",
        "ax.axhline(y=80, color='red', linestyle='--', alpha=0.5, label='Performance MÃ­nima')\n",
        "ax.axvline(x=10000, color='orange', linestyle='--', alpha=0.5, label='OrÃ§amento MÃ¡ximo')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ¯ Qual estratÃ©gia vocÃª escolheria? Pense em:\")\n",
        "print(\"â€¢ RestriÃ§Ãµes de orÃ§amento e tempo\")\n",
        "print(\"â€¢ Performance necessÃ¡ria\")\n",
        "print(\"â€¢ Controle sobre o modelo\")\n",
        "print(\"â€¢ Riscos envolvidos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ‰ Resumo do MÃ³dulo: O que Aprendemos?\n\nUfa! Que jornada, nÃ© pessoal? Vamos recapitular o que vimos neste mÃ³dulo:\n\n### ğŸ† **Conceitos Principais:**\n1. **PrÃ©-treinamento**: Como LLMs aprendem linguagem (auto-supervisionado)\n2. **Fine-tuning**: Especializando modelos para tarefas especÃ­ficas\n3. **LoRA/QLoRA**: TÃ©cnicas eficientes para fine-tuning\n4. **Desafios**: Catastrophic forgetting, custo, bias\n\n### ğŸ› ï¸ **TÃ©cnicas Aprendidas:**\n- PreparaÃ§Ã£o de dados para treinamento\n- ImplementaÃ§Ã£o de loops de treinamento\n- EstratÃ©gias de fine-tuning\n- AnÃ¡lise de trade-offs\n\n### ğŸ”— **ConexÃµes com MÃ³dulos Anteriores:**\n- **Tokens** (MÃ³dulo 4): Base para preparar dados de treinamento\n- **Embeddings** (MÃ³dulo 5): Como o modelo aprende representaÃ§Ãµes\n- **Arquitetura** (MÃ³dulo 3): Como os transformers processam durante treinamento\n\n### ğŸš€ **Preparando para o PrÃ³ximo MÃ³dulo:**\nNo **MÃ³dulo 8 (Prompting e Engenharia)**, vamos ver como usar esses modelos treinados de forma eficiente, sem precisar retreinÃ¡-los!\n\n**Dica Final do Pedro**: Treinamento Ã© como cozinhar - vocÃª pode fazer do zero (caro e demorado) ou usar ingredientes prontos e temperar do seu jeito (fine-tuning)! ğŸ‘¨â€ğŸ³\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introduÃ§Ã£o-Ã -llms-modulo-07_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“ Certificado de conclusÃ£o do mÃ³dulo!\n",
        "import datetime\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ğŸ“ CERTIFICADO DE CONCLUSÃƒO ğŸ“\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\"\"   \n",
        "    ParabÃ©ns! VocÃª concluiu o MÃ³dulo 7:\n",
        "    \n",
        "    ğŸ“š TREINAMENTO E PRÃ‰-TREINAMENTO DE LLMs\n",
        "    \n",
        "    Conceitos dominados:\n",
        "    âœ… PrÃ©-treinamento auto-supervisionado\n",
        "    âœ… Fine-tuning e especializaÃ§Ã£o\n",
        "    âœ… TÃ©cnicas LoRA e QLoRA\n",
        "    âœ… Desafios e soluÃ§Ãµes do treinamento\n",
        "    âœ… AnÃ¡lise de trade-offs e estratÃ©gias\n",
        "    \n",
        "    Data: {datetime.datetime.now().strftime('%d/%m/%Y')}\n",
        "    Instrutor: Pedro Nunes Guth\n",
        "    \n",
        "    ğŸš€ PrÃ³ximo: MÃ³dulo 8 - Prompting e Engenharia\n",
        "\"\"\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nğŸ”¥ VocÃª estÃ¡ no caminho certo para dominar LLMs!\")\n",
        "print(\"ğŸ’ª Continue praticando e experimentando!\")\n",
        "print(\"ğŸ“š Nos vemos no prÃ³ximo mÃ³dulo!\")\n",
        "\n",
        "# Easter egg: EstatÃ­sticas do mÃ³dulo\n",
        "print(\"\\nğŸ“Š EstatÃ­sticas deste mÃ³dulo:\")\n",
        "print(f\"â€¢ CÃ©lulas de cÃ³digo executadas: {len([cell for cell in globals() if not cell.startswith('_')])}\")\n",
        "print(f\"â€¢ Conceitos apresentados: 15+\")\n",
        "print(f\"â€¢ GrÃ¡ficos criados: 8\")\n",
        "print(f\"â€¢ ExercÃ­cios propostos: 2\")\n",
        "print(f\"â€¢ Dicas do Pedro: 10+\")\n",
        "print(\"\\nğŸ¯ VocÃª estÃ¡ pronto para os prompts! Bora pro MÃ³dulo 8! ğŸš€\")"
      ]
    }
  ]
}