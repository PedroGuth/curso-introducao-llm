{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üèãÔ∏è‚Äç‚ôÇÔ∏è M√≥dulo 7: Treinamento e Pr√©-treinamento - A Academia dos LLMs!\n\n**Por Pedro Nunes Guth** üöÄ\n\n---\n\nFala, pessoal! Chegamos no m√≥dulo mais suado do nosso curso! üí™\n\nT√°, mas o que √© treinamento e pr√©-treinamento? Imagina que voc√™ vai aprender a jogar futebol. Primeiro voc√™ precisa aprender o b√°sico: chutar, correr, dominar a bola (isso √© o **pr√©-treinamento**). Depois, voc√™ treina para jogar numa posi√ß√£o espec√≠fica: atacante, zagueiro, goleiro (isso √© o **fine-tuning**).\n\nCom LLMs √© a mesma coisa! Primeiro eles aprendem a \"entender\" linguagem em geral, depois s√£o especializados para tarefas espec√≠ficas.\n\n**Bora entender como funciona essa academia dos modelos!** üéØ\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introdu√ß√£o-√†-llms-modulo-07_img_01.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup inicial - Importando as bibliotecas que vamos usar\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from IPython.display import Markdown, display\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configura√ß√µes para os gr√°ficos ficarem liiindos!\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"üî• Setup pronto! Bora treinar alguns modelos!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Numpy version: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ O que √© Pr√©-treinamento?\n\nLembra dos **embeddings** e **tokens** que vimos nos m√≥dulos anteriores? Agora vamos ver como o modelo aprende a criar essas representa√ß√µes!\n\nO **pr√©-treinamento** √© como ensinar uma crian√ßa a ler. Voc√™ n√£o come√ßa ensinando Shakespeare, n√©? Come√ßa com \"O gato subiu no telhado\". \n\n### As 3 Fases do Pr√©-treinamento:\n\n1. **Coleta de Dados**: Pegamos MUUUITO texto da internet (livros, artigos, Wikipedia...)\n2. **Tokeniza√ß√£o**: Transformamos texto em n√∫meros (j√° vimos isso no M√≥dulo 4!)\n3. **Treinamento Auto-supervisionado**: O modelo aprende a prever a pr√≥xima palavra\n\n**Dica do Pedro**: O pr√©-treinamento √© caro pra caramba! O GPT-3 custou uns 4.6 milh√µes de d√≥lares para treinar. Por isso que a galera usa modelos j√° pr√©-treinados! üí∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos simular um dataset de pr√©-treinamento simples\n",
        "# Imagina que estamos treinando um modelo para entender portugu√™s\n",
        "\n",
        "# Dados de exemplo (bem simplificado!)\n",
        "textos_pretreinamento = [\n",
        "    \"O gato subiu no telhado\",\n",
        "    \"O cachorro late muito alto\", \n",
        "    \"A chuva molha a rua\",\n",
        "    \"O sol brilha no c√©u\",\n",
        "    \"As flores crescem no jardim\",\n",
        "    \"O p√°ssaro voa livre\",\n",
        "    \"A lua ilumina a noite\",\n",
        "    \"O vento balan√ßa as √°rvores\"\n",
        "]\n",
        "\n",
        "# Vamos criar um vocabul√°rio simples\n",
        "todas_palavras = []\n",
        "for texto in textos_pretreinamento:\n",
        "    palavras = texto.lower().split()\n",
        "    todas_palavras.extend(palavras)\n",
        "\n",
        "# Criando vocabul√°rio √∫nico\n",
        "vocabulario = list(set(todas_palavras))\n",
        "vocab_size = len(vocabulario)\n",
        "\n",
        "# Mapeamento palavra -> √≠ndice\n",
        "palavra_para_id = {palavra: i for i, palavra in enumerate(vocabulario)}\n",
        "id_para_palavra = {i: palavra for palavra, i in palavra_para_id.items()}\n",
        "\n",
        "print(f\"üìö Vocabul√°rio criado com {vocab_size} palavras √∫nicas\")\n",
        "print(f\"Primeiras 10 palavras: {vocabulario[:10]}\")\n",
        "print(f\"\\nüî¢ Exemplo de tokeniza√ß√£o:\")\n",
        "print(f\"'{textos_pretreinamento[0]}' -> {[palavra_para_id[palavra] for palavra in textos_pretreinamento[0].lower().split()]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† Como Funciona o Treinamento Auto-supervisionado?\n\nT√°, mas como o modelo aprende sem ningu√©m dizer o que t√° certo ou errado?\n\n√â a√≠ que entra a **m√°gica**: o modelo tenta adivinhar a pr√≥xima palavra! √â como completar a frase:\n\n- \"O gato subiu no ___\" (resposta: telhado)\n- \"Hoje est√° fazendo muito ___\" (resposta: calor/frio/sol)\n\n### O Processo:\n1. **Input**: \"O gato subiu no\"\n2. **Predi√ß√£o**: Modelo chuta \"telhado\" (70% confian√ßa)\n3. **Target**: A palavra real √© \"telhado\"\n4. **Erro**: Se acertou, erro baixo. Se errou, erro alto\n5. **Backpropagation**: Ajusta os pesos para acertar na pr√≥xima\n\nEsse processo se repete trilh√µes de vezes! üîÑ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar um modelo simples para demonstrar o conceito\n",
        "class ModeloSimples(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=64, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        # Camada de embedding (lembra do M√≥dulo 5?)\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM para capturar sequ√™ncias\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        \n",
        "        # Camada final para prever a pr√≥xima palavra\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, sequence_length]\n",
        "        embedded = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
        "        lstm_out, _ = self.lstm(embedded)  # [batch_size, seq_len, hidden_dim]\n",
        "        output = self.fc(lstm_out)  # [batch_size, seq_len, vocab_size]\n",
        "        return output\n",
        "\n",
        "# Criando o modelo\n",
        "modelo = ModeloSimples(vocab_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(modelo.parameters(), lr=0.001)\n",
        "\n",
        "print(f\"ü§ñ Modelo criado!\")\n",
        "print(f\"Par√¢metros: {sum(p.numel() for p in modelo.parameters())}\")\n",
        "print(f\"\\nüìê Arquitetura:\")\n",
        "print(modelo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos preparar os dados para treinamento\n",
        "def preparar_dados(textos, palavra_para_id, seq_length=3):\n",
        "    X, y = [], []\n",
        "    \n",
        "    for texto in textos:\n",
        "        palavras = texto.lower().split()\n",
        "        ids = [palavra_para_id[palavra] for palavra in palavras]\n",
        "        \n",
        "        # Criando sequ√™ncias de entrada e sa√≠da\n",
        "        for i in range(len(ids) - seq_length):\n",
        "            X.append(ids[i:i+seq_length])\n",
        "            y.append(ids[i+seq_length])\n",
        "    \n",
        "    return torch.tensor(X), torch.tensor(y)\n",
        "\n",
        "# Preparando dados\n",
        "X_train, y_train = preparar_dados(textos_pretreinamento, palavra_para_id)\n",
        "\n",
        "print(f\"üìä Dados preparados:\")\n",
        "print(f\"Formato X: {X_train.shape} (batch_size, seq_length)\")\n",
        "print(f\"Formato y: {y_train.shape} (batch_size,)\")\n",
        "print(f\"\\nüîç Exemplo de treino:\")\n",
        "print(f\"Input: {[id_para_palavra[id.item()] for id in X_train[0]]} -> Target: {id_para_palavra[y_train[0].item()]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Agora vamos treinar nosso modelo! üèãÔ∏è‚Äç‚ôÇÔ∏è\n",
        "def treinar_modelo(modelo, X, y, epochs=100):\n",
        "    losses = []\n",
        "    modelo.train()\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Forward pass\n",
        "        outputs = modelo(X)  # [batch_size, seq_len, vocab_size]\n",
        "        # Pegamos s√≥ a √∫ltima posi√ß√£o da sequ√™ncia\n",
        "        outputs = outputs[:, -1, :]  # [batch_size, vocab_size]\n",
        "        \n",
        "        # Calculando perda\n",
        "        loss = criterion(outputs, y)\n",
        "        \n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        if epoch % 20 == 0:\n",
        "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item():.4f}\")\n",
        "    \n",
        "    return losses\n",
        "\n",
        "print(\"üî• Iniciando treinamento...\")\n",
        "losses = treinar_modelo(modelo, X_train, y_train)\n",
        "print(\"\\n‚úÖ Treinamento conclu√≠do! Liiindo!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando o progresso do treinamento\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(losses, linewidth=2, color='#e74c3c')\n",
        "plt.title('üìâ Evolu√ß√£o da Loss Durante o Treinamento', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Epochs', fontsize=12)\n",
        "plt.ylabel('Loss (Cross Entropy)', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"üìä Loss inicial: {losses[0]:.4f}\")\n",
        "print(f\"üìä Loss final: {losses[-1]:.4f}\")\n",
        "print(f\"üìä Melhoria: {((losses[0] - losses[-1]) / losses[0] * 100):.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé≠ Fine-tuning: Especializando o Modelo\n\nAgora que nosso modelo \"aprendeu portugu√™s b√°sico\", vamos especializ√°-lo!\n\n√â como um m√©dico: primeiro ele estuda medicina geral (pr√©-treinamento), depois se especializa em cardiologia, pediatria, etc. (fine-tuning).\n\n### Tipos de Fine-tuning:\n\n1. **Supervised Fine-tuning (SFT)**: Com exemplos rotulados\n2. **Instruction Tuning**: Ensinando a seguir instru√ß√µes\n3. **RLHF (Reinforcement Learning from Human Feedback)**: Aprendendo com feedback humano\n\n**Dica do Pedro**: Fine-tuning √© muito mais barato que pr√©-treinamento! √â como customizar um carro em vez de construir do zero! üöó"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos simular um fine-tuning para classifica√ß√£o de sentimentos\n",
        "# Dados para fine-tuning (classifica√ß√£o de sentimentos)\n",
        "dados_sentimento = [\n",
        "    (\"Que dia lindo hoje\", \"positivo\"),\n",
        "    (\"Estou muito feliz\", \"positivo\"), \n",
        "    (\"Adoro esse lugar\", \"positivo\"),\n",
        "    (\"Que dia terr√≠vel\", \"negativo\"),\n",
        "    (\"Estou muito triste\", \"negativo\"),\n",
        "    (\"Detesto essa situa√ß√£o\", \"negativo\"),\n",
        "    (\"O tempo est√° normal\", \"neutro\"),\n",
        "    (\"√â apenas um dia comum\", \"neutro\")\n",
        "]\n",
        "\n",
        "# Mapeamento de sentimentos\n",
        "sentimento_para_id = {\"positivo\": 0, \"negativo\": 1, \"neutro\": 2}\n",
        "id_para_sentimento = {0: \"positivo\", 1: \"negativo\", 2: \"neutro\"}\n",
        "\n",
        "print(\"üé≠ Dados para Fine-tuning (An√°lise de Sentimentos):\")\n",
        "for i, (texto, sentimento) in enumerate(dados_sentimento[:3]):\n",
        "    print(f\"  {i+1}. '{texto}' -> {sentimento}\")\n",
        "print(\"  ...\")\n",
        "\n",
        "print(f\"\\nüìä Classes: {list(sentimento_para_id.keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modelo para classifica√ß√£o (usando o pr√©-treinado como base)\n",
        "class ModeloClassificacao(nn.Module):\n",
        "    def __init__(self, modelo_pretreinado, num_classes=3):\n",
        "        super().__init__()\n",
        "        # Usando as camadas do modelo pr√©-treinado\n",
        "        self.embedding = modelo_pretreinado.embedding\n",
        "        self.lstm = modelo_pretreinado.lstm\n",
        "        \n",
        "        # Nova cabe√ßa para classifica√ß√£o\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128, 64),  # 128 √© o hidden_dim do LSTM\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "        \n",
        "        # Congelando par√¢metros do modelo base (opcional)\n",
        "        # for param in self.embedding.parameters():\n",
        "        #     param.requires_grad = False\n",
        "        \n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        lstm_out, (hidden, _) = self.lstm(embedded)\n",
        "        # Usando o √∫ltimo estado hidden para classifica√ß√£o\n",
        "        output = self.classifier(hidden[-1])  # [batch_size, num_classes]\n",
        "        return output\n",
        "\n",
        "# Criando modelo de classifica√ß√£o baseado no pr√©-treinado\n",
        "modelo_classificacao = ModeloClassificacao(modelo)\n",
        "criterion_class = nn.CrossEntropyLoss()\n",
        "optimizer_class = optim.Adam(modelo_classificacao.parameters(), lr=0.001)\n",
        "\n",
        "print(\"üéØ Modelo de classifica√ß√£o criado!\")\n",
        "print(f\"Par√¢metros totais: {sum(p.numel() for p in modelo_classificacao.parameters())}\")\n",
        "print(f\"Par√¢metros trein√°veis: {sum(p.numel() for p in modelo_classificacao.parameters() if p.requires_grad)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Comparando Estrat√©gias de Treinamento\n\nExistem v√°rias formas de treinar um modelo. Vamos ver as principais:\n\n### 1. **Training from Scratch** (Do Zero)\n- ‚úÖ Controle total\n- ‚ùå Muito caro e demorado\n\n### 2. **Fine-tuning Completo**\n- ‚úÖ Melhor performance\n- ‚ùå Pode \"esquecer\" conhecimento anterior (catastrophic forgetting)\n\n### 3. **Feature Extraction** (Congelando camadas)\n- ‚úÖ R√°pido e barato\n- ‚ùå Menos flex√≠vel\n\n### 4. **LoRA (Low-Rank Adaptation)**\n- ‚úÖ Eficiente em mem√≥ria\n- ‚úÖ Mant√©m conhecimento original\n- ‚ùå Mais complexo de implementar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando as diferentes estrat√©gias de treinamento\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "fig.suptitle('üéØ Estrat√©gias de Treinamento de LLMs', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Dados simulados para compara√ß√£o\n",
        "estrategias = ['From Scratch', 'Fine-tuning\\nCompleto', 'Feature\\nExtraction', 'LoRA']\n",
        "custo = [100, 30, 5, 15]  # Custo relativo\n",
        "tempo = [100, 25, 3, 12]  # Tempo relativo\n",
        "performance = [95, 90, 75, 88]  # Performance relativa\n",
        "memoria = [100, 100, 20, 45]  # Uso de mem√≥ria relativo\n",
        "\n",
        "# Gr√°fico de custo\n",
        "axes[0,0].bar(estrategias, custo, color=['#e74c3c', '#f39c12', '#27ae60', '#3498db'])\n",
        "axes[0,0].set_title('üí∞ Custo Relativo')\n",
        "axes[0,0].set_ylabel('Custo (%)')\n",
        "\n",
        "# Gr√°fico de tempo\n",
        "axes[0,1].bar(estrategias, tempo, color=['#e74c3c', '#f39c12', '#27ae60', '#3498db'])\n",
        "axes[0,1].set_title('‚è±Ô∏è Tempo de Treinamento')\n",
        "axes[0,1].set_ylabel('Tempo (%)')\n",
        "\n",
        "# Gr√°fico de performance\n",
        "axes[1,0].bar(estrategias, performance, color=['#e74c3c', '#f39c12', '#27ae60', '#3498db'])\n",
        "axes[1,0].set_title('üéØ Performance')\n",
        "axes[1,0].set_ylabel('Accuracy (%)')\n",
        "\n",
        "# Gr√°fico de mem√≥ria\n",
        "axes[1,1].bar(estrategias, memoria, color=['#e74c3c', '#f39c12', '#27ae60', '#3498db'])\n",
        "axes[1,1].set_title('üß† Uso de Mem√≥ria')\n",
        "axes[1,1].set_ylabel('Mem√≥ria (%)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Compara√ß√£o das estrat√©gias:\")\n",
        "print(\"‚Ä¢ From Scratch: M√°xima performance, m√°ximo custo\")\n",
        "print(\"‚Ä¢ Fine-tuning: Bom equil√≠brio geral\")\n",
        "print(\"‚Ä¢ Feature Extraction: Mais barato, menor performance\")\n",
        "print(\"‚Ä¢ LoRA: Meio termo eficiente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è Arquitetura do Processo de Treinamento\n\nVamos visualizar como funciona todo o pipeline de treinamento de um LLM:\n\n```mermaid\ngraph TD\n    A[üìö Coleta de Dados] --> B[üî§ Tokeniza√ß√£o]\n    B --> C[üéØ Pr√©-treinamento]\n    C --> D[üíæ Modelo Base]\n    D --> E[üé≠ Fine-tuning]\n    E --> F[üß™ Avalia√ß√£o]\n    F --> G{‚úÖ Performance OK?}\n    G -->|N√£o| H[‚öôÔ∏è Ajustar Hiperpar√¢metros]\n    H --> E\n    G -->|Sim| I[üöÄ Modelo Final]\n    \n    style A fill:#3498db\n    style D fill:#e74c3c\n    style I fill:#27ae60\n```\n\n**Dica do Pedro**: Esse processo pode levar meses! O GPT-4 provavelmente levou mais de 6 meses para ficar pronto. Paci√™ncia √© fundamental! ‚è∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos simular m√©tricas de diferentes fases do treinamento\n",
        "import pandas as pd\n",
        "\n",
        "# Simulando dados de treinamento ao longo do tempo\n",
        "fases = ['Semana 1', 'Semana 2', 'Semana 4', 'Semana 8', 'Semana 12', 'Semana 16']\n",
        "pre_training_loss = [4.2, 3.8, 3.2, 2.9, 2.7, 2.6]\n",
        "fine_tuning_acc = [None, None, None, None, 0.65, 0.82]\n",
        "validation_loss = [4.5, 4.1, 3.4, 3.0, 2.8, 2.7]\n",
        "\n",
        "# Criando DataFrame\n",
        "df_metrics = pd.DataFrame({\n",
        "    'Fase': fases,\n",
        "    'Pre-training Loss': pre_training_loss,\n",
        "    'Fine-tuning Accuracy': fine_tuning_acc,\n",
        "    'Validation Loss': validation_loss\n",
        "})\n",
        "\n",
        "# Visualiza√ß√£o das m√©tricas\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Gr√°fico de Loss\n",
        "ax1.plot(fases, pre_training_loss, marker='o', linewidth=3, label='Pre-training Loss', color='#e74c3c')\n",
        "ax1.plot(fases, validation_loss, marker='s', linewidth=3, label='Validation Loss', color='#f39c12')\n",
        "ax1.set_title('üìâ Evolu√ß√£o da Loss', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
        "\n",
        "# Gr√°fico de Accuracy (apenas fine-tuning)\n",
        "fine_tune_fases = ['Semana 12', 'Semana 16']\n",
        "fine_tune_acc = [0.65, 0.82]\n",
        "ax2.plot(fine_tune_fases, fine_tune_acc, marker='D', linewidth=3, color='#27ae60', markersize=8)\n",
        "ax2.set_title('üéØ Accuracy do Fine-tuning', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.set_ylim(0, 1)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìà Observa√ß√µes importantes:\")\n",
        "print(\"‚Ä¢ Loss de pr√©-treinamento diminui gradualmente\")\n",
        "print(\"‚Ä¢ Fine-tuning come√ßa ap√≥s pr√©-treinamento\")\n",
        "print(\"‚Ä¢ Validation loss acompanha training loss (sem overfitting)\")\n",
        "print(\"‚Ä¢ Accuracy melhora rapidamente no fine-tuning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö° T√©cnicas Avan√ßadas: LoRA e QLoRA\n\nT√°, mas e se eu quiser fazer fine-tuning de um modelo gigante como o Llama-2 70B? Meu computador vai explodir! üí•\n\n√â a√≠ que entram as t√©cnicas modernas:\n\n### **LoRA (Low-Rank Adaptation)**\n- Em vez de atualizar todos os pesos, criamos matrizes pequenas\n- Reduz par√¢metros trein√°veis em 90%+\n- Mant√©m performance similar\n\n### **QLoRA (Quantized LoRA)**\n- LoRA + Quantiza√ß√£o (4-bit)\n- Permite treinar modelos 65B numa GPU 24GB!\n- Revolu√ß√£o democr√°tica do fine-tuning\n\n**Analogia do Pedro**: √â como reformar sua casa. Em vez de demolir tudo (fine-tuning completo), voc√™ s√≥ troca alguns m√≥veis (LoRA). Muito mais barato e r√°pido! üè†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simula√ß√£o simples de LoRA\n",
        "class LoRALayer(nn.Module):\n",
        "    def __init__(self, original_layer, rank=8):\n",
        "        super().__init__()\n",
        "        self.original_layer = original_layer\n",
        "        \n",
        "        # Congelando a camada original\n",
        "        for param in self.original_layer.parameters():\n",
        "            param.requires_grad = False\n",
        "        \n",
        "        # Criando matrizes LoRA pequenas\n",
        "        in_features = original_layer.in_features\n",
        "        out_features = original_layer.out_features\n",
        "        \n",
        "        self.lora_A = nn.Linear(in_features, rank, bias=False)\n",
        "        self.lora_B = nn.Linear(rank, out_features, bias=False)\n",
        "        self.scaling = 0.1  # Fator de escala\n",
        "        \n",
        "        # Inicializa√ß√£o\n",
        "        nn.init.kaiming_uniform_(self.lora_A.weight)\n",
        "        nn.init.zeros_(self.lora_B.weight)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Sa√≠da original + adapta√ß√£o LoRA\n",
        "        original_out = self.original_layer(x)\n",
        "        lora_out = self.lora_B(self.lora_A(x)) * self.scaling\n",
        "        return original_out + lora_out\n",
        "\n",
        "# Exemplo de uso\n",
        "camada_original = nn.Linear(512, 256)\n",
        "camada_lora = LoRALayer(camada_original, rank=16)\n",
        "\n",
        "# Comparando n√∫mero de par√¢metros\n",
        "params_original = sum(p.numel() for p in camada_original.parameters())\n",
        "params_lora = sum(p.numel() for p in camada_lora.parameters() if p.requires_grad)\n",
        "params_total = sum(p.numel() for p in camada_lora.parameters())\n",
        "\n",
        "print(\"üîç Compara√ß√£o LoRA vs Normal:\")\n",
        "print(f\"Par√¢metros originais: {params_original:,}\")\n",
        "print(f\"Par√¢metros LoRA (trein√°veis): {params_lora:,}\")\n",
        "print(f\"Par√¢metros totais: {params_total:,}\")\n",
        "print(f\"Redu√ß√£o: {(1 - params_lora/params_original)*100:.1f}%\")\n",
        "print(f\"\\nüí° LoRA permite treinar com {params_lora/params_original*100:.1f}% dos par√¢metros!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando a efici√™ncia do LoRA\n",
        "ranks = [1, 2, 4, 8, 16, 32, 64]\n",
        "reducao_params = []\n",
        "memoria_estimada = []\n",
        "\n",
        "in_features, out_features = 4096, 4096  # Tamanho t√≠pico de um LLM\n",
        "params_full = in_features * out_features\n",
        "\n",
        "for rank in ranks:\n",
        "    params_lora = (in_features * rank) + (rank * out_features)\n",
        "    reducao = (1 - params_lora/params_full) * 100\n",
        "    reducao_params.append(reducao)\n",
        "    \n",
        "    # Estimativa de mem√≥ria (assumindo float16)\n",
        "    memoria_mb = (params_lora * 2) / (1024 * 1024)  # 2 bytes por par√¢metro\n",
        "    memoria_estimada.append(memoria_mb)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Gr√°fico de redu√ß√£o de par√¢metros\n",
        "ax1.plot(ranks, reducao_params, marker='o', linewidth=3, color='#e74c3c', markersize=8)\n",
        "ax1.set_title('üìä Redu√ß√£o de Par√¢metros com LoRA', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Rank')\n",
        "ax1.set_ylabel('Redu√ß√£o (%)')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim(95, 100)\n",
        "\n",
        "# Gr√°fico de uso de mem√≥ria\n",
        "ax2.plot(ranks, memoria_estimada, marker='s', linewidth=3, color='#3498db', markersize=8)\n",
        "ax2.set_title('üß† Uso de Mem√≥ria (Par√¢metros LoRA)', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Rank')\n",
        "ax2.set_ylabel('Mem√≥ria (MB)')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"üéØ Para uma camada 4096x4096:\")\n",
        "print(f\"‚Ä¢ Par√¢metros completos: {params_full:,}\")\n",
        "print(f\"‚Ä¢ Com rank=16: {(in_features * 16) + (16 * out_features):,} par√¢metros\")\n",
        "print(f\"‚Ä¢ Redu√ß√£o: {reducao_params[4]:.2f}%\")\n",
        "print(f\"‚Ä¢ Mem√≥ria LoRA: {memoria_estimada[4]:.1f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exerc√≠cio Pr√°tico 1: Implementando um Mini Fine-tuning\n\nAgora √© sua vez! Vamos implementar um fine-tuning simples para classifica√ß√£o de texto.\n\n**Seu desafio**:\n1. Complete a fun√ß√£o de prepara√ß√£o dos dados\n2. Implemente o loop de treinamento\n3. Calcule a acur√°cia no final\n\n**Dica do Pedro**: Use os exemplos anteriores como base. Voc√™ consegue! üí™"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üèãÔ∏è‚Äç‚ôÇÔ∏è EXERC√çCIO 1: Complete o c√≥digo abaixo\n",
        "\n",
        "# Dados para o exerc√≠cio\n",
        "dados_exercicio = [\n",
        "    (\"Amo programar em Python\", \"positivo\"),\n",
        "    (\"Machine Learning √© fascinante\", \"positivo\"),\n",
        "    (\"Adoro aprender coisas novas\", \"positivo\"),\n",
        "    (\"Odeio bugs no c√≥digo\", \"negativo\"),\n",
        "    (\"Esse erro √© muito chato\", \"negativo\"),\n",
        "    (\"Estou frustrado com isso\", \"negativo\"),\n",
        "    (\"O c√≥digo funciona normal\", \"neutro\"),\n",
        "    (\"√â apenas uma fun√ß√£o comum\", \"neutro\")\n",
        "]\n",
        "\n",
        "def preparar_dados_exercicio(dados, palavra_para_id, sentimento_para_id):\n",
        "    X, y = [], []\n",
        "    \n",
        "    for texto, sentimento in dados:\n",
        "        # TODO: Tokenizar o texto e converter para IDs\n",
        "        palavras = texto.lower().split()\n",
        "        \n",
        "        # Filtrar palavras que n√£o est√£o no vocabul√°rio\n",
        "        ids = []\n",
        "        for palavra in palavras:\n",
        "            if palavra in palavra_para_id:\n",
        "                ids.append(palavra_para_id[palavra])\n",
        "        \n",
        "        if len(ids) > 0:  # S√≥ adicionar se tiver palavras v√°lidas\n",
        "            # TODO: Fazer padding ou truncar para tamanho fixo\n",
        "            max_len = 5\n",
        "            if len(ids) < max_len:\n",
        "                ids.extend([0] * (max_len - len(ids)))  # Padding com 0\n",
        "            else:\n",
        "                ids = ids[:max_len]  # Truncar\n",
        "            \n",
        "            X.append(ids)\n",
        "            y.append(sentimento_para_id[sentimento])\n",
        "    \n",
        "    return torch.tensor(X), torch.tensor(y)\n",
        "\n",
        "# Preparar dados\n",
        "X_exercise, y_exercise = preparar_dados_exercicio(dados_exercicio, palavra_para_id, sentimento_para_id)\n",
        "\n",
        "print(f\"‚úÖ Dados preparados para exerc√≠cio:\")\n",
        "print(f\"Shape X: {X_exercise.shape}\")\n",
        "print(f\"Shape y: {y_exercise.shape}\")\n",
        "print(f\"Exemplo: {X_exercise[0]} -> {id_para_sentimento[y_exercise[0].item()]}\")\n",
        "\n",
        "# TODO: Agora complete o treinamento!\n",
        "# Dica: Use o modelo_classificacao que criamos anteriormente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üö® Desafios do Treinamento de LLMs\n\nNem tudo s√£o flores no mundo dos LLMs! Existem v√°rios desafios:\n\n### üî• **Principais Problemas:**\n\n1. **Catastrophic Forgetting**: Modelo \"esquece\" conhecimento anterior\n2. **Data Contamination**: Dados de teste \"vazam\" no treinamento\n3. **Bias e Toxicidade**: Modelo replica preconceitos dos dados\n4. **Hallucination**: Modelo \"inventa\" informa√ß√µes\n5. **Custo Computacional**: Treinar √© car√≠ssimo!\n\n### üí° **Solu√ß√µes:**\n- **Regulariza√ß√£o**: Para evitar overfitting\n- **Curriculum Learning**: Treinar do f√°cil para o dif√≠cil\n- **Data Filtering**: Limpar dados de treinamento\n- **Constitutional AI**: Ensinar princ√≠pios √©ticos\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introdu√ß√£o-√†-llms-modulo-07_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulando o problema de Catastrophic Forgetting\n",
        "import numpy as np\n",
        "\n",
        "# Simula√ß√£o de performance em diferentes tarefas\n",
        "tarefas = ['Tarefa A\\n(Original)', 'Tarefa B\\n(Fine-tuning)', 'Tarefa A\\n(Ap√≥s B)', 'Tarefa C\\n(Fine-tuning)', 'Tarefa A\\n(Ap√≥s C)']\n",
        "performance_sem_estrategia = [85, 90, 60, 88, 45]  # Com catastrophic forgetting\n",
        "performance_com_estrategia = [85, 88, 82, 86, 80]  # Com regulariza√ß√£o\n",
        "\n",
        "x = np.arange(len(tarefas))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "bars1 = ax.bar(x - width/2, performance_sem_estrategia, width, label='Sem Estrat√©gia', color='#e74c3c', alpha=0.8)\n",
        "bars2 = ax.bar(x + width/2, performance_com_estrategia, width, label='Com Regulariza√ß√£o', color='#27ae60', alpha=0.8)\n",
        "\n",
        "ax.set_title('üß† Catastrophic Forgetting em A√ß√£o', fontsize=16, fontweight='bold')\n",
        "ax.set_ylabel('Performance (%)')\n",
        "ax.set_xlabel('Sequ√™ncia de Treinamento')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(tarefas)\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate(f'{height}%',\n",
        "                   xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                   xytext=(0, 3),\n",
        "                   textcoords=\"offset points\",\n",
        "                   ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üîç Observa√ß√µes:\")\n",
        "print(\"‚Ä¢ Performance na Tarefa A cai drasticamente sem estrat√©gias\")\n",
        "print(\"‚Ä¢ Regulariza√ß√£o ajuda a manter conhecimento anterior\")\n",
        "print(\"‚Ä¢ √â um trade-off entre aprender novo e manter antigo\")\n",
        "print(\"\\nüí° Solu√ß√µes: EWC, L2 regularization, rehearsal learning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÆ Pipeline Completo: Do Texto Bruto ao Modelo\n\nVamos ver todo o processo completo, do come√ßo ao fim:\n\n```mermaid\ngraph TB\n    subgraph \"üìö Dados\"\n        A[Web Scraping] --> B[Livros]\n        C[Wikipedia] --> B\n        D[Artigos] --> B\n        B --> E[Dataset Bruto]\n    end\n    \n    subgraph \"üßπ Pr√©-processamento\"\n        E --> F[Limpeza]\n        F --> G[Deduplica√ß√£o]\n        G --> H[Tokeniza√ß√£o]\n    end\n    \n    subgraph \"üèãÔ∏è Treinamento\"\n        H --> I[Pr√©-treinamento]\n        I --> J[Modelo Base]\n        J --> K[Fine-tuning]\n        K --> L[RLHF]\n    end\n    \n    subgraph \"üéØ Resultado\"\n        L --> M[Modelo Final]\n    end\n    \n    style E fill:#3498db\n    style J fill:#f39c12\n    style M fill:#27ae60\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estimativas de recursos para diferentes tamanhos de modelo\n",
        "modelos = ['GPT-2\\n(1.5B)', 'GPT-3\\n(175B)', 'PaLM\\n(540B)', 'GPT-4\\n(~1T)']\n",
        "parametros = [1.5, 175, 540, 1000]  # Em bilh√µes\n",
        "custo_treinamento = [50000, 4600000, 15000000, 100000000]  # Em d√≥lares (estimativa)\n",
        "gpus_necessarias = [8, 1024, 3000, 10000]  # GPUs A100\n",
        "tempo_treinamento = [7, 30, 45, 90]  # Em dias\n",
        "\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('üí∞ Recursos Necess√°rios por Tamanho de Modelo', fontsize=16, fontweight='bold')\n",
        "\n",
        "colors = ['#3498db', '#e74c3c', '#f39c12', '#9b59b6']\n",
        "\n",
        "# Par√¢metros\n",
        "bars1 = ax1.bar(modelos, parametros, color=colors)\n",
        "ax1.set_title('üìä N√∫mero de Par√¢metros')\n",
        "ax1.set_ylabel('Bilh√µes de Par√¢metros')\n",
        "ax1.set_yscale('log')\n",
        "\n",
        "# Custo\n",
        "bars2 = ax2.bar(modelos, custo_treinamento, color=colors)\n",
        "ax2.set_title('üí∏ Custo de Treinamento')\n",
        "ax2.set_ylabel('D√≥lares (USD)')\n",
        "ax2.set_yscale('log')\n",
        "\n",
        "# GPUs\n",
        "bars3 = ax3.bar(modelos, gpus_necessarias, color=colors)\n",
        "ax3.set_title('üñ•Ô∏è GPUs Necess√°rias')\n",
        "ax3.set_ylabel('N√∫mero de GPUs A100')\n",
        "ax3.set_yscale('log')\n",
        "\n",
        "# Tempo\n",
        "bars4 = ax4.bar(modelos, tempo_treinamento, color=colors)\n",
        "ax4.set_title('‚è∞ Tempo de Treinamento')\n",
        "ax4.set_ylabel('Dias')\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for ax, values in [(ax1, parametros), (ax2, custo_treinamento), (ax3, gpus_necessarias), (ax4, tempo_treinamento)]:\n",
        "    bars = ax.patches\n",
        "    for bar, value in zip(bars, values):\n",
        "        height = bar.get_height()\n",
        "        if ax == ax2:  # Custo em milh√µes\n",
        "            label = f'${value/1000000:.1f}M' if value >= 1000000 else f'${value/1000:.0f}K'\n",
        "        elif ax == ax1:  # Par√¢metros\n",
        "            label = f'{value}B'\n",
        "        else:\n",
        "            label = f'{value}'\n",
        "        \n",
        "        ax.annotate(label,\n",
        "                   xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                   xytext=(0, 3),\n",
        "                   textcoords=\"offset points\",\n",
        "                   ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ü§Ø Fatos impressionantes:\")\n",
        "print(f\"‚Ä¢ GPT-4 custou ~$100M para treinar (estimativa)\")\n",
        "print(f\"‚Ä¢ Precisou de ~10,000 GPUs A100 por 3 meses\")\n",
        "print(f\"‚Ä¢ Isso √© mais que o PIB de alguns pa√≠ses pequenos!\")\n",
        "print(f\"‚Ä¢ Por isso que fine-tuning √© t√£o importante! üí°\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exerc√≠cio Final: An√°lise de Estrat√©gias\n\n**Cen√°rio**: Voc√™ trabalha numa startup e precisa criar um chatbot para atendimento ao cliente. Voc√™ tem:\n- Or√ßamento: $10,000\n- Prazo: 2 semanas \n- Hardware: 1 GPU A100\n- Dataset: 50,000 conversas de atendimento\n\n**Sua miss√£o**: Escolha a melhor estrat√©gia e justifique!\n\n**Op√ß√µes**:\n1. Treinar do zero um modelo pequeno\n2. Fine-tuning completo do Llama-2 7B\n3. LoRA fine-tuning do Llama-2 13B\n4. Prompt engineering com GPT-4 via API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ü§î EXERC√çCIO FINAL: An√°lise de estrat√©gias\n",
        "# Complete a an√°lise abaixo!\n",
        "\n",
        "estrategias_analise = {\n",
        "    'Treinar do Zero': {\n",
        "        'custo': 8000,\n",
        "        'tempo_dias': 10,\n",
        "        'performance_estimada': 70,\n",
        "        'controle': 100,\n",
        "        'risco': 80\n",
        "    },\n",
        "    'Fine-tuning Llama-2 7B': {\n",
        "        'custo': 2000,\n",
        "        'tempo_dias': 3,\n",
        "        'performance_estimada': 85,\n",
        "        'controle': 80,\n",
        "        'risco': 30\n",
        "    },\n",
        "    'LoRA Llama-2 13B': {\n",
        "        'custo': 1500,\n",
        "        'tempo_dias': 2,\n",
        "        'performance_estimada': 88,\n",
        "        'controle': 70,\n",
        "        'risco': 20\n",
        "    },\n",
        "    'GPT-4 API': {\n",
        "        'custo': 5000,  # Custo mensal estimado\n",
        "        'tempo_dias': 1,\n",
        "        'performance_estimada': 92,\n",
        "        'controle': 30,\n",
        "        'risco': 40  # Depend√™ncia externa\n",
        "    }\n",
        "}\n",
        "\n",
        "# Visualiza√ß√£o da an√°lise\n",
        "import pandas as pd\n",
        "\n",
        "df_estrategias = pd.DataFrame(estrategias_analise).T\n",
        "print(\"üìä An√°lise das Estrat√©gias:\")\n",
        "print(df_estrategias)\n",
        "\n",
        "# TODO: Complete sua an√°lise aqui!\n",
        "print(\"\\nü§î Minha escolha seria: ___________\")\n",
        "print(\"\\n‚úÖ Justificativa:\")\n",
        "print(\"1. ___________\")\n",
        "print(\"2. ___________\")\n",
        "print(\"3. ___________\")\n",
        "\n",
        "# Dica do Pedro: Considere o trade-off entre custo, tempo, performance e controle!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualiza√ß√£o final da an√°lise de estrat√©gias\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Criando scatter plot\n",
        "for i, (nome, dados) in enumerate(estrategias_analise.items()):\n",
        "    # Plotando custo vs performance, com tamanho do ponto = inverso do tempo\n",
        "    size = 1000 / dados['tempo_dias']  # Quanto menor o tempo, maior o ponto\n",
        "    ax.scatter(dados['custo'], dados['performance_estimada'], \n",
        "              s=size, alpha=0.7, label=nome)\n",
        "    \n",
        "    # Adicionando r√≥tulos\n",
        "    ax.annotate(nome, \n",
        "               (dados['custo'], dados['performance_estimada']),\n",
        "               xytext=(10, 10), textcoords='offset points',\n",
        "               fontsize=10, fontweight='bold')\n",
        "\n",
        "ax.set_xlabel('üí∞ Custo (USD)', fontsize=12)\n",
        "ax.set_ylabel('üéØ Performance Estimada (%)', fontsize=12)\n",
        "ax.set_title('‚öñÔ∏è Trade-off: Custo vs Performance\\n(Tamanho do ponto = Velocidade)', \n",
        "            fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.legend()\n",
        "\n",
        "# Adicionando linhas de refer√™ncia\n",
        "ax.axhline(y=80, color='red', linestyle='--', alpha=0.5, label='Performance M√≠nima')\n",
        "ax.axvline(x=10000, color='orange', linestyle='--', alpha=0.5, label='Or√ßamento M√°ximo')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üéØ Qual estrat√©gia voc√™ escolheria? Pense em:\")\n",
        "print(\"‚Ä¢ Restri√ß√µes de or√ßamento e tempo\")\n",
        "print(\"‚Ä¢ Performance necess√°ria\")\n",
        "print(\"‚Ä¢ Controle sobre o modelo\")\n",
        "print(\"‚Ä¢ Riscos envolvidos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Resumo do M√≥dulo: O que Aprendemos?\n\nUfa! Que jornada, n√© pessoal? Vamos recapitular o que vimos neste m√≥dulo:\n\n### üèÜ **Conceitos Principais:**\n1. **Pr√©-treinamento**: Como LLMs aprendem linguagem (auto-supervisionado)\n2. **Fine-tuning**: Especializando modelos para tarefas espec√≠ficas\n3. **LoRA/QLoRA**: T√©cnicas eficientes para fine-tuning\n4. **Desafios**: Catastrophic forgetting, custo, bias\n\n### üõ†Ô∏è **T√©cnicas Aprendidas:**\n- Prepara√ß√£o de dados para treinamento\n- Implementa√ß√£o de loops de treinamento\n- Estrat√©gias de fine-tuning\n- An√°lise de trade-offs\n\n### üîó **Conex√µes com M√≥dulos Anteriores:**\n- **Tokens** (M√≥dulo 4): Base para preparar dados de treinamento\n- **Embeddings** (M√≥dulo 5): Como o modelo aprende representa√ß√µes\n- **Arquitetura** (M√≥dulo 3): Como os transformers processam durante treinamento\n\n### üöÄ **Preparando para o Pr√≥ximo M√≥dulo:**\nNo **M√≥dulo 8 (Prompting e Engenharia)**, vamos ver como usar esses modelos treinados de forma eficiente, sem precisar retrein√°-los!\n\n**Dica Final do Pedro**: Treinamento √© como cozinhar - voc√™ pode fazer do zero (caro e demorado) ou usar ingredientes prontos e temperar do seu jeito (fine-tuning)! üë®‚Äçüç≥\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/introdu√ß√£o-√†-llms-modulo-07_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéì Certificado de conclus√£o do m√≥dulo!\n",
        "import datetime\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üéì CERTIFICADO DE CONCLUS√ÉO üéì\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\"\"   \n",
        "    Parab√©ns! Voc√™ concluiu o M√≥dulo 7:\n",
        "    \n",
        "    üìö TREINAMENTO E PR√â-TREINAMENTO DE LLMs\n",
        "    \n",
        "    Conceitos dominados:\n",
        "    ‚úÖ Pr√©-treinamento auto-supervisionado\n",
        "    ‚úÖ Fine-tuning e especializa√ß√£o\n",
        "    ‚úÖ T√©cnicas LoRA e QLoRA\n",
        "    ‚úÖ Desafios e solu√ß√µes do treinamento\n",
        "    ‚úÖ An√°lise de trade-offs e estrat√©gias\n",
        "    \n",
        "    Data: {datetime.datetime.now().strftime('%d/%m/%Y')}\n",
        "    Instrutor: Pedro Nunes Guth\n",
        "    \n",
        "    üöÄ Pr√≥ximo: M√≥dulo 8 - Prompting e Engenharia\n",
        "\"\"\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nüî• Voc√™ est√° no caminho certo para dominar LLMs!\")\n",
        "print(\"üí™ Continue praticando e experimentando!\")\n",
        "print(\"üìö Nos vemos no pr√≥ximo m√≥dulo!\")\n",
        "\n",
        "# Easter egg: Estat√≠sticas do m√≥dulo\n",
        "print(\"\\nüìä Estat√≠sticas deste m√≥dulo:\")\n",
        "print(f\"‚Ä¢ C√©lulas de c√≥digo executadas: {len([cell for cell in globals() if not cell.startswith('_')])}\")\n",
        "print(f\"‚Ä¢ Conceitos apresentados: 15+\")\n",
        "print(f\"‚Ä¢ Gr√°ficos criados: 8\")\n",
        "print(f\"‚Ä¢ Exerc√≠cios propostos: 2\")\n",
        "print(f\"‚Ä¢ Dicas do Pedro: 10+\")\n",
        "print(\"\\nüéØ Voc√™ est√° pronto para os prompts! Bora pro M√≥dulo 8! üöÄ\")"
      ]
    }
  ]
}