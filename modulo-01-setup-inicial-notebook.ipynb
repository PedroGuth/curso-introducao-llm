{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🚀 Setup Inicial para LLMs: Preparando sua Nave Espacial para Decolar!\n\n**Módulo 1 de 13 - Curso: Introdução à LLMs**\n\n*Por Pedro Nunes Guth*\n\n---\n\nE aí, pessoal! Tá, mas antes de sairmos por aí criando chatbots inteligentes e conversando com IAs como se fossem nossos melhores amigos, precisamos fazer o básico: **SETUP INICIAL**!\n\nPensa assim: você não vai dirigir um carro sem antes ajustar o banco, os espelhos e ligar o motor, né? Com LLMs é a mesma coisa! Vamos preparar todo o ambiente para que você possa explorar esse mundo incrível das Large Language Models sem dor de cabeça.\n\n## O que vamos aprender hoje:\n\n1. **Ambiente de Desenvolvimento**: Como configurar tudo certinho\n2. **Bibliotecas Essenciais**: As ferramentas que vão ser suas melhores amigas\n3. **APIs e Tokens**: Como se conectar com os modelos\n4. **Primeiros Testes**: Vamos fazer funcionar!\n5. **Troubleshooting**: Quando as coisas dão errado (e sempre dão! 😅)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🏗️ Por que o Setup é TÃO Importante?\n\nOlha só, imagina que você é um chef que vai preparar um banquete incrível. Antes de começar a cozinhar, você precisa:\n\n- ✅ Organizar a cozinha\n- ✅ Separar os ingredientes\n- ✅ Preparar os utensílios\n- ✅ Testar se o fogão funciona\n\nCom LLMs é **exatamente** a mesma coisa! Se você pular essa etapa, vai ficar igual aquele meme do cachorrinho na casa pegando fogo falando \"This is fine\" 🔥🐕\n\n### Analogia do Pedro:\n\nO setup inicial é como preparar a sua **\"bancada de trabalho digital\"**. Você não constrói uma casa começando pelo telhado, né? Primeiro vem a fundação, depois as paredes, e só então o telhado. Aqui é igual:\n\n1. **Fundação**: Python + Jupyter\n2. **Paredes**: Bibliotecas essenciais\n3. **Telhado**: APIs e modelos funcionando\n\n**Dica do Pedro**: Nunca, JAMAIS, pule o setup! Eu já vi gente passar 3 dias debugando um código que não funcionava simplesmente porque uma biblioteca estava desatualizada. Não seja essa pessoa! 😂"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos começar verificando nossa versão do Python\n# É como checar se temos a chave de fenda certa antes de montar um móvel!\n\nimport sys\nimport platform\nfrom datetime import datetime\n\nprint(\"🐍 DIAGNÓSTICO DO AMBIENTE PYTHON 🐍\")\nprint(\"=\" * 50)\nprint(f\"Versão do Python: {sys.version}\")\nprint(f\"Sistema Operacional: {platform.system()} {platform.release()}\")\nprint(f\"Arquitetura: {platform.machine()}\")\nprint(f\"Data/Hora atual: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\nprint(\"=\" * 50)\n\n# Verificação se estamos no ambiente certo\nif sys.version_info >= (3, 8):\n    print(\"✅ Python versão OK! Bora continuar!\")\nelse:\n    print(\"⚠️  Opa! Recomendo Python 3.8+ para trabalhar com LLMs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📚 As Bibliotecas que Vão Ser Suas Melhores Amigas\n\nTá, agora vamos instalar as bibliotecas essenciais. Pensa nelas como os **ingredientes básicos** da sua despensa digital:\n\n### Bibliotecas Fundamentais:\n\n- **🤗 Transformers**: A biblioteca da Hugging Face (é tipo o \"Netflix dos modelos de IA\")\n- **🔥 Torch**: Para trabalhar com redes neurais (é o motor do carro)\n- **📊 Numpy/Pandas**: Para manipular dados (seus assistentes de cozinha)\n- **📈 Matplotlib**: Para fazer gráficos bonitos (o Instagram dos seus dados)\n- **🌐 Requests**: Para fazer chamadas de API (seu correio digital)\n- **🔑 Python-dotenv**: Para guardar suas chaves secretas (seu cofre digital)\n\n**Dica do Pedro**: Sempre instale as bibliotecas uma por uma primeiro. É como montar um lego - se você misturar todas as peças de uma vez, vira uma bagunça!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos instalar as bibliotecas essenciais!\n# Descomenta as linhas abaixo se estiver rodando localmente\n\n# !pip install transformers torch numpy pandas matplotlib requests python-dotenv\n# !pip install openai tiktoken\n# !pip install ipywidgets tqdm\n\n# Para o Google Colab, algumas já vêm instaladas, mas vamos garantir:\nprint(\"🔧 Instalando/Verificando bibliotecas essenciais...\")\nprint(\"(Se estiver no Colab, algumas já estão instaladas!)\")\n\n# Lista das bibliotecas que vamos usar no curso\nbibliotecas_essenciais = [\n    'transformers',\n    'torch', \n    'numpy',\n    'pandas',\n    'matplotlib',\n    'requests',\n    'openai',\n    'tiktoken'\n]\n\nprint(\"\\n📋 Lista de bibliotecas para este curso:\")\nfor i, lib in enumerate(bibliotecas_essenciais, 1):\n    print(f\"{i:2d}. {lib}\")\n    \nprint(\"\\n✨ Liiindo! Agora vamos testar se tudo está funcionando...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando as importações - é como testar se todos os ingredientes estão na despensa!\n\nprint(\"🧪 TESTE DAS IMPORTAÇÕES 🧪\")\nprint(\"=\" * 40)\n\nbibliotecas_teste = {\n    'numpy': 'np',\n    'pandas': 'pd', \n    'matplotlib.pyplot': 'plt',\n    'requests': 'requests',\n    'json': 'json',\n    'os': 'os',\n    'sys': 'sys'\n}\n\nbibliotecas_ok = []\nbibliotecas_erro = []\n\nfor biblioteca, alias in bibliotecas_teste.items():\n    try:\n        exec(f\"import {biblioteca} as {alias}\")\n        print(f\"✅ {biblioteca:<20} | OK!\")\n        bibliotecas_ok.append(biblioteca)\n    except ImportError as e:\n        print(f\"❌ {biblioteca:<20} | ERRO: {str(e)}\")\n        bibliotecas_erro.append(biblioteca)\n\nprint(\"\\n\" + \"=\" * 40)\nprint(f\"✅ Funcionando: {len(bibliotecas_ok)}/{len(bibliotecas_teste)}\")\nif bibliotecas_erro:\n    print(f\"❌ Com problemas: {bibliotecas_erro}\")\nelse:\n    print(\"🎉 Todas as bibliotecas básicas estão funcionando! Liiindo!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔑 Configurando APIs e Tokens\n\nAgora vem a parte importante: configurar o acesso às APIs dos modelos de linguagem. É como ter as **chaves da cidade** - sem elas, você não entra em lugar nenhum!\n\n### Como funciona?\n\nPensa assim: as APIs são como **restaurantes exclusivos**. Você precisa de uma \"reserva\" (token/chave) para entrar. Cada provedor tem seu próprio sistema:\n\n- **OpenAI**: Para GPT-3.5, GPT-4, etc.\n- **Anthropic**: Para Claude\n- **Google**: Para PaLM, Gemini\n- **Hugging Face**: Para modelos open-source\n\n### Estrutura de um Token:\n```\nOpenAI: sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\nHugging Face: hf_xxxxxxxxxxxxxxxxxxxxxxxxx\n```\n\n**Dica do Pedro**: NUNCA, mas NUNCA MESMO, coloque suas chaves diretamente no código! É como deixar a chave de casa na porta com um bilhetinho \"pode entrar\". Use sempre variáveis de ambiente ou arquivos .env!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuração segura de variáveis de ambiente\n# É como ter um cofre digital para suas chaves!\n\nimport os\nfrom pathlib import Path\n\n# Função para configurar variáveis de ambiente de forma segura\ndef configurar_ambiente():\n    \"\"\"\n    Configura as variáveis de ambiente necessárias para o curso.\n    Esta é a forma CORRETA de fazer!\n    \"\"\"\n    \n    print(\"🔐 CONFIGURAÇÃO DE AMBIENTE SEGURO 🔐\")\n    print(\"=\" * 45)\n    \n    # Variáveis de ambiente que vamos usar no curso\n    variaveis_necessarias = [\n        'OPENAI_API_KEY',\n        'HUGGING_FACE_TOKEN',\n        'ANTHROPIC_API_KEY'\n    ]\n    \n    for var in variaveis_necessarias:\n        valor = os.getenv(var)\n        if valor:\n            # Mostra apenas os primeiros e últimos caracteres por segurança\n            valor_mascarado = f\"{valor[:8]}...{valor[-4:]}\"\n            print(f\"✅ {var:<20} | Configurada ({valor_mascarado})\")\n        else:\n            print(f\"⚠️  {var:<20} | Não configurada\")\n    \n    print(\"\\n💡 Para configurar suas chaves:\")\n    print(\"1. Crie um arquivo .env na raiz do projeto\")\n    print(\"2. Adicione: OPENAI_API_KEY=sua_chave_aqui\")\n    print(\"3. Use python-dotenv para carregar\")\n    \n    return True\n\n# Executa a configuração\nconfigurar_ambiente()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo de como criar um arquivo .env (NÃO EXECUTE com chaves reais aqui!)\n# Este é apenas um exemplo educativo!\n\nexemplo_env = \"\"\"\n# Arquivo .env - EXEMPLO\n# NUNCA compartilhe este arquivo!\n\n# OpenAI (para GPT-3.5, GPT-4)\nOPENAI_API_KEY=sk-sua_chave_super_secreta_aqui\n\n# Hugging Face (para modelos open-source)  \nHUGGING_FACE_TOKEN=hf_sua_chave_hugging_face_aqui\n\n# Anthropic (para Claude)\nANTHROPIC_API_KEY=sk-ant-sua_chave_anthropic_aqui\n\n# Configurações gerais\nENVIRONMENT=development\nDEBUG=True\n\"\"\"\n\nprint(\"📝 EXEMPLO DE ARQUIVO .env\")\nprint(\"=\" * 30)\nprint(exemplo_env)\n\nprint(\"\\n🚨 LEMBRETE IMPORTANTE:\")\nprint(\"• Adicione .env no seu .gitignore\")\nprint(\"• Nunca faça commit de chaves reais\")\nprint(\"• Use sempre variáveis de ambiente em produção\")\nprint(\"• Rotacione suas chaves periodicamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Estrutura de Pastas: Organizando sua Casa Digital\n\nTá, agora vamos organizar nosso projeto como gente grande! Pensa na estrutura de pastas como a **planta da sua casa**: cada cômodo tem sua função específica.\n\n### Estrutura Recomendada:\n\n```\ncurso-llms/\n├── 📁 notebooks/          # Nossos Jupyter notebooks\n├── 📁 data/              # Dados para treinamento/teste\n├── 📁 models/            # Modelos salvos localmente\n├── 📁 utils/             # Funções utilitárias\n├── 📁 config/            # Arquivos de configuração\n├── 📄 .env               # Variáveis de ambiente (SECRETO!)\n├── 📄 .gitignore         # O que NÃO vai pro Git\n├── 📄 requirements.txt   # Lista de dependências\n└── 📄 README.md          # Manual do projeto\n```\n\n**Dica do Pedro**: Uma pasta organizada é como uma cozinha organizada - você encontra tudo rapidinho e não fica procurando a colher no meio das panelas!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar a estrutura de pastas automaticamente!\n# É como ter um assistente que organiza sua casa pra você\n\nimport os\nfrom pathlib import Path\n\ndef criar_estrutura_projeto():\n    \"\"\"\n    Cria a estrutura de pastas recomendada para o curso de LLMs\n    \"\"\"\n    \n    # Define a estrutura do projeto\n    estrutura = {\n        'notebooks': 'Jupyter notebooks do curso',\n        'notebooks/modulo_01': 'Setup Inicial', \n        'notebooks/modulo_02': 'O que são LLMs',\n        'notebooks/modulo_03': 'Arquitetura Transformer',\n        'data': 'Datasets e arquivos de dados',\n        'data/raw': 'Dados brutos',\n        'data/processed': 'Dados processados',\n        'models': 'Modelos salvos localmente',\n        'utils': 'Funções utilitárias e helpers',\n        'config': 'Arquivos de configuração',\n        'examples': 'Exemplos práticos',\n        'tests': 'Testes unitários'\n    }\n    \n    print(\"🏗️  CRIANDO ESTRUTURA DO PROJETO 🏗️\")\n    print(\"=\" * 40)\n    \n    base_path = Path('curso-llms')\n    \n    for pasta, descricao in estrutura.items():\n        caminho = base_path / pasta\n        \n        # Cria a pasta se não existir\n        if not caminho.exists():\n            caminho.mkdir(parents=True, exist_ok=True)\n            status = \"✅ CRIADA\"\n        else:\n            status = \"📁 EXISTE\"\n            \n        print(f\"{status} {str(caminho):<30} | {descricao}\")\n    \n    print(\"\\n🎉 Estrutura criada com sucesso!\")\n    return base_path\n\n# Executa a criação (descomente para usar)\n# projeto_path = criar_estrutura_projeto()\n\nprint(\"💡 Dica: Descomente a linha acima para criar a estrutura real!\")\nprint(\"📝 Cada pasta tem um propósito específico no desenvolvimento de LLMs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 Visualizando Nossa Arquitetura de Setup\n\nVamos criar um diagrama para visualizar como tudo se conecta! É como ter um **mapa do tesouro** do nosso ambiente de desenvolvimento.\n\nO fluxo é assim: você escreve código no Jupyter → acessa APIs com tokens → processa dados → visualiza resultados. Simples assim!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar uma visualização da nossa arquitetura de setup!\n# É como desenhar a planta da nossa \"casa digital\"\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib.patches import FancyBboxPatch\nimport numpy as np\n\nplt.style.use('default')\nfig, ax = plt.subplots(1, 1, figsize=(14, 10))\n\n# Define cores do tema\ncor_ambiente = '#E8F4FD'\ncor_biblioteca = '#B8E6B8' \ncor_api = '#FFE4B5'\ncor_dados = '#E6E6FA'\ncor_output = '#FFB6C1'\n\n# Função para criar caixas estilizadas\ndef criar_caixa(ax, x, y, width, height, texto, cor, texto_cor='black'):\n    caixa = FancyBboxPatch(\n        (x, y), width, height,\n        boxstyle=\"round,pad=0.02\",\n        facecolor=cor,\n        edgecolor='gray',\n        linewidth=1.5\n    )\n    ax.add_patch(caixa)\n    ax.text(x + width/2, y + height/2, texto, \n            ha='center', va='center', \n            fontsize=10, weight='bold',\n            color=texto_cor, wrap=True)\n\n# Título\nax.text(0.5, 0.95, '🚀 Arquitetura do Setup para LLMs', \n        ha='center', va='center', fontsize=16, weight='bold',\n        transform=ax.transAxes)\n\n# Camada 1: Ambiente Base\ncriar_caixa(ax, 0.1, 0.8, 0.8, 0.1, \n           '🐍 AMBIENTE BASE\\nPython 3.8+ | Jupyter Notebook | Sistema Operacional', \n           cor_ambiente)\n\n# Camada 2: Bibliotecas\nbibliotecas = [\n    ('🤗 Transformers\\nModelos pré-treinados', 0.05, 0.65),\n    ('🔥 PyTorch\\nRedes neurais', 0.25, 0.65),\n    ('📊 Pandas/Numpy\\nManipulação de dados', 0.45, 0.65),\n    ('📈 Matplotlib\\nVisualizações', 0.65, 0.65),\n    ('🌐 Requests\\nChamadas HTTP', 0.85, 0.65)\n]\n\nfor texto, x, y in bibliotecas:\n    criar_caixa(ax, x, y, 0.15, 0.12, texto, cor_biblioteca)\n\n# Camada 3: APIs e Tokens\napis = [\n    ('🔑 OpenAI API\\nGPT-3.5/4', 0.15, 0.45),\n    ('🤖 Hugging Face\\nModelos Open Source', 0.35, 0.45),\n    ('🧠 Anthropic\\nClaude', 0.55, 0.45),\n    ('🔐 Variáveis ENV\\nSegurança', 0.75, 0.45)\n]\n\nfor texto, x, y in apis:\n    criar_caixa(ax, x, y, 0.18, 0.12, texto, cor_api)\n\n# Camada 4: Processamento\ncriar_caixa(ax, 0.2, 0.28, 0.6, 0.1, \n           '⚙️ PROCESSAMENTO\\nTokenização | Embeddings | Inferência | Fine-tuning', \n           cor_dados)\n\n# Camada 5: Output\noutputs = [\n    ('📝 Texto Gerado', 0.1, 0.08),\n    ('📊 Análises', 0.3, 0.08), \n    ('🎯 Classificações', 0.5, 0.08),\n    ('💬 Chatbots', 0.7, 0.08)\n]\n\nfor texto, x, y in outputs:\n    criar_caixa(ax, x, y, 0.18, 0.1, texto, cor_output)\n\n# Setas conectando as camadas\narrow_props = dict(arrowstyle='->', lw=2, color='#666666')\n\n# Setas verticais\nfor x in [0.2, 0.4, 0.6, 0.8]:\n    ax.annotate('', xy=(x, 0.8), xytext=(x, 0.77), arrowprops=arrow_props)\n    ax.annotate('', xy=(x, 0.65), xytext=(x, 0.57), arrowprops=arrow_props)\n    ax.annotate('', xy=(x, 0.45), xytext=(x, 0.38), arrowprops=arrow_props)\n    ax.annotate('', xy=(x, 0.28), xytext=(x, 0.18), arrowprops=arrow_props)\n\n# Configurações do gráfico\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)\nax.axis('off')\n\n# Legenda\nlegenda_texto = '''\n🎯 Fluxo do Setup:\n1. Ambiente Python configurado\n2. Bibliotecas instaladas\n3. APIs configuradas com segurança\n4. Processamento dos dados\n5. Resultados gerados\n'''\n\nax.text(0.02, 0.25, legenda_texto, fontsize=9, \n        bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='white', alpha=0.8),\n        verticalalignment='top')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n🎨 Liiindo! Este é o nosso mapa do tesouro para o setup de LLMs!\")\nprint(\"📝 Cada camada depende da anterior - é como construir uma casa!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🧪 Primeiro Teste: \"Hello World\" com LLMs!\n\nAgora vem a parte mais divertida: vamos fazer nosso primeiro teste! É como dar a primeira volta de chave no carro depois de montá-lo.\n\nVamos fazer um teste simples usando uma biblioteca que simula interações com LLMs, para garantir que tudo está funcionando certinho.\n\n**Dica do Pedro**: Sempre comece com testes simples! É como aprender a andar antes de correr. Se o básico não funciona, o complexo também não vai funcionar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar nosso primeiro teste de LLM!\n# É como dizer \"oi\" para a IA pela primeira vez 👋\n\nimport json\nimport random\nfrom datetime import datetime\n\n# Simulador simples de LLM para teste (enquanto não configuramos APIs reais)\nclass SimuladorLLM:\n    \"\"\"\n    Classe que simula um LLM básico para testes de setup.\n    Na vida real, usaremos APIs como OpenAI, mas isto é só para testar!\n    \"\"\"\n    \n    def __init__(self, nome=\"GPT-Simulado\"):\n        self.nome = nome\n        self.respostas_predefinidas = [\n            \"Olá! Seu setup está funcionando perfeitamente! 🎉\",\n            \"Oi! Parece que tudo está configurado corretamente! ✅\",\n            \"Hello! Your LLM environment is ready to go! 🚀\",\n            \"Seu ambiente de desenvolvimento está pronto para LLMs! 💪\",\n            \"Setup concluído com sucesso! Agora é só partir para o abraço! 🤗\"\n        ]\n    \n    def gerar_resposta(self, prompt, temperatura=0.7):\n        \"\"\"\n        Simula uma resposta de LLM baseada no prompt\n        \"\"\"\n        \n        # Simula processamento\n        import time\n        time.sleep(1)  # Simula latência da API\n        \n        # Escolhe uma resposta baseada no prompt\n        if \"hello\" in prompt.lower() or \"oi\" in prompt.lower():\n            resposta = random.choice(self.respostas_predefinidas)\n        else:\n            resposta = f\"Recebi seu prompt: '{prompt}'. Setup funcionando! ✨\"\n        \n        return {\n            'modelo': self.nome,\n            'prompt': prompt,\n            'resposta': resposta,\n            'timestamp': datetime.now().isoformat(),\n            'temperatura': temperatura,\n            'tokens_usados': len(prompt.split()) + len(resposta.split())\n        }\n\n# Vamos testar nosso simulador!\nprint(\"🧪 PRIMEIRO TESTE DE LLM 🧪\")\nprint(\"=\" * 35)\n\n# Cria uma instância do simulador\nllm_teste = SimuladorLLM(\"Pedro-GPT-Test\")\n\n# Lista de prompts para testar\nprompts_teste = [\n    \"Oi! Meu setup está funcionando?\",\n    \"Hello! Is my environment ready?\", \n    \"Teste de configuração do ambiente\",\n    \"Como você está hoje?\"\n]\n\n# Executa os testes\nresultados = []\n\nfor i, prompt in enumerate(prompts_teste, 1):\n    print(f\"\\n📝 Teste {i}: {prompt}\")\n    print(\"⏳ Processando...\")\n    \n    resultado = llm_teste.gerar_resposta(prompt)\n    resultados.append(resultado)\n    \n    print(f\"🤖 Resposta: {resultado['resposta']}\")\n    print(f\"📊 Tokens usados: {resultado['tokens_usados']}\")\n\nprint(\"\\n\" + \"=\" * 35)\nprint(f\"✅ Todos os {len(prompts_teste)} testes concluídos!\")\nprint(\"🎉 Seu ambiente está PRONTO para LLMs reais!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos analisar os resultados dos nossos testes!\n# É como fazer um \"checkup\" do nosso sistema\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Análise dos resultados dos testes\ntokens_por_teste = [r['tokens_usados'] for r in resultados]\ntempos_resposta = [1.0 + random.uniform(-0.2, 0.3) for _ in resultados]  # Simula tempos\n\n# Criar visualização dos resultados\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n\n# Gráfico 1: Tokens por teste\nax1.bar(range(1, len(tokens_por_teste) + 1), tokens_por_teste, \n        color='skyblue', edgecolor='navy', linewidth=1.5)\nax1.set_title('📊 Tokens Usados por Teste', fontsize=14, weight='bold')\nax1.set_xlabel('Número do Teste')\nax1.set_ylabel('Quantidade de Tokens')\nax1.grid(axis='y', alpha=0.3)\n\n# Adiciona valores nas barras\nfor i, v in enumerate(tokens_por_teste):\n    ax1.text(i + 1, v + 0.5, str(v), ha='center', va='bottom', weight='bold')\n\n# Gráfico 2: Tempo de resposta simulado\nax2.plot(range(1, len(tempos_resposta) + 1), tempos_resposta, \n         marker='o', linewidth=3, markersize=8, color='green')\nax2.set_title('⏱️ Tempo de Resposta (simulado)', fontsize=14, weight='bold')\nax2.set_xlabel('Número do Teste')\nax2.set_ylabel('Tempo (segundos)')\nax2.grid(alpha=0.3)\nax2.set_ylim(0, max(tempos_resposta) * 1.2)\n\n# Adiciona valores nos pontos\nfor i, v in enumerate(tempos_resposta):\n    ax2.text(i + 1, v + 0.05, f'{v:.2f}s', ha='center', va='bottom', weight='bold')\n\nplt.tight_layout()\nplt.show()\n\n# Relatório de status do setup\nprint(\"\\n📋 RELATÓRIO DE STATUS DO SETUP\")\nprint(\"=\" * 40)\nprint(f\"✅ Testes executados: {len(resultados)}\")\nprint(f\"📊 Média de tokens por teste: {np.mean(tokens_por_teste):.1f}\")\nprint(f\"⏱️ Tempo médio de resposta: {np.mean(tempos_resposta):.2f}s\")\nprint(f\"🎯 Taxa de sucesso: 100%\")\nprint(\"\\n🎉 STATUS: AMBIENTE PRONTO PARA LLMs REAIS!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔧 Troubleshooting: Quando as Coisas Dão Errado\n\nTá, vamos falar do elefante na sala: **as coisas VÃO dar errado**. E tá tudo bem! É como aprender a dirigir - todo mundo bate o carro no poste pelo menos uma vez (metaforicamente falando! 😅).\n\nVou te ensinar os problemas mais comuns e como resolver cada um deles:\n\n### 🚨 Problemas Mais Comuns:\n\n1. **Erro de importação**: \"ModuleNotFoundError\"\n2. **Problemas de versão**: Conflitos entre bibliotecas\n3. **Erro de API**: Chaves inválidas ou expiradas\n4. **Problemas de memória**: Modelos muito grandes\n5. **Timeout**: Conexão lenta ou instável\n\n**Dica do Pedro**: Mantenha sempre um \"kit de primeiros socorros\" para debugging. É como ter uma caixa de ferramentas - você nunca sabe quando vai precisar!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sistema de diagnóstico automático!\n# É como ter um \"doutor\" para o seu ambiente de desenvolvimento\n\nimport sys\nimport subprocess\nimport importlib\nfrom pathlib import Path\n\nclass DiagnosticadorLLM:\n    \"\"\"\n    Classe que faz diagnóstico completo do ambiente de LLMs\n    É como ter um médico para o seu setup!\n    \"\"\"\n    \n    def __init__(self):\n        self.problemas_encontrados = []\n        self.solucoes_sugeridas = []\n    \n    def verificar_python(self):\n        \"\"\"Verifica se a versão do Python está adequada\"\"\"\n        versao = sys.version_info\n        \n        if versao.major == 3 and versao.minor >= 8:\n            return True, f\"✅ Python {versao.major}.{versao.minor} OK\"\n        else:\n            problema = f\"❌ Python {versao.major}.{versao.minor} muito antigo\"\n            solucao = \"💡 Instale Python 3.8+\"\n            self.problemas_encontrados.append(problema)\n            self.solucoes_sugeridas.append(solucao)\n            return False, problema\n    \n    def verificar_bibliotecas(self):\n        \"\"\"Verifica se as bibliotecas essenciais estão instaladas\"\"\"\n        bibliotecas_essenciais = [\n            'numpy', 'pandas', 'matplotlib', 'requests', 'json', 'os'\n        ]\n        \n        bibliotecas_opcionais = [\n            'transformers', 'torch', 'openai', 'tiktoken'\n        ]\n        \n        resultados = {}\n        \n        # Testa bibliotecas essenciais\n        for lib in bibliotecas_essenciais:\n            try:\n                importlib.import_module(lib)\n                resultados[lib] = \"✅ OK\"\n            except ImportError:\n                erro = f\"❌ {lib} não encontrada\"\n                solucao = f\"💡 Execute: pip install {lib}\"\n                resultados[lib] = erro\n                self.problemas_encontrados.append(erro)\n                self.solucoes_sugeridas.append(solucao)\n        \n        # Testa bibliotecas opcionais (para LLMs)\n        for lib in bibliotecas_opcionais:\n            try:\n                importlib.import_module(lib)\n                resultados[lib] = \"✅ OK (LLM pronto)\"\n            except ImportError:\n                resultados[lib] = \"⚠️ Opcional (instale para LLMs reais)\"\n        \n        return resultados\n    \n    def verificar_ambiente(self):\n        \"\"\"Verifica variáveis de ambiente\"\"\"\n        variaveis_importantes = [\n            'OPENAI_API_KEY',\n            'HUGGING_FACE_TOKEN', \n            'PATH'\n        ]\n        \n        resultados = {}\n        \n        for var in variaveis_importantes:\n            valor = os.getenv(var)\n            if valor:\n                if 'KEY' in var or 'TOKEN' in var:\n                    # Mascarar chaves sensíveis\n                    valor_mostrar = f\"{valor[:8]}...{valor[-4:]}\" if len(valor) > 12 else \"[CONFIGURADA]\"\n                    resultados[var] = f\"✅ {valor_mostrar}\"\n                else:\n                    resultados[var] = \"✅ Configurada\"\n            else:\n                if var == 'PATH':\n                    resultados[var] = \"❌ PATH não encontrada (problema sério!)\"\n                else:\n                    resultados[var] = \"⚠️ Não configurada (configure para APIs)\"\n        \n        return resultados\n    \n    def executar_diagnostico_completo(self):\n        \"\"\"Executa diagnóstico completo do ambiente\"\"\"\n        print(\"🔍 DIAGNÓSTICO COMPLETO DO AMBIENTE 🔍\")\n        print(\"=\" * 45)\n        \n        # 1. Verificar Python\n        python_ok, python_status = self.verificar_python()\n        print(f\"\\n🐍 Python: {python_status}\")\n        \n        # 2. Verificar bibliotecas\n        print(\"\\n📚 Bibliotecas:\")\n        libs_status = self.verificar_bibliotecas()\n        for lib, status in libs_status.items():\n            print(f\"   {lib:<15} | {status}\")\n        \n        # 3. Verificar ambiente\n        print(\"\\n🔐 Variáveis de Ambiente:\")\n        env_status = self.verificar_ambiente()\n        for var, status in env_status.items():\n            print(f\"   {var:<20} | {status}\")\n        \n        # 4. Resumo\n        print(\"\\n\" + \"=\" * 45)\n        if self.problemas_encontrados:\n            print(f\"⚠️ Problemas encontrados: {len(self.problemas_encontrados)}\")\n            print(\"\\n🔧 SOLUÇÕES SUGERIDAS:\")\n            for i, solucao in enumerate(self.solucoes_sugeridas, 1):\n                print(f\"   {i}. {solucao}\")\n        else:\n            print(\"🎉 Nenhum problema crítico encontrado!\")\n            print(\"✨ Seu ambiente está pronto para LLMs!\")\n        \n        return len(self.problemas_encontrados) == 0\n\n# Executa o diagnóstico\ndiagnosticador = DiagnosticadorLLM()\nambiente_ok = diagnosticador.executar_diagnostico_completo()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Exercício Prático: Monte Seu Próprio Setup!\n\nAgora é sua vez de botar a mão na massa! Vou te dar um desafio prático para fixar tudo que aprendemos.\n\n### 🏆 DESAFIO 1: Detector de Setup\n\nCrie uma função que verifica se seu ambiente está 100% pronto para o curso de LLMs. A função deve:\n\n1. ✅ Verificar versão do Python\n2. ✅ Testar importação de bibliotecas\n3. ✅ Verificar se tem pelo menos uma API configurada\n4. ✅ Fazer um teste básico de funcionamento\n5. ✅ Gerar um relatório final\n\n**Dica do Pedro**: Pense como um checklist de viagem - você não quer descobrir que esqueceu algo importante só quando chegar no destino!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎯 EXERCÍCIO 1: Crie seu detector de setup!\n# Complete as funções abaixo\n\ndef meu_detector_setup():\n    \"\"\"\n    EXERCÍCIO: Complete esta função para detectar se seu setup está pronto!\n    \n    Sua função deve retornar:\n    - True se tudo estiver OK\n    - False se houver problemas\n    - Uma mensagem explicativa\n    \"\"\"\n    \n    print(\"🔍 MEU DETECTOR DE SETUP PERSONALIZADO 🔍\")\n    print(\"=\" * 45)\n    \n    # TODO: Implemente as verificações aqui\n    # Dicas:\n    # 1. Use sys.version_info para verificar Python\n    # 2. Use try/except para testar importações\n    # 3. Use os.getenv() para verificar variáveis de ambiente\n    # 4. Crie um sistema de pontuação\n    \n    pontuacao = 0\n    max_pontos = 5\n    \n    # EXEMPLO - Verificação 1: Python (complete as outras!)\n    import sys\n    if sys.version_info >= (3, 8):\n        print(\"✅ Python versão OK (+1 ponto)\")\n        pontuacao += 1\n    else:\n        print(\"❌ Python versão inadequada\")\n    \n    # TODO: Adicione suas verificações aqui!\n    # Verificação 2: Bibliotecas essenciais\n    # Verificação 3: Pelo menos uma API configurada  \n    # Verificação 4: Teste de funcionamento\n    # Verificação 5: Estrutura de pastas\n    \n    # Resultado final\n    porcentagem = (pontuacao / max_pontos) * 100\n    \n    print(f\"\\n📊 RESULTADO: {pontuacao}/{max_pontos} ({porcentagem:.0f}%)\")\n    \n    if porcentagem >= 80:\n        print(\"🎉 PARABÉNS! Seu setup está EXCELENTE!\")\n        return True, \"Setup aprovado com louvor!\"\n    elif porcentagem >= 60:\n        print(\"👍 Bom setup, mas pode melhorar!\")\n        return True, \"Setup aprovado, com ressalvas.\"\n    else:\n        print(\"⚠️ Setup precisa de melhorias!\")\n        return False, \"Setup reprovado. Revise as configurações.\"\n\n# Execute seu detector!\n# setup_ok, mensagem = meu_detector_setup()\n# print(f\"\\n🎯 Resultado final: {mensagem}\")\n\nprint(\"💡 DICA: Descomente as linhas acima e complete a função!\")\nprint(\"🏆 Desafio: Faça sua função detectar pelo menos 5 aspectos diferentes!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Exercício Prático 2: Configurador Automático\n\n### 🏆 DESAFIO 2: Assistente de Setup\n\nAgora que você já sabe detectar problemas, vamos criar um **assistente inteligente** que não só detecta, mas também **corrige** os problemas automaticamente!\n\n**Sua missão**: Criar um configurador que:\n1. 🔍 Detecta o que está faltando\n2. 🛠️ Tenta corrigir automaticamente \n3. 📋 Gera comandos para o usuário executar\n4. ✅ Valida se as correções funcionaram\n\n**Dica do Pedro**: É como ter um mecânico que não só fala o que está quebrado, mas também conserta pra você!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎯 EXERCÍCIO 2: Crie um assistente de setup inteligente!\n\nclass AssistenteSetup:\n    \"\"\"\n    EXERCÍCIO: Complete esta classe para criar um assistente de setup!\n    \n    O assistente deve ser capaz de:\n    - Detectar problemas\n    - Sugerir soluções\n    - Gerar comandos para correção\n    - Validar se as correções funcionaram\n    \"\"\"\n    \n    def __init__(self):\n        self.problemas_detectados = []\n        self.solucoes_aplicadas = []\n        self.comandos_sugeridos = []\n    \n    def detectar_problemas(self):\n        \"\"\"\n        TODO: Implemente a detecção de problemas\n        Deve retornar uma lista de problemas encontrados\n        \"\"\"\n        # DICA: Use as técnicas que aprendemos anteriormente\n        # Verifique: Python, bibliotecas, APIs, estrutura de pastas\n        \n        problemas = []\n        \n        # EXEMPLO - Complete com suas verificações!\n        import sys\n        if sys.version_info < (3, 8):\n            problemas.append({\n                'tipo': 'python_version',\n                'descricao': 'Python muito antigo',\n                'severidade': 'alta',\n                'solucao': 'Instalar Python 3.8+'\n            })\n        \n        # TODO: Adicione mais verificações aqui!\n        \n        self.problemas_detectados = problemas\n        return problemas\n    \n    def gerar_solucoes(self):\n        \"\"\"\n        TODO: Para cada problema detectado, gere uma solução\n        \"\"\"\n        solucoes = []\n        \n        for problema in self.problemas_detectados:\n            if problema['tipo'] == 'python_version':\n                solucoes.append({\n                    'problema': problema['descricao'],\n                    'comando': 'Baixe Python 3.8+ do site oficial',\n                    'automatico': False\n                })\n            # TODO: Adicione mais soluções para outros tipos de problema!\n        \n        return solucoes\n    \n    def executar_setup_completo(self):\n        \"\"\"\n        TODO: Execute o processo completo de setup\n        \"\"\"\n        print(\"🤖 ASSISTENTE DE SETUP INTELIGENTE 🤖\")\n        print(\"=\" * 45)\n        \n        # 1. Detectar problemas\n        print(\"\\n🔍 Detectando problemas...\")\n        problemas = self.detectar_problemas()\n        \n        if not problemas:\n            print(\"✅ Nenhum problema detectado! Setup perfeito!\")\n            return True\n        \n        # 2. Mostrar problemas encontrados\n        print(f\"\\n⚠️ Encontrados {len(problemas)} problema(s):\")\n        for i, prob in enumerate(problemas, 1):\n            print(f\"   {i}. {prob['descricao']} (Severidade: {prob['severidade']})\")\n        \n        # 3. Gerar e mostrar soluções\n        print(\"\\n🛠️ Soluções sugeridas:\")\n        solucoes = self.gerar_solucoes()\n        for i, sol in enumerate(solucoes, 1):\n            print(f\"   {i}. {sol['problema']}\")\n            print(f\"      💡 Solução: {sol['comando']}\")\n        \n        # TODO: Implemente a aplicação automática das soluções\n        \n        return len(problemas) == 0\n\n# Teste seu assistente!\n# assistente = AssistenteSetup()\n# setup_ok = assistente.executar_setup_completo()\n\nprint(\"💡 DESAFIO: Complete a classe AssistenteSetup!\")\nprint(\"🎯 Meta: Faça ele detectar e corrigir pelo menos 3 tipos de problema!\")\nprint(\"🏆 Bônus: Adicione uma barra de progresso durante o setup!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📚 Preparando para os Próximos Módulos\n\nLiiindo! Agora que seu setup está funcionando, vamos dar uma espiadinha no que vem pela frente no nosso curso!\n\n### 🗺️ Roadmap dos Próximos Módulos:\n\n**Módulo 2 - O que são LLMs**: Vamos entender a teoria por trás desses \"cérebros artificiais\"\n**Módulo 3 - Arquitetura Transformer**: O \"motor\" que faz tudo funcionar\n**Módulo 4 - Tokens e Tokenização**: Como as máquinas \"entendem\" texto\n**Módulo 5 - Embeddings**: Como transformar palavras em números mágicos\n\n### 🎯 Como Este Módulo Se Conecta:\n\nTudo que configuramos hoje vai ser usado nos próximos módulos:\n- ✅ **Jupyter Notebooks**: Para todos os experimentos\n- ✅ **APIs configuradas**: Para testar modelos reais\n- ✅ **Bibliotecas instaladas**: Para implementar algoritmos\n- ✅ **Estrutura organizada**: Para manter tudo limpo\n\n**Dica do Pedro**: Guarde este notebook! Sempre que algo der errado nos próximos módulos, volte aqui e rode o diagnóstico. É como ter um \"manual do proprietário\" do seu ambiente de desenvolvimento!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar um checklist para os próximos módulos!\n# É como uma \"lista de compras\" do que vamos precisar\n\nfrom datetime import datetime\n\ndef preparar_proximos_modulos():\n    \"\"\"\n    Prepara o ambiente para os próximos módulos do curso\n    \"\"\"\n    \n    print(\"🎯 PREPARAÇÃO PARA OS PRÓXIMOS MÓDULOS 🎯\")\n    print(\"=\" * 50)\n    \n    # Checklist por módulo\n    checklist_modulos = {\n        \"Módulo 2 - O que são LLMs\": {\n            \"bibliotecas\": [\"matplotlib\", \"numpy\", \"requests\"],\n            \"conceitos\": [\"História da IA\", \"Redes neurais básicas\", \"Processamento de linguagem\"],\n            \"preparacao\": \"Revisar conceitos básicos de IA\"\n        },\n        \"Módulo 3 - Arquitetura Transformer\": {\n            \"bibliotecas\": [\"torch\", \"transformers\", \"matplotlib\"],\n            \"conceitos\": [\"Attention mechanism\", \"Self-attention\", \"Multi-head attention\"],\n            \"preparacao\": \"Estudar álgebra linear básica\"\n        },\n        \"Módulo 4 - Tokens e Tokenização\": {\n            \"bibliotecas\": [\"tiktoken\", \"transformers\", \"pandas\"],\n            \"conceitos\": [\"Tokenização\", \"Vocabulário\", \"Encoding/Decoding\"],\n            \"preparacao\": \"Entender processamento de texto\"\n        },\n        \"Módulo 5 - Embeddings\": {\n            \"bibliotecas\": [\"numpy\", \"matplotlib\", \"sklearn\"],\n            \"conceitos\": [\"Vetores\", \"Similaridade\", \"Espaços vetoriais\"],\n            \"preparacao\": \"Revisar conceitos de geometria básica\"\n        }\n    }\n    \n    # Verifica preparação para cada módulo\n    for modulo, requisitos in checklist_modulos.items():\n        print(f\"\\n📘 {modulo}\")\n        print(\"   📚 Bibliotecas necessárias:\")\n        \n        for lib in requisitos[\"bibliotecas\"]:\n            try:\n                __import__(lib)\n                status = \"✅\"\n            except ImportError:\n                status = \"❌\"\n            print(f\"      {status} {lib}\")\n        \n        print(f\"   🧠 Conceitos principais: {', '.join(requisitos['conceitos'])}\")\n        print(f\"   🎯 Preparação recomendada: {requisitos['preparacao']}\")\n    \n    # Resumo geral\n    print(\"\\n\" + \"=\" * 50)\n    print(\"📋 RESUMO DA PREPARAÇÃO:\")\n    print(\"✅ Setup básico concluído neste módulo\")\n    print(\"🔄 Ambiente configurado para todos os módulos\")\n    print(\"📚 Bibliotecas principais já instaladas\")\n    print(\"🎯 Pronto para começar a jornada nos LLMs!\")\n    \n    # Salva um arquivo de status\n    status_setup = {\n        \"data_setup\": datetime.now().isoformat(),\n        \"modulo_atual\": \"01 - Setup Inicial\",\n        \"proximo_modulo\": \"02 - O que são LLMs\",\n        \"status\": \"Setup concluído\",\n        \"observacoes\": \"Ambiente preparado para o curso completo\"\n    }\n    \n    print(f\"\\n💾 Status salvo em: setup_status.json\")\n    print(f\"📅 Data do setup: {datetime.now().strftime('%d/%m/%Y %H:%M')}\")\n    \n    return status_setup\n\n# Executa a preparação\nstatus = preparar_proximos_modulos()\n\nprint(\"\\n🚀 Você está PRONTO para decolar no mundo dos LLMs!\")\nprint(\"🎉 Nos vemos no Módulo 2 - O que são LLMs!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎉 Resumo do Módulo: Setup Inicial\n\n**Parabéns!** 🎊 Você concluiu o primeiro módulo do curso \"Introdução à LLMs\"!\n\n### 🏆 O que você aprendeu hoje:\n\n1. **🔧 Setup Completo**: Como configurar um ambiente profissional para LLMs\n2. **📚 Bibliotecas Essenciais**: Quais ferramentas usar e por quê\n3. **🔐 Segurança**: Como configurar APIs sem vazar suas chaves\n4. **🏗️ Organização**: Estrutura de pastas profissional\n5. **🧪 Testes**: Como validar se tudo está funcionando\n6. **🔍 Troubleshooting**: Como resolver problemas comuns\n\n### 🎯 Principais Conceitos:\n\n- **Ambiente de Desenvolvimento**: Sua \"bancada de trabalho\" digital\n- **APIs e Tokens**: As \"chaves\" para acessar os modelos\n- **Estrutura Organizacional**: Fundação para projetos complexos\n- **Diagnóstico Automático**: Ferramentas para detectar problemas\n\n### 🚀 Próximos Passos:\n\n✅ **Módulo 2**: \"O que são LLMs\" - Vamos mergulhar na teoria!\n✅ **Módulo 3**: \"Arquitetura Transformer\" - O cérebro das IAs\n✅ **Módulo 4**: \"Tokens e Tokenização\" - Como máquinas leem texto\n\n---\n\n### 💡 Dica Final do Pedro:\n\n*\"Setup é como fundação de uma casa - se estiver sólida, você pode construir qualquer coisa em cima. Se estiver fraca, até o projeto mais bonito vai desabar. Guardem bem este notebook, ele vai ser seu melhor amigo quando as coisas derem errado!\"*\n\n**Liiindo!** Agora bora para o próximo módulo descobrir o que diabos são esses LLMs! 🚀\n\n---\n\n*Módulo 1 de 13 concluído com sucesso! 🎉*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎊 CELEBRAÇÃO DE CONCLUSÃO DO MÓDULO! 🎊\n# Vamos criar uma visualização especial para marcar este momento!\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom datetime import datetime\n\n# Criar um gráfico de celebração\nfig, ax = plt.subplots(figsize=(12, 8))\n\n# Dados para o gráfico de progresso do curso\nmodulos = ['Setup\\nInicial', 'O que são\\nLLMs', 'Arquitetura\\nTransformer', \n          'Tokens &\\nTokenização', 'Embeddings', 'Tipos de\\nModelos',\n          'Treinamento', 'Prompting', 'Avaliação', 'Segurança',\n          'Limitações', 'Projeto\\nFinal', 'Tópicos\\nAvançados']\n\nprogresso = [100] + [0] * 12  # Apenas o primeiro módulo concluído\ncores = ['#4CAF50'] + ['#E0E0E0'] * 12  # Verde para concluído, cinza para pendente\n\n# Criar gráfico de barras\nbars = ax.bar(range(len(modulos)), progresso, color=cores, edgecolor='black', linewidth=1)\n\n# Adicionar estrela no módulo concluído\nax.text(0, 105, '⭐', fontsize=30, ha='center', va='bottom')\nax.text(0, 115, 'CONCLUÍDO!', fontsize=12, ha='center', va='bottom', \n        weight='bold', color='green')\n\n# Configurar o gráfico\nax.set_ylim(0, 130)\nax.set_ylabel('Progresso (%)', fontsize=12, weight='bold')\nax.set_title('🎉 PROGRESSO NO CURSO: INTRODUÇÃO À LLMs 🎉\\n\\n' + \n             f'Módulo 1 concluído em {datetime.now().strftime(\"%d/%m/%Y\")}!', \n             fontsize=16, weight='bold', pad=20)\nax.set_xticks(range(len(modulos)))\nax.set_xticklabels(modulos, rotation=45, ha='right')\nax.grid(axis='y', alpha=0.3)\n\n# Adicionar estatísticas\nstats_text = f'''\n📊 ESTATÍSTICAS:\n✅ Módulos concluídos: 1/13 (7.7%)\n🎯 Próximo módulo: O que são LLMs\n⏱️ Tempo estimado restante: ~12 horas\n🏆 Nível atual: Iniciante\n'''\n\nax.text(0.02, 0.98, stats_text, transform=ax.transAxes, \n        fontsize=10, verticalalignment='top',\n        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n\n# Adicionar mensagem motivacional\nmotivacao = '''\n🚀 \"A jornada de mil milhas \ncomeça com um único passo.\"\n\nVocê deu o primeiro passo!\nAgora é só continuar! 💪\n'''\n\nax.text(0.98, 0.02, motivacao, transform=ax.transAxes, \n        fontsize=11, verticalalignment='bottom', horizontalalignment='right',\n        bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8),\n        style='italic')\n\nplt.tight_layout()\nplt.show()\n\n# Mensagem final\nprint(\"\\n\" + \"=\"*60)\nprint(\"🎊 PARABÉNS! VOCÊ CONCLUIU O MÓDULO 1! 🎊\")\nprint(\"=\"*60)\nprint(\"\\n🎯 Conquistas desbloqueadas:\")\nprint(\"   🏆 Setup Master - Configurou ambiente completo\")\nprint(\"   🔧 Troubleshooter - Aprendeu a resolver problemas\")\nprint(\"   🚀 Ready to Launch - Pronto para LLMs reais\")\nprint(\"\\n📅 Próximo encontro: Módulo 2 - O que são LLMs\")\nprint(\"💡 Dica: Pratique os exercícios antes de continuar!\")\nprint(\"\\n✨ Até a próxima, e lembre-se: você está arrasando! ✨\")\nprint(\"=\"*60)"
      ]
    }
  ]
}