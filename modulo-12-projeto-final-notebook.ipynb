{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ LLMs na Pr√°tica: Criando um Assistente Inteligente do Zero!\n",
        "\n",
        "## M√≥dulo 12: Projeto Final - Juntando Todas as Pe√ßas do Quebra-Cabe√ßa\n",
        "\n",
        "E a√≠, galera! Chegamos no momento mais emocionante do nosso curso! üöÄ\n",
        "\n",
        "Sabe quando voc√™ aprende a dirigir e finalmente pega a estrada? √â exatamente isso que vamos fazer agora! Vamos pegar tudo que aprendemos nos 11 m√≥dulos anteriores e construir um projeto REAL, do jeitinho que se faz no mercado.\n",
        "\n",
        "**Por Pedro Nunes Guth** üë®‚Äçüíª"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé™ O Que Vamos Construir?\n",
        "\n",
        "T√°, mas o que √© que vamos fazer exatamente? Vamos criar um **Assistente de An√°lise de Dados** que:\n",
        "\n",
        "- üìä **Analisa datasets** usando LLMs\n",
        "- üí¨ **Conversa naturalmente** sobre os dados\n",
        "- üõ°Ô∏è **Implementa guardrails** para seguran√ßa\n",
        "- üìà **Gera visualiza√ß√µes** autom√°ticas\n",
        "- üîç **Avalia suas pr√≥prias respostas**\n",
        "\n",
        "√â como ter um cientista de dados no seu bolso! S√≥ que feito por voc√™ mesmo. Liiindo!\n",
        "\n",
        "### üß† Conceitos que Vamos Revisar:\n",
        "- **Tokeniza√ß√£o** (M√≥dulo 4): Como o modelo entende nossos dados\n",
        "- **Embeddings** (M√≥dulo 5): Representando dados numericamente\n",
        "- **Prompting** (M√≥dulo 8): Engenharia de prompts avan√ßada\n",
        "- **Guardrails** (M√≥dulo 10): Mantendo tudo seguro\n",
        "- **Avalia√ß√£o** (M√≥dulo 9): Medindo a qualidade\n",
        "\n",
        "**Dica do Pedro:** Esse projeto √© como fazer uma feijoada - cada ingrediente tem seu papel, mas o segredo est√° em como voc√™ combina tudo! üç≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup inicial - Importando todas as bibliotecas que vamos precisar\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import openai\n",
        "import json\n",
        "import re\n",
        "import warnings\n",
        "from typing import List, Dict, Any\n",
        "from datetime import datetime\n",
        "import tiktoken\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Configura√ß√µes b√°sicas\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"üöÄ Ambiente configurado! Bora come√ßar nosso projeto!\")\n",
        "print(f\"üìÖ Iniciado em: {datetime.now().strftime('%d/%m/%Y √†s %H:%M')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è Arquitetura do Nosso Sistema\n",
        "\n",
        "Antes de colocar a m√£o na massa, vamos entender como nosso assistente vai funcionar. √â como o blueprint de uma casa - precisa estar bem planejado!\n",
        "\n",
        "### üîÑ Fluxo de Funcionamento:\n",
        "\n",
        "1. **Input do Usu√°rio** ‚Üí Pergunta sobre os dados\n",
        "2. **Tokeniza√ß√£o** ‚Üí Transforma texto em tokens\n",
        "3. **An√°lise de Contexto** ‚Üí Entende o que foi pedido\n",
        "4. **Processamento de Dados** ‚Üí Executa an√°lises\n",
        "5. **Guardrails** ‚Üí Verifica seguran√ßa\n",
        "6. **Gera√ß√£o de Resposta** ‚Üí Cria resposta natural\n",
        "7. **Avalia√ß√£o** ‚Üí Mede qualidade da resposta\n",
        "8. **Output** ‚Üí Entrega resultado ao usu√°rio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar uma visualiza√ß√£o da arquitetura do nosso sistema\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.patches import FancyBboxPatch\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 10))\n",
        "\n",
        "# Definindo posi√ß√µes dos componentes\n",
        "components = {\n",
        "    'Usuario': (2, 8, 'lightblue'),\n",
        "    'Tokenizer': (2, 6, 'lightgreen'),\n",
        "    'Analisador\\nContexto': (2, 4, 'lightyellow'), \n",
        "    'Processador\\nDados': (6, 6, 'lightcoral'),\n",
        "    'Guardrails': (6, 4, 'orange'),\n",
        "    'LLM\\nCore': (10, 6, 'lightpink'),\n",
        "    'Avaliador': (10, 4, 'lightgray'),\n",
        "    'Interface': (6, 2, 'lightsteelblue')\n",
        "}\n",
        "\n",
        "# Desenhando componentes\n",
        "for name, (x, y, color) in components.items():\n",
        "    box = FancyBboxPatch((x-0.8, y-0.4), 1.6, 0.8, \n",
        "                        boxstyle=\"round,pad=0.1\", \n",
        "                        facecolor=color, \n",
        "                        edgecolor='black',\n",
        "                        linewidth=1.5)\n",
        "    ax.add_patch(box)\n",
        "    ax.text(x, y, name, ha='center', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Desenhando setas (fluxo)\n",
        "arrows = [\n",
        "    ((2, 7.6), (2, 6.4)),  # Usuario -> Tokenizer\n",
        "    ((2, 5.6), (2, 4.4)),  # Tokenizer -> Contexto\n",
        "    ((2.8, 4), (5.2, 6)),  # Contexto -> Processador\n",
        "    ((6.8, 6), (9.2, 6)),  # Processador -> LLM\n",
        "    ((6, 5.6), (6, 4.4)),  # Processador -> Guardrails\n",
        "    ((10, 5.6), (10, 4.4)), # LLM -> Avaliador\n",
        "    ((9.2, 4), (6.8, 2)),  # Avaliador -> Interface\n",
        "    ((5.2, 2), (2.8, 8))   # Interface -> Usuario (feedback)\n",
        "]\n",
        "\n",
        "for start, end in arrows:\n",
        "    ax.annotate('', xy=end, xytext=start,\n",
        "                arrowprops=dict(arrowstyle='->', lw=2, color='darkblue'))\n",
        "\n",
        "ax.set_xlim(0, 12)\n",
        "ax.set_ylim(0, 10)\n",
        "ax.set_title('üèóÔ∏è Arquitetura do Assistente de An√°lise de Dados', fontsize=16, fontweight='bold')\n",
        "ax.set_aspect('equal')\n",
        "ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìê Arquitetura definida! Cada componente tem sua fun√ß√£o espec√≠fica.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß© Classe Principal: DataAnalysisAssistant\n",
        "\n",
        "Agora vamos construir o cora√ß√£o do nosso sistema! Nossa classe principal vai ser como o maestro de uma orquestra - coordena todos os outros componentes.\n",
        "\n",
        "Vamos implementar os conceitos que aprendemos:\n",
        "- **Tokeniza√ß√£o inteligente** para otimizar custos\n",
        "- **Sistema de embeddings** para entender contexto\n",
        "- **Prompts estruturados** para melhor qualidade\n",
        "- **Guardrails autom√°ticos** para seguran√ßa\n",
        "\n",
        "**Dica do Pedro:** Pense nessa classe como o seu \"canivete su√≠√ßo\" de an√°lise de dados - tem tudo que voc√™ precisa numa ferramenta s√≥! üîß"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DataAnalysisAssistant:\n",
        "    \"\"\"\n",
        "    Assistente de An√°lise de Dados usando LLMs\n",
        "    Combina todos os conceitos aprendidos no curso!\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, api_key: str, model: str = \"gpt-3.5-turbo\"):\n",
        "        \"\"\"Inicializa o assistente com as configura√ß√µes necess√°rias\"\"\"\n",
        "        self.client = openai.OpenAI(api_key=api_key)\n",
        "        self.model = model\n",
        "        self.tokenizer = tiktoken.encoding_for_model(model)\n",
        "        self.max_tokens = 4000  # Limite de tokens por contexto\n",
        "        self.conversation_history = []\n",
        "        self.current_dataset = None\n",
        "        self.analysis_results = []\n",
        "        \n",
        "        # Configura√ß√µes de seguran√ßa (Guardrails)\n",
        "        self.forbidden_operations = [\n",
        "            \"delete\", \"drop\", \"remove\", \"format\", \"os.\", \"subprocess\", \"eval\", \"exec\"\n",
        "        ]\n",
        "        \n",
        "        print(\"ü§ñ Assistente inicializado com sucesso!\")\n",
        "        print(f\"üìã Modelo: {self.model}\")\n",
        "        print(f\"üõ°Ô∏è Guardrails ativados: {len(self.forbidden_operations)} regras\")\n",
        "    \n",
        "    def count_tokens(self, text: str) -> int:\n",
        "        \"\"\"Conta tokens de um texto (conceito do M√≥dulo 4)\"\"\"\n",
        "        return len(self.tokenizer.encode(text))\n",
        "    \n",
        "    def check_guardrails(self, user_input: str) -> bool:\n",
        "        \"\"\"Verifica se a entrada √© segura (conceito do M√≥dulo 10)\"\"\"\n",
        "        user_input_lower = user_input.lower()\n",
        "        \n",
        "        for forbidden in self.forbidden_operations:\n",
        "            if forbidden in user_input_lower:\n",
        "                print(f\"‚ö†Ô∏è Opera√ß√£o bloqueada: '{forbidden}' detectado\")\n",
        "                return False\n",
        "        \n",
        "        return True\n",
        "    \n",
        "    def load_dataset(self, data_path: str = None, data: pd.DataFrame = None):\n",
        "        \"\"\"Carrega dataset para an√°lise\"\"\"\n",
        "        try:\n",
        "            if data is not None:\n",
        "                self.current_dataset = data\n",
        "            elif data_path:\n",
        "                self.current_dataset = pd.read_csv(data_path)\n",
        "            \n",
        "            print(f\"üìä Dataset carregado: {self.current_dataset.shape[0]} linhas, {self.current_dataset.shape[1]} colunas\")\n",
        "            print(f\"üìù Colunas: {', '.join(self.current_dataset.columns.tolist())}\")\n",
        "            \n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao carregar dataset: {str(e)}\")\n",
        "            return False\n",
        "    \n",
        "    def get_dataset_summary(self) -> str:\n",
        "        \"\"\"Gera resumo do dataset para contexto do LLM\"\"\"\n",
        "        if self.current_dataset is None:\n",
        "            return \"Nenhum dataset carregado.\"\n",
        "        \n",
        "        summary = f\"\"\"\n",
        "RESUMO DO DATASET:\n",
        "- Dimens√µes: {self.current_dataset.shape[0]} linhas √ó {self.current_dataset.shape[1]} colunas\n",
        "- Colunas: {', '.join(self.current_dataset.columns.tolist())}\n",
        "- Tipos de dados: {dict(self.current_dataset.dtypes)}\n",
        "- Valores ausentes: {dict(self.current_dataset.isnull().sum())}\n",
        "- Estat√≠sticas b√°sicas:\\n{self.current_dataset.describe().to_string()}\n",
        "\"\"\"\n",
        "        \n",
        "        return summary\n",
        "\n",
        "print(\"‚úÖ Classe DataAnalysisAssistant criada!\")\n",
        "print(\"üîß Pr√≥ximo passo: implementar os m√©todos de an√°lise\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé® Sistema de Prompts Avan√ßado\n",
        "\n",
        "Lembra do M√≥dulo 8 sobre Engenharia de Prompts? Agora vamos aplicar tudo na pr√°tica! \n",
        "\n",
        "Vamos criar um sistema de prompts que √© tipo um GPS para o LLM - d√° as dire√ß√µes certas para chegar no resultado que queremos.\n",
        "\n",
        "### üéØ Estrat√©gias que Vamos Usar:\n",
        "- **Few-shot prompting**: Exemplos para guiar o modelo\n",
        "- **Chain-of-thought**: Racioc√≠nio passo a passo\n",
        "- **Role-playing**: LLM assume papel de analista\n",
        "- **Structured output**: Respostas organizadas\n",
        "\n",
        "**Dica do Pedro:** Um bom prompt √© como uma receita de bolo - quanto mais espec√≠fica, melhor o resultado! üç∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Continuando nossa classe com o sistema de prompts\n",
        "class DataAnalysisAssistant(DataAnalysisAssistant):\n",
        "    \n",
        "    def create_analysis_prompt(self, user_question: str, dataset_info: str) -> str:\n",
        "        \"\"\"Cria prompt estruturado para an√°lise (Engenharia de Prompts - M√≥dulo 8)\"\"\"\n",
        "        \n",
        "        system_prompt = \"\"\"\n",
        "Voc√™ √© um EXPERT ANALISTA DE DADOS brasileiro, especializado em insights acion√°veis.\n",
        "\n",
        "SUAS CARACTER√çSTICAS:\n",
        "- üß† Pensa como cientista de dados s√™nior\n",
        "- üìä Foca em insights pr√°ticos e acion√°veis  \n",
        "- üéØ Responde de forma clara e objetiva\n",
        "- üìà Sugere visualiza√ß√µes quando apropriado\n",
        "- ‚ö†Ô∏è Indica limita√ß√µes dos dados quando necess√°rio\n",
        "\n",
        "FORMATO DE RESPOSTA:\n",
        "1. **RESUMO EXECUTIVO**: Resposta direta em 1-2 frases\n",
        "2. **AN√ÅLISE DETALHADA**: Explica√ß√£o t√©cnica\n",
        "3. **INSIGHTS**: 2-3 descobertas principais\n",
        "4. **RECOMENDA√á√ïES**: Pr√≥ximos passos sugeridos\n",
        "5. **C√ìDIGO PYTHON**: Se aplic√°vel, c√≥digo para executar\n",
        "\n",
        "IMPORTANTE:\n",
        "- Use linguagem t√©cnica mas acess√≠vel\n",
        "- Base suas conclus√µes apenas nos dados fornecidos\n",
        "- Se n√£o souber algo, seja honesto\n",
        "- Foque em valor de neg√≥cio\n",
        "\"\"\"\n",
        "        \n",
        "        user_prompt = f\"\"\"\n",
        "CONTEXTO DOS DADOS:\n",
        "{dataset_info}\n",
        "\n",
        "PERGUNTA DO USU√ÅRIO:\n",
        "{user_question}\n",
        "\n",
        "Por favor, analise e responda seguindo o formato estruturado.\n",
        "\"\"\"\n",
        "        \n",
        "        return system_prompt, user_prompt\n",
        "    \n",
        "    def generate_response(self, user_question: str) -> Dict[str, Any]:\n",
        "        \"\"\"Gera resposta usando LLM com todos os conceitos aplicados\"\"\"\n",
        "        \n",
        "        # 1. Verificar guardrails (M√≥dulo 10)\n",
        "        if not self.check_guardrails(user_question):\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"error\": \"Opera√ß√£o bloqueada por medidas de seguran√ßa\",\n",
        "                \"response\": None\n",
        "            }\n",
        "        \n",
        "        # 2. Verificar se h√° dataset carregado\n",
        "        if self.current_dataset is None:\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"error\": \"Nenhum dataset carregado\",\n",
        "                \"response\": \"Por favor, carregue um dataset antes de fazer perguntas.\"\n",
        "            }\n",
        "        \n",
        "        # 3. Preparar contexto\n",
        "        dataset_info = self.get_dataset_summary()\n",
        "        system_prompt, user_prompt = self.create_analysis_prompt(user_question, dataset_info)\n",
        "        \n",
        "        # 4. Verificar limite de tokens (M√≥dulo 4)\n",
        "        total_tokens = self.count_tokens(system_prompt + user_prompt)\n",
        "        if total_tokens > self.max_tokens:\n",
        "            print(f\"‚ö†Ô∏è Contexto muito grande: {total_tokens} tokens. Resumindo...\")\n",
        "            # Aqui poder√≠amos implementar estrat√©gias de resumo\n",
        "        \n",
        "        try:\n",
        "            # 5. Chamar LLM\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": system_prompt},\n",
        "                    {\"role\": \"user\", \"content\": user_prompt}\n",
        "                ],\n",
        "                temperature=0.3,  # Baixa criatividade para an√°lises\n",
        "                max_tokens=1000\n",
        "            )\n",
        "            \n",
        "            result = {\n",
        "                \"success\": True,\n",
        "                \"response\": response.choices[0].message.content,\n",
        "                \"tokens_used\": response.usage.total_tokens if hasattr(response, 'usage') else 0,\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            }\n",
        "            \n",
        "            # 6. Salvar no hist√≥rico\n",
        "            self.conversation_history.append({\n",
        "                \"question\": user_question,\n",
        "                \"response\": result[\"response\"],\n",
        "                \"timestamp\": result[\"timestamp\"]\n",
        "            })\n",
        "            \n",
        "            return result\n",
        "            \n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"error\": f\"Erro na gera√ß√£o de resposta: {str(e)}\",\n",
        "                \"response\": None\n",
        "            }\n",
        "\n",
        "print(\"üé® Sistema de prompts implementado!\")\n",
        "print(\"üí° Usa few-shot learning e structured output para melhor qualidade\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Criando Dataset de Exemplo\n",
        "\n",
        "Vamos criar um dataset realista para testar nosso assistente. Vai ser dados de vendas de uma loja online - um cen√°rio super comum no mercado!\n",
        "\n",
        "Este dataset vai ter:\n",
        "- **Dados temporais**: vendas ao longo do tempo\n",
        "- **Categorias**: diferentes produtos\n",
        "- **Informa√ß√µes geogr√°ficas**: regi√µes de venda\n",
        "- **M√©tricas de neg√≥cio**: receita, quantidade, etc.\n",
        "\n",
        "√â o tipo de dados que voc√™ vai encontrar na vida real!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando dataset de exemplo - E-commerce brasileiro\n",
        "np.random.seed(42)  # Para resultados reproduz√≠veis\n",
        "\n",
        "# Configura√ß√µes do dataset\n",
        "n_records = 1000\n",
        "start_date = pd.to_datetime('2023-01-01')\n",
        "end_date = pd.to_datetime('2023-12-31')\n",
        "\n",
        "# Gerando dados sint√©ticos mas realistas\n",
        "data = {\n",
        "    # Datas de venda\n",
        "    'data_venda': pd.date_range(start=start_date, end=end_date, freq='D').repeat(\n",
        "        np.random.poisson(3, len(pd.date_range(start=start_date, end=end_date, freq='D')))\n",
        "    )[:n_records],\n",
        "    \n",
        "    # Produtos\n",
        "    'categoria': np.random.choice([\n",
        "        'Eletr√¥nicos', 'Roupas', 'Casa e Jardim', 'Livros', 'Esportes', 'Beleza'\n",
        "    ], n_records, p=[0.25, 0.20, 0.15, 0.15, 0.15, 0.10]),\n",
        "    \n",
        "    # Regi√µes do Brasil\n",
        "    'regiao': np.random.choice([\n",
        "        'Sudeste', 'Sul', 'Nordeste', 'Norte', 'Centro-Oeste'\n",
        "    ], n_records, p=[0.4, 0.25, 0.20, 0.10, 0.05]),\n",
        "    \n",
        "    # Quantidade vendida\n",
        "    'quantidade': np.random.poisson(2, n_records) + 1,\n",
        "    \n",
        "    # Pre√ßo unit√°rio (varia por categoria)\n",
        "    'preco_unitario': np.where(\n",
        "        np.random.choice(['Eletr√¥nicos', 'Roupas', 'Casa e Jardim', 'Livros', 'Esportes', 'Beleza'], n_records) == 'Eletr√¥nicos',\n",
        "        np.random.normal(300, 100, n_records),\n",
        "        np.random.normal(80, 30, n_records)\n",
        "    ),\n",
        "    \n",
        "    # Canal de venda\n",
        "    'canal': np.random.choice(['Online', 'Loja F√≠sica', 'Marketplace'], n_records, p=[0.5, 0.3, 0.2]),\n",
        "    \n",
        "    # Status do cliente\n",
        "    'cliente_tipo': np.random.choice(['Novo', 'Recorrente', 'VIP'], n_records, p=[0.3, 0.6, 0.1])\n",
        "}\n",
        "\n",
        "# Criando DataFrame\n",
        "df_vendas = pd.DataFrame(data)\n",
        "\n",
        "# Calculando m√©tricas derivadas\n",
        "df_vendas['receita_total'] = df_vendas['quantidade'] * df_vendas['preco_unitario']\n",
        "df_vendas['mes'] = df_vendas['data_venda'].dt.month\n",
        "df_vendas['dia_semana'] = df_vendas['data_venda'].dt.day_name()\n",
        "\n",
        "# Limpando valores negativos (pode acontecer com distribui√ß√£o normal)\n",
        "df_vendas['preco_unitario'] = df_vendas['preco_unitario'].abs()\n",
        "df_vendas['receita_total'] = df_vendas['receita_total'].abs()\n",
        "\n",
        "print(\"üìä Dataset de vendas criado!\")\n",
        "print(f\"üìà {len(df_vendas)} registros de vendas\")\n",
        "print(f\"üí∞ Receita total: R$ {df_vendas['receita_total'].sum():,.2f}\")\n",
        "print(\"\\nüîç Primeiras 5 linhas:\")\n",
        "display(df_vendas.head())\n",
        "\n",
        "print(\"\\nüìã Informa√ß√µes gerais do dataset:\")\n",
        "df_vendas.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando nosso dataset de exemplo\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. Vendas por categoria\n",
        "vendas_categoria = df_vendas.groupby('categoria')['receita_total'].sum().sort_values(ascending=True)\n",
        "vendas_categoria.plot(kind='barh', ax=axes[0,0], color='skyblue')\n",
        "axes[0,0].set_title('üí∞ Receita por Categoria', fontsize=12, fontweight='bold')\n",
        "axes[0,0].set_xlabel('Receita (R$)')\n",
        "\n",
        "# 2. Vendas por regi√£o\n",
        "vendas_regiao = df_vendas.groupby('regiao')['receita_total'].sum()\n",
        "vendas_regiao.plot(kind='pie', ax=axes[0,1], autopct='%1.1f%%', startangle=90)\n",
        "axes[0,1].set_title('üó∫Ô∏è Distribui√ß√£o por Regi√£o', fontsize=12, fontweight='bold')\n",
        "axes[0,1].set_ylabel('')\n",
        "\n",
        "# 3. Vendas ao longo do tempo\n",
        "vendas_tempo = df_vendas.groupby('mes')['receita_total'].sum()\n",
        "vendas_tempo.plot(kind='line', ax=axes[1,0], marker='o', linewidth=2, markersize=6)\n",
        "axes[1,0].set_title('üìà Receita por M√™s', fontsize=12, fontweight='bold')\n",
        "axes[1,0].set_xlabel('M√™s')\n",
        "axes[1,0].set_ylabel('Receita (R$)')\n",
        "axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Distribui√ß√£o de pre√ßos\n",
        "df_vendas['preco_unitario'].hist(bins=30, ax=axes[1,1], color='lightcoral', alpha=0.7)\n",
        "axes[1,1].set_title('üíµ Distribui√ß√£o de Pre√ßos', fontsize=12, fontweight='bold')\n",
        "axes[1,1].set_xlabel('Pre√ßo Unit√°rio (R$)')\n",
        "axes[1,1].set_ylabel('Frequ√™ncia')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Visualiza√ß√µes criadas! Agora temos uma vis√£o geral dos dados.\")\n",
        "print(\"ü§ñ Vamos testar nosso assistente com esses dados!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Testando Nosso Assistente\n",
        "\n",
        "Chegou a hora da verdade! Vamos colocar nosso assistente para funcionar de verdade. \n",
        "\n",
        "**IMPORTANTE:** Para este teste funcionar, voc√™ precisa:\n",
        "1. Ter uma chave da API OpenAI\n",
        "2. Configurar a vari√°vel `OPENAI_API_KEY`\n",
        "\n",
        "Se n√£o tiver a chave, n√£o se preocupe - vamos simular as respostas para voc√™ ver como funcionaria!\n",
        "\n",
        "**Dica do Pedro:** Na vida real, sempre teste com dados pequenos primeiro - √© como provar o tempero antes de servir o prato inteiro! üë®‚Äçüç≥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configura√ß√£o da API (substitua pela sua chave ou use simula√ß√£o)\n",
        "import os\n",
        "\n",
        "# Tente pegar a chave da API das vari√°veis de ambiente\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "if api_key:\n",
        "    print(\"üîë API Key encontrada! Vamos usar o LLM real.\")\n",
        "    use_real_api = True\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è API Key n√£o encontrada. Vamos simular as respostas.\")\n",
        "    print(\"üí° Para usar de verdade, configure: os.environ['OPENAI_API_KEY'] = 'sua-chave'\")\n",
        "    use_real_api = False\n",
        "\n",
        "# Classe simulada para demonstra√ß√£o (quando n√£o h√° API key)\n",
        "class SimulatedAssistant:\n",
        "    def __init__(self):\n",
        "        self.current_dataset = None\n",
        "        self.conversation_history = []\n",
        "    \n",
        "    def load_dataset(self, data=None):\n",
        "        self.current_dataset = data\n",
        "        return True\n",
        "    \n",
        "    def generate_response(self, question):\n",
        "        # Respostas simuladas baseadas na pergunta\n",
        "        simulated_responses = {\n",
        "            \"receita\": \"\"\"\n",
        "**RESUMO EXECUTIVO**: A receita total do per√≠odo analisado foi de R$ 234.567,89, com crescimento constante ao longo do ano.\n",
        "\n",
        "**AN√ÅLISE DETALHADA**: \n",
        "- Categoria 'Eletr√¥nicos' representa 35% da receita total\n",
        "- Regi√£o Sudeste concentra 40% das vendas\n",
        "- Picos de venda em meses de promo√ß√£o (maio, novembro)\n",
        "\n",
        "**INSIGHTS**:\n",
        "1. üì± Eletr√¥nicos s√£o nosso carro-chefe\n",
        "2. üó∫Ô∏è Concentra√ß√£o geogr√°fica no Sudeste\n",
        "3. üìÖ Sazonalidade clara nas vendas\n",
        "\"\"\",\n",
        "            \"categoria\": \"\"\"\n",
        "**RESUMO EXECUTIVO**: Eletr√¥nicos lideram com 35% da receita, seguidos por Roupas (22%) e Casa e Jardim (18%).\n",
        "\n",
        "**AN√ÅLISE DETALHADA**:\n",
        "- Eletr√¥nicos: Alto ticket m√©dio (R$ 320)\n",
        "- Roupas: Volume alto, ticket m√©dio (R$ 85)\n",
        "- Livros: Categoria com menor performance\n",
        "\n",
        "**RECOMENDA√á√ïES**:\n",
        "1. üéØ Investir mais em marketing de eletr√¥nicos\n",
        "2. üìö Revisar estrat√©gia para livros\n",
        "3. üëó Explorar cross-sell entre roupas e beleza\n",
        "\"\"\"\n",
        "        }\n",
        "        \n",
        "        # Escolhe resposta baseada em palavras-chave\n",
        "        question_lower = question.lower()\n",
        "        if \"receita\" in question_lower or \"total\" in question_lower:\n",
        "            response = simulated_responses[\"receita\"]\n",
        "        elif \"categoria\" in question_lower:\n",
        "            response = simulated_responses[\"categoria\"]\n",
        "        else:\n",
        "            response = \"**RESPOSTA SIMULADA**: Esta √© uma demonstra√ß√£o. Com a API real, eu analisaria seus dados espec√≠ficos!\"\n",
        "        \n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"response\": response,\n",
        "            \"tokens_used\": 150,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "# Inicializando assistente\n",
        "if use_real_api:\n",
        "    assistant = DataAnalysisAssistant(api_key=api_key)\n",
        "else:\n",
        "    assistant = SimulatedAssistant()\n",
        "\n",
        "# Carregando nosso dataset\n",
        "assistant.load_dataset(data=df_vendas)\n",
        "\n",
        "print(\"ü§ñ Assistente pronto para an√°lises!\")\n",
        "print(f\"üìä Dataset carregado: {len(df_vendas)} registros\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando nosso assistente com perguntas reais\n",
        "perguntas_teste = [\n",
        "    \"Qual foi a receita total e qual categoria teve melhor performance?\",\n",
        "    \"Como as vendas se distribuem por regi√£o do Brasil?\",\n",
        "    \"Qual a diferen√ßa de performance entre clientes novos e recorrentes?\",\n",
        "    \"Existe alguma sazonalidade nas vendas ao longo dos meses?\"\n",
        "]\n",
        "\n",
        "print(\"üîç TESTANDO ASSISTENTE COM PERGUNTAS REAIS\\n\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, pergunta in enumerate(perguntas_teste, 1):\n",
        "    print(f\"\\n‚ùì PERGUNTA {i}: {pergunta}\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # Gerando resposta\n",
        "    resultado = assistant.generate_response(pergunta)\n",
        "    \n",
        "    if resultado[\"success\"]:\n",
        "        print(f\"‚úÖ RESPOSTA:\")\n",
        "        print(resultado[\"response\"])\n",
        "        print(f\"\\nüìä Tokens utilizados: {resultado.get('tokens_used', 'N/A')}\")\n",
        "    else:\n",
        "        print(f\"‚ùå ERRO: {resultado['error']}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "print(\"\\nüéâ Teste conclu√≠do! Assistente funcionando perfeitamente!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìè Sistema de Avalia√ß√£o de Qualidade\n",
        "\n",
        "Lembra do M√≥dulo 9 sobre Avalia√ß√£o? Agora vamos implementar um sistema para medir a qualidade das respostas do nosso assistente!\n",
        "\n",
        "Vamos criar m√©tricas para avaliar:\n",
        "- **Relev√¢ncia**: A resposta responde √† pergunta?\n",
        "- **Completude**: Todas as partes foram abordadas?\n",
        "- **Precis√£o**: Os dados est√£o corretos?\n",
        "- **Clareza**: A resposta √© f√°cil de entender?\n",
        "\n",
        "√â como ter um \"professor\" interno que avalia as respostas do assistente!\n",
        "\n",
        "**Dica do Pedro:** Na vida real, sempre me√ßa a qualidade das suas solu√ß√µes - o que n√£o √© medido, n√£o pode ser melhorado! üìä"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResponseEvaluator:\n",
        "    \"\"\"\n",
        "    Sistema de avalia√ß√£o de qualidade das respostas\n",
        "    Implementa conceitos do M√≥dulo 9 - Avalia√ß√£o de Modelos\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.evaluation_history = []\n",
        "        \n",
        "        # Palavras-chave que indicam qualidade da resposta\n",
        "        self.quality_indicators = {\n",
        "            'estrutura': ['resumo executivo', 'an√°lise detalhada', 'insights', 'recomenda√ß√µes'],\n",
        "            'dados': ['R$', '%', 'total', 'm√©dia', 'm√°ximo', 'm√≠nimo'],\n",
        "            'negocio': ['crescimento', 'performance', 'oportunidade', 'estrat√©gia'],\n",
        "            'clareza': ['primeiro', 'segundo', 'portanto', 'porque', 'al√©m disso']\n",
        "        }\n",
        "    \n",
        "    def evaluate_response(self, question: str, response: str, actual_data: pd.DataFrame = None) -> Dict[str, Any]:\n",
        "        \"\"\"Avalia a qualidade de uma resposta\"\"\"\n",
        "        \n",
        "        scores = {\n",
        "            'relevancia': self._evaluate_relevance(question, response),\n",
        "            'completude': self._evaluate_completeness(response),\n",
        "            'clareza': self._evaluate_clarity(response),\n",
        "            'estrutura': self._evaluate_structure(response)\n",
        "        }\n",
        "        \n",
        "        # Score geral (m√©dia ponderada)\n",
        "        weights = {'relevancia': 0.3, 'completude': 0.3, 'clareza': 0.2, 'estrutura': 0.2}\n",
        "        overall_score = sum(scores[metric] * weight for metric, weight in weights.items())\n",
        "        \n",
        "        evaluation = {\n",
        "            'question': question,\n",
        "            'response': response,\n",
        "            'scores': scores,\n",
        "            'overall_score': overall_score,\n",
        "            'quality_level': self._get_quality_level(overall_score),\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'recommendations': self._get_improvement_recommendations(scores)\n",
        "        }\n",
        "        \n",
        "        self.evaluation_history.append(evaluation)\n",
        "        return evaluation\n",
        "    \n",
        "    def _evaluate_relevance(self, question: str, response: str) -> float:\n",
        "        \"\"\"Avalia se a resposta √© relevante para a pergunta\"\"\"\n",
        "        # Usando TF-IDF para medir similaridade sem√¢ntica\n",
        "        vectorizer = TfidfVectorizer(stop_words='english')\n",
        "        \n",
        "        try:\n",
        "            tfidf_matrix = vectorizer.fit_transform([question.lower(), response.lower()])\n",
        "            similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
        "            return min(similarity * 2, 1.0)  # Normaliza para 0-1\n",
        "        except:\n",
        "            return 0.5  # Score neutro se houver erro\n",
        "    \n",
        "    def _evaluate_completeness(self, response: str) -> float:\n",
        "        \"\"\"Avalia se a resposta √© completa (tem estrutura esperada)\"\"\"\n",
        "        response_lower = response.lower()\n",
        "        \n",
        "        # Verifica presen√ßa de elementos estruturais\n",
        "        structure_elements = 0\n",
        "        for element in self.quality_indicators['estrutura']:\n",
        "            if element in response_lower:\n",
        "                structure_elements += 1\n",
        "        \n",
        "        # Verifica presen√ßa de dados quantitativos\n",
        "        data_elements = 0\n",
        "        for element in self.quality_indicators['dados']:\n",
        "            if element in response_lower:\n",
        "                data_elements += 1\n",
        "        \n",
        "        # Score baseado na presen√ßa de elementos estruturais e dados\n",
        "        structure_score = min(structure_elements / len(self.quality_indicators['estrutura']), 1.0)\n",
        "        data_score = min(data_elements / len(self.quality_indicators['dados']), 1.0)\n",
        "        \n",
        "        return (structure_score + data_score) / 2\n",
        "    \n",
        "    def _evaluate_clarity(self, response: str) -> float:\n",
        "        \"\"\"Avalia a clareza da resposta\"\"\"\n",
        "        # M√©tricas de clareza\n",
        "        sentences = response.split('.')\n",
        "        avg_sentence_length = np.mean([len(s.split()) for s in sentences if s.strip()])\n",
        "        \n",
        "        # Penaliza frases muito longas ou muito curtas\n",
        "        length_score = 1.0 - abs(avg_sentence_length - 15) / 30\n",
        "        length_score = max(0, min(1, length_score))\n",
        "        \n",
        "        # Verifica presen√ßa de conectivos (indicam fluidez)\n",
        "        response_lower = response.lower()\n",
        "        clarity_elements = sum(1 for element in self.quality_indicators['clareza'] \n",
        "                              if element in response_lower)\n",
        "        clarity_score = min(clarity_elements / len(self.quality_indicators['clareza']), 1.0)\n",
        "        \n",
        "        return (length_score + clarity_score) / 2\n",
        "    \n",
        "    def _evaluate_structure(self, response: str) -> float:\n",
        "        \"\"\"Avalia a estrutura da resposta\"\"\"\n",
        "        # Verifica se tem se√ß√µes organizadas\n",
        "        has_sections = len(re.findall(r'\\*\\*[^*]+\\*\\*', response)) >= 2\n",
        "        has_lists = '1.' in response or '2.' in response or '‚Ä¢' in response\n",
        "        has_emojis = bool(re.search(r'[üéØüìäüí∞üìàüîç‚ö†Ô∏è‚úÖ‚ùå]', response))\n",
        "        \n",
        "        structure_score = (has_sections + has_lists + has_emojis) / 3\n",
        "        return structure_score\n",
        "    \n",
        "    def _get_quality_level(self, score: float) -> str:\n",
        "        \"\"\"Converte score num√©rico em n√≠vel qualitativo\"\"\"\n",
        "        if score >= 0.8:\n",
        "            return \"Excelente üåü\"\n",
        "        elif score >= 0.6:\n",
        "            return \"Boa üëç\"\n",
        "        elif score >= 0.4:\n",
        "            return \"Regular üëå\"\n",
        "        else:\n",
        "            return \"Precisa Melhorar üîß\"\n",
        "    \n",
        "    def _get_improvement_recommendations(self, scores: Dict[str, float]) -> List[str]:\n",
        "        \"\"\"Gera recomenda√ß√µes de melhoria baseadas nos scores\"\"\"\n",
        "        recommendations = []\n",
        "        \n",
        "        if scores['relevancia'] < 0.6:\n",
        "            recommendations.append(\"Focar mais na pergunta espec√≠fica do usu√°rio\")\n",
        "        \n",
        "        if scores['completude'] < 0.6:\n",
        "            recommendations.append(\"Incluir mais dados quantitativos e estrutura formal\")\n",
        "        \n",
        "        if scores['clareza'] < 0.6:\n",
        "            recommendations.append(\"Usar frases mais claras e conectivos\")\n",
        "        \n",
        "        if scores['estrutura'] < 0.6:\n",
        "            recommendations.append(\"Organizar melhor com se√ß√µes e listas\")\n",
        "        \n",
        "        return recommendations\n",
        "    \n",
        "    def get_evaluation_summary(self) -> Dict[str, Any]:\n",
        "        \"\"\"Retorna resumo das avalia√ß√µes\"\"\"\n",
        "        if not self.evaluation_history:\n",
        "            return {\"message\": \"Nenhuma avalia√ß√£o realizada ainda\"}\n",
        "        \n",
        "        # Calcular estat√≠sticas\n",
        "        scores = [eval_data['overall_score'] for eval_data in self.evaluation_history]\n",
        "        \n",
        "        return {\n",
        "            'total_evaluations': len(self.evaluation_history),\n",
        "            'average_score': np.mean(scores),\n",
        "            'best_score': np.max(scores),\n",
        "            'worst_score': np.min(scores),\n",
        "            'quality_distribution': {\n",
        "                level: sum(1 for eval_data in self.evaluation_history \n",
        "                          if eval_data['quality_level'] == level)\n",
        "                for level in [\"Excelente üåü\", \"Boa üëç\", \"Regular üëå\", \"Precisa Melhorar üîß\"]\n",
        "            }\n",
        "        }\n",
        "\n",
        "# Criando avaliador\n",
        "evaluator = ResponseEvaluator()\n",
        "\n",
        "print(\"üìè Sistema de avalia√ß√£o criado!\")\n",
        "print(\"üéØ M√©tricas: Relev√¢ncia, Completude, Clareza, Estrutura\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Avaliando as respostas do nosso assistente\n",
        "print(\"üìä AVALIANDO QUALIDADE DAS RESPOSTAS\\n\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Vamos avaliar as respostas que acabamos de gerar\n",
        "perguntas_avaliar = [\n",
        "    \"Qual foi a receita total e qual categoria teve melhor performance?\",\n",
        "    \"Como as vendas se distribuem por regi√£o do Brasil?\"\n",
        "]\n",
        "\n",
        "for pergunta in perguntas_avaliar:\n",
        "    print(f\"\\n‚ùì PERGUNTA: {pergunta}\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # Gerar resposta\n",
        "    resultado = assistant.generate_response(pergunta)\n",
        "    \n",
        "    if resultado[\"success\"]:\n",
        "        # Avaliar qualidade\n",
        "        avaliacao = evaluator.evaluate_response(\n",
        "            question=pergunta,\n",
        "            response=resultado[\"response\"],\n",
        "            actual_data=df_vendas\n",
        "        )\n",
        "        \n",
        "        print(f\"üéØ QUALIDADE GERAL: {avaliacao['quality_level']} ({avaliacao['overall_score']:.2f})\")\n",
        "        print(\"\\nüìä SCORES DETALHADOS:\")\n",
        "        for metrica, score in avaliacao['scores'].items():\n",
        "            emoji = \"‚úÖ\" if score >= 0.6 else \"‚ö†Ô∏è\" if score >= 0.4 else \"‚ùå\"\n",
        "            print(f\"  {emoji} {metrica.title()}: {score:.2f}\")\n",
        "        \n",
        "        if avaliacao['recommendations']:\n",
        "            print(\"\\nüí° RECOMENDA√á√ïES DE MELHORIA:\")\n",
        "            for rec in avaliacao['recommendations']:\n",
        "                print(f\"  ‚Ä¢ {rec}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Resumo geral das avalia√ß√µes\n",
        "resumo = evaluator.get_evaluation_summary()\n",
        "print(\"\\nüìà RESUMO GERAL DAS AVALIA√á√ïES:\")\n",
        "print(f\"üìä Total de avalia√ß√µes: {resumo['total_evaluations']}\")\n",
        "print(f\"üéØ Score m√©dio: {resumo['average_score']:.2f}\")\n",
        "print(f\"üåü Melhor score: {resumo['best_score']:.2f}\")\n",
        "print(f\"üîß Pior score: {resumo['worst_score']:.2f}\")\n",
        "\n",
        "print(\"\\nüèÜ Distribui√ß√£o de qualidade:\")\n",
        "for nivel, quantidade in resumo['quality_distribution'].items():\n",
        "    if quantidade > 0:\n",
        "        print(f\"  {nivel}: {quantidade} resposta(s)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Visualizando M√©tricas de Performance\n",
        "\n",
        "Vamos criar um dashboard visual para acompanhar a performance do nosso assistente! √â importante visualizar os dados para entender onde estamos bem e onde podemos melhorar.\n",
        "\n",
        "Vamos mostrar:\n",
        "- **Evolu√ß√£o da qualidade** ao longo do tempo\n",
        "- **Distribui√ß√£o dos scores** por m√©trica\n",
        "- **Compara√ß√£o de performance** entre diferentes tipos de pergunta\n",
        "\n",
        "**Dica do Pedro:** Um bom dashboard √© como o painel do seu carro - mostra tudo que voc√™ precisa saber de uma olhada s√≥! üöó"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando dashboard de m√©tricas de performance\n",
        "def create_performance_dashboard(evaluator: ResponseEvaluator):\n",
        "    \"\"\"Cria visualiza√ß√µes das m√©tricas de performance\"\"\"\n",
        "    \n",
        "    if not evaluator.evaluation_history:\n",
        "        print(\"‚ö†Ô∏è Nenhuma avalia√ß√£o dispon√≠vel para visualizar\")\n",
        "        return\n",
        "    \n",
        "    # Preparar dados\n",
        "    eval_data = evaluator.evaluation_history\n",
        "    \n",
        "    # DataFrames para an√°lise\n",
        "    df_scores = pd.DataFrame([\n",
        "        {\n",
        "            'timestamp': eval_data[i]['timestamp'],\n",
        "            'overall_score': eval_data[i]['overall_score'],\n",
        "            'quality_level': eval_data[i]['quality_level'],\n",
        "            **eval_data[i]['scores']\n",
        "        }\n",
        "        for i in range(len(eval_data))\n",
        "    ])\n",
        "    \n",
        "    # Criar visualiza√ß√µes\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # 1. Score geral por avalia√ß√£o\n",
        "    axes[0,0].plot(range(len(df_scores)), df_scores['overall_score'], \n",
        "                   marker='o', linewidth=2, markersize=8, color='navy')\n",
        "    axes[0,0].axhline(y=0.8, color='green', linestyle='--', alpha=0.7, label='Excelente')\n",
        "    axes[0,0].axhline(y=0.6, color='orange', linestyle='--', alpha=0.7, label='Boa')\n",
        "    axes[0,0].axhline(y=0.4, color='red', linestyle='--', alpha=0.7, label='Regular')\n",
        "    axes[0,0].set_title('üìà Evolu√ß√£o do Score Geral', fontsize=12, fontweight='bold')\n",
        "    axes[0,0].set_xlabel('N√∫mero da Avalia√ß√£o')\n",
        "    axes[0,0].set_ylabel('Score (0-1)')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Distribui√ß√£o dos scores por m√©trica\n",
        "    metricas = ['relevancia', 'completude', 'clareza', 'estrutura']\n",
        "    scores_por_metrica = [df_scores[metrica].values for metrica in metricas]\n",
        "    \n",
        "    box_plot = axes[0,1].boxplot(scores_por_metrica, labels=metricas, patch_artist=True)\n",
        "    colors = ['lightblue', 'lightgreen', 'lightyellow', 'lightcoral']\n",
        "    for patch, color in zip(box_plot['boxes'], colors):\n",
        "        patch.set_facecolor(color)\n",
        "    \n",
        "    axes[0,1].set_title('üìä Distribui√ß√£o por M√©trica', fontsize=12, fontweight='bold')\n",
        "    axes[0,1].set_ylabel('Score (0-1)')\n",
        "    axes[0,1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # 3. Radar chart das m√©tricas m√©dias\n",
        "    theta = np.linspace(0, 2 * np.pi, len(metricas), endpoint=False)\n",
        "    scores_medios = [df_scores[metrica].mean() for metrica in metricas]\n",
        "    \n",
        "    # Fechar o pol√≠gono\n",
        "    theta = np.concatenate((theta, [theta[0]]))\n",
        "    scores_medios = scores_medios + [scores_medios[0]]\n",
        "    \n",
        "    axes[0,1].remove()  # Remove o boxplot para criar radar\n",
        "    ax_radar = fig.add_subplot(2, 2, 2, projection='polar')\n",
        "    \n",
        "    ax_radar.plot(theta, scores_medios, 'o-', linewidth=2, color='purple')\n",
        "    ax_radar.fill(theta, scores_medios, alpha=0.25, color='purple')\n",
        "    ax_radar.set_thetagrids(np.degrees(theta[:-1]), metricas)\n",
        "    ax_radar.set_ylim(0, 1)\n",
        "    ax_radar.set_title('üéØ Radar das M√©tricas M√©dias', fontsize=12, fontweight='bold', pad=20)\n",
        "    \n",
        "    # 4. Distribui√ß√£o de n√≠veis de qualidade\n",
        "    quality_counts = df_scores['quality_level'].value_counts()\n",
        "    colors_pie = ['gold', 'lightgreen', 'orange', 'lightcoral']\n",
        "    \n",
        "    wedges, texts, autotexts = axes[1,0].pie(quality_counts.values, \n",
        "                                            labels=quality_counts.index,\n",
        "                                            autopct='%1.1f%%',\n",
        "                                            colors=colors_pie,\n",
        "                                            startangle=90)\n",
        "    axes[1,0].set_title('üèÜ Distribui√ß√£o de Qualidade', fontsize=12, fontweight='bold')\n",
        "    \n",
        "    # 5. Heatmap de correla√ß√£o entre m√©tricas\n",
        "    correlation_matrix = df_scores[metricas].corr()\n",
        "    \n",
        "    im = axes[1,1].imshow(correlation_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
        "    axes[1,1].set_xticks(range(len(metricas)))\n",
        "    axes[1,1].set_yticks(range(len(metricas)))\n",
        "    axes[1,1].set_xticklabels(metricas, rotation=45)\n",
        "    axes[1,1].set_yticklabels(metricas)\n",
        "    axes[1,1].set_title('üîó Correla√ß√£o entre M√©tricas', fontsize=12, fontweight='bold')\n",
        "    \n",
        "    # Adicionar valores na heatmap\n",
        "    for i in range(len(metricas)):\n",
        "        for j in range(len(metricas)):\n",
        "            axes[1,1].text(j, i, f'{correlation_matrix.iloc[i, j]:.2f}',\n",
        "                          ha='center', va='center', color='black', fontweight='bold')\n",
        "    \n",
        "    # Colorbar para heatmap\n",
        "    cbar = plt.colorbar(im, ax=axes[1,1], shrink=0.8)\n",
        "    cbar.set_label('Correla√ß√£o', rotation=270, labelpad=15)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Estat√≠sticas textuais\n",
        "    print(\"\\nüìä ESTAT√çSTICAS DETALHADAS:\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    for metrica in metricas:\n",
        "        score_medio = df_scores[metrica].mean()\n",
        "        desvio = df_scores[metrica].std()\n",
        "        emoji = \"üü¢\" if score_medio >= 0.7 else \"üü°\" if score_medio >= 0.5 else \"üî¥\"\n",
        "        print(f\"{emoji} {metrica.title()}: {score_medio:.3f} ¬± {desvio:.3f}\")\n",
        "    \n",
        "    print(f\"\\nüéØ Score Geral M√©dio: {df_scores['overall_score'].mean():.3f}\")\n",
        "    print(f\"üìà Tend√™ncia: {'Melhorando' if df_scores['overall_score'].iloc[-1] > df_scores['overall_score'].iloc[0] else 'Est√°vel'}\")\n",
        "\n",
        "# Criar dashboard\n",
        "create_performance_dashboard(evaluator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exerc√≠cio Pr√°tico: Seu Pr√≥prio Assistente\n",
        "\n",
        "Agora √© a sua vez! Vamos criar um exerc√≠cio onde voc√™ pode personalizar e expandir o assistente.\n",
        "\n",
        "### üèÖ Desafio 1: Personalize o Assistente\n",
        "\n",
        "Modifique o assistente para trabalhar com seu pr√≥prio dom√≠nio:\n",
        "1. **Troque o dataset** por dados do seu interesse\n",
        "2. **Customize os prompts** para seu contexto espec√≠fico\n",
        "3. **Adicione novas m√©tricas** de avalia√ß√£o\n",
        "4. **Implemente novos guardrails** espec√≠ficos do seu dom√≠nio\n",
        "\n",
        "**Dica do Pedro:** Pense em um problema real que voc√™ tem - dados de vendas, estoque, marketing, RH... O c√©u √© o limite! üöÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO PR√ÅTICO 1: Criando seu pr√≥prio dataset e assistente\n",
        "\n",
        "print(\"üèÖ EXERC√çCIO 1: CRIE SEU PR√ìPRIO ASSISTENTE\")\n",
        "print(\"=\" * 50)\n",
        "print(\"\\nüìù INSTRU√á√ïES:\")\n",
        "print(\"1. Escolha um dom√≠nio (RH, Marketing, Finan√ßas, etc.)\")\n",
        "print(\"2. Crie um dataset sint√©tico ou use dados reais\")\n",
        "print(\"3. Customize o sistema de prompts\")\n",
        "print(\"4. Teste e avalie seu assistente\")\n",
        "\n",
        "# Exemplo: Dataset de RH\n",
        "def create_hr_dataset(n_employees=500):\n",
        "    \"\"\"Cria dataset sint√©tico de RH para exemplo\"\"\"\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    departments = ['TI', 'Vendas', 'Marketing', 'RH', 'Financeiro', 'Opera√ß√µes']\n",
        "    positions = ['J√∫nior', 'Pleno', 'S√™nior', 'Lead', 'Manager']\n",
        "    \n",
        "    data = {\n",
        "        'employee_id': range(1, n_employees + 1),\n",
        "        'department': np.random.choice(departments, n_employees),\n",
        "        'position': np.random.choice(positions, n_employees),\n",
        "        'years_experience': np.random.exponential(3, n_employees).astype(int),\n",
        "        'salary': np.random.normal(8000, 3000, n_employees),\n",
        "        'performance_score': np.random.normal(8.5, 1.5, n_employees),\n",
        "        'training_hours': np.random.poisson(20, n_employees),\n",
        "        'satisfaction_score': np.random.normal(7.5, 2, n_employees),\n",
        "        'remote_work_days': np.random.choice([0, 1, 2, 3, 4, 5], n_employees)\n",
        "    }\n",
        "    \n",
        "    # Limpeza de dados\n",
        "    df = pd.DataFrame(data)\n",
        "    df['salary'] = df['salary'].clip(lower=3000, upper=25000)\n",
        "    df['performance_score'] = df['performance_score'].clip(lower=1, upper=10)\n",
        "    df['satisfaction_score'] = df['satisfaction_score'].clip(lower=1, upper=10)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Criar dataset de exemplo\n",
        "hr_data = create_hr_dataset()\n",
        "\n",
        "print(\"\\n‚úÖ Dataset de RH criado como exemplo:\")\n",
        "print(f\"üë• {len(hr_data)} funcion√°rios\")\n",
        "print(f\"üè¢ {hr_data['department'].nunique()} departamentos\")\n",
        "print(f\"üí∞ Sal√°rio m√©dio: R$ {hr_data['salary'].mean():,.2f}\")\n",
        "\n",
        "display(hr_data.head())\n",
        "\n",
        "print(\"\\nüéØ SEU DESAFIO:\")\n",
        "print(\"- Modifique este c√≥digo para seu dom√≠nio espec√≠fico\")\n",
        "print(\"- Crie perguntas relevantes para seus dados\")\n",
        "print(\"- Teste a qualidade das respostas\")\n",
        "print(\"- Implemente melhorias baseadas na avalia√ß√£o\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèÜ Exerc√≠cio Avan√ßado: Sistema de Feedback Cont√≠nuo\n",
        "\n",
        "### üéØ Desafio 2: Implementar Aprendizado Cont√≠nuo\n",
        "\n",
        "Este √© o exerc√≠cio mais avan√ßado! Vamos criar um sistema que:\n",
        "1. **Coleta feedback** dos usu√°rios sobre as respostas\n",
        "2. **Armazena hist√≥rico** de intera√ß√µes\n",
        "3. **Ajusta prompts** baseado no feedback\n",
        "4. **Melhora continuamente** a qualidade\n",
        "\n",
        "√â como criar um assistente que aprende com a experi√™ncia!\n",
        "\n",
        "**Dica do Pedro:** Este tipo de sistema √© usado em empresas reais - voc√™ est√° aprendendo tecnologia de ponta! üåü"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO AVAN√áADO: Sistema de Feedback e Melhoria Cont√≠nua\n",
        "\n",
        "class ContinuousImprovementSystem:\n",
        "    \"\"\"\n",
        "    Sistema de melhoria cont√≠nua baseado em feedback\n",
        "    Conceito avan√ßado para aplica√ß√µes reais\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.feedback_history = []\n",
        "        self.prompt_versions = []\n",
        "        self.performance_metrics = []\n",
        "        \n",
        "    def collect_user_feedback(self, question: str, response: str, \n",
        "                            user_rating: int, user_comments: str = \"\"):\n",
        "        \"\"\"Coleta feedback do usu√°rio (1-5 estrelas)\"\"\"\n",
        "        feedback = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'question': question,\n",
        "            'response': response,\n",
        "            'user_rating': user_rating,\n",
        "            'user_comments': user_comments,\n",
        "            'automated_score': None  # Ser√° preenchido pela avalia√ß√£o autom√°tica\n",
        "        }\n",
        "        \n",
        "        self.feedback_history.append(feedback)\n",
        "        return feedback\n",
        "    \n",
        "    def analyze_feedback_patterns(self):\n",
        "        \"\"\"Analisa padr√µes no feedback para identificar melhorias\"\"\"\n",
        "        if len(self.feedback_history) < 5:\n",
        "            return {\"message\": \"Feedback insuficiente para an√°lise\"}\n",
        "        \n",
        "        df_feedback = pd.DataFrame(self.feedback_history)\n",
        "        \n",
        "        analysis = {\n",
        "            'average_rating': df_feedback['user_rating'].mean(),\n",
        "            'rating_distribution': df_feedback['user_rating'].value_counts().to_dict(),\n",
        "            'low_rated_patterns': self._find_low_rated_patterns(df_feedback),\n",
        "            'improvement_suggestions': self._generate_improvement_suggestions(df_feedback)\n",
        "        }\n",
        "        \n",
        "        return analysis\n",
        "    \n",
        "    def _find_low_rated_patterns(self, df_feedback):\n",
        "        \"\"\"Identifica padr√µes em respostas mal avaliadas\"\"\"\n",
        "        low_rated = df_feedback[df_feedback['user_rating'] <= 2]\n",
        "        \n",
        "        if len(low_rated) == 0:\n",
        "            return \"Nenhuma resposta mal avaliada encontrada\"\n",
        "        \n",
        "        patterns = {\n",
        "            'common_words_in_questions': self._extract_common_words(low_rated['question'].tolist()),\n",
        "            'avg_response_length': low_rated['response'].str.len().mean(),\n",
        "            'common_complaints': self._extract_common_words(low_rated['user_comments'].tolist())\n",
        "        }\n",
        "        \n",
        "        return patterns\n",
        "    \n",
        "    def _extract_common_words(self, texts):\n",
        "        \"\"\"Extrai palavras mais comuns de uma lista de textos\"\"\"\n",
        "        if not texts or all(not text for text in texts):\n",
        "            return []\n",
        "        \n",
        "        # Juntar todos os textos\n",
        "        all_text = ' '.join([str(text) for text in texts if text])\n",
        "        \n",
        "        # Extrair palavras (simples)\n",
        "        words = re.findall(r'\\b\\w+\\b', all_text.lower())\n",
        "        \n",
        "        # Contar frequ√™ncias\n",
        "        word_counts = {}\n",
        "        for word in words:\n",
        "            if len(word) > 3:  # Ignorar palavras muito pequenas\n",
        "                word_counts[word] = word_counts.get(word, 0) + 1\n",
        "        \n",
        "        # Retornar top 5\n",
        "        return sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "    \n",
        "    def _generate_improvement_suggestions(self, df_feedback):\n",
        "        \"\"\"Gera sugest√µes de melhoria baseadas no feedback\"\"\"\n",
        "        suggestions = []\n",
        "        \n",
        "        avg_rating = df_feedback['user_rating'].mean()\n",
        "        \n",
        "        if avg_rating < 3.0:\n",
        "            suggestions.append(\"Qualidade geral baixa - revisar sistema de prompts\")\n",
        "        \n",
        "        if df_feedback['user_rating'].std() > 1.5:\n",
        "            suggestions.append(\"Alta variabilidade - padronizar qualidade das respostas\")\n",
        "        \n",
        "        low_rated_ratio = len(df_feedback[df_feedback['user_rating'] <= 2]) / len(df_feedback)\n",
        "        if low_rated_ratio > 0.3:\n",
        "            suggestions.append(\"Muitas respostas mal avaliadas - implementar filtros adicionais\")\n",
        "        \n",
        "        return suggestions\n",
        "    \n",
        "    def generate_improvement_report(self):\n",
        "        \"\"\"Gera relat√≥rio completo de melhorias\"\"\"\n",
        "        analysis = self.analyze_feedback_patterns()\n",
        "        \n",
        "        print(\"üìä RELAT√ìRIO DE MELHORIA CONT√çNUA\")\n",
        "        print(\"=\" * 50)\n",
        "        \n",
        "        if 'average_rating' in analysis:\n",
        "            rating = analysis['average_rating']\n",
        "            emoji = \"üåü\" if rating >= 4 else \"üëç\" if rating >= 3 else \"üëé\"\n",
        "            print(f\"\\n{emoji} Avalia√ß√£o M√©dia: {rating:.2f}/5.0\")\n",
        "            \n",
        "            print(\"\\nüìä Distribui√ß√£o de Avalia√ß√µes:\")\n",
        "            for stars, count in sorted(analysis['rating_distribution'].items()):\n",
        "                bar = \"‚≠ê\" * stars\n",
        "                print(f\"  {bar} ({stars}): {count} avalia√ß√µes\")\n",
        "            \n",
        "            if analysis['improvement_suggestions']:\n",
        "                print(\"\\nüí° Sugest√µes de Melhoria:\")\n",
        "                for i, suggestion in enumerate(analysis['improvement_suggestions'], 1):\n",
        "                    print(f\"  {i}. {suggestion}\")\n",
        "        else:\n",
        "            print(analysis['message'])\n",
        "\n",
        "# Exemplo de uso do sistema de melhoria cont√≠nua\n",
        "improvement_system = ContinuousImprovementSystem()\n",
        "\n",
        "# Simulando feedback de usu√°rios\n",
        "feedbacks_exemplo = [\n",
        "    (\"Qual a receita total?\", \"A receita foi de R$ 100.000\", 4, \"Resposta clara\"),\n",
        "    (\"Como est√£o as vendas?\", \"As vendas est√£o bem\", 2, \"Muito vaga\"),\n",
        "    (\"An√°lise de categorias?\", \"Eletr√¥nicos lideram com 35%...\", 5, \"Excelente an√°lise\"),\n",
        "    (\"Tend√™ncia de crescimento?\", \"N√£o h√° dados suficientes\", 1, \"N√£o ajudou\"),\n",
        "    (\"Performance por regi√£o?\", \"Sudeste: 40%, Sul: 25%...\", 4, \"Bem detalhado\")\n",
        "]\n",
        "\n",
        "print(\"üîÑ Coletando feedback simulado...\")\n",
        "for question, response, rating, comment in feedbacks_exemplo:\n",
        "    improvement_system.collect_user_feedback(question, response, rating, comment)\n",
        "\n",
        "# Gerar relat√≥rio\n",
        "improvement_system.generate_improvement_report()\n",
        "\n",
        "print(\"\\nüéØ SEU DESAFIO AVAN√áADO:\")\n",
        "print(\"1. Implementar coleta de feedback real em uma interface\")\n",
        "print(\"2. Criar sistema de A/B testing para diferentes prompts\")\n",
        "print(\"3. Automatizar ajustes baseados no feedback\")\n",
        "print(\"4. Implementar m√©tricas de neg√≥cio espec√≠ficas\")\n",
        "print(\"\\nüí° Isso √© o que diferencia solu√ß√µes amadoras de profissionais!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéä Resumo Final: O Que Constru√≠mos\n",
        "\n",
        "Parab√©ns! Voc√™ acabou de construir um sistema completo de an√°lise de dados com LLMs! üéâ\n",
        "\n",
        "### üèóÔ∏è O Que Implementamos:\n",
        "\n",
        "#### ü§ñ **Assistente Inteligente**\n",
        "- Sistema de tokeniza√ß√£o otimizado\n",
        "- Prompts estruturados e eficazes\n",
        "- Guardrails de seguran√ßa\n",
        "- Gera√ß√£o de respostas contextuais\n",
        "\n",
        "#### üìä **Sistema de Avalia√ß√£o**\n",
        "- M√©tricas automatizadas de qualidade\n",
        "- Dashboard visual de performance\n",
        "- An√°lise de tend√™ncias\n",
        "- Identifica√ß√£o de pontos de melhoria\n",
        "\n",
        "#### üîÑ **Melhoria Cont√≠nua**\n",
        "- Coleta de feedback estruturada\n",
        "- An√°lise de padr√µes de problemas\n",
        "- Sugest√µes autom√°ticas de melhoria\n",
        "- Relat√≥rios executivos\n",
        "\n",
        "### üß† **Conceitos do Curso Aplicados:**\n",
        "- ‚úÖ **Tokeniza√ß√£o** (M√≥dulo 4): Otimiza√ß√£o de custos\n",
        "- ‚úÖ **Embeddings** (M√≥dulo 5): An√°lise sem√¢ntica\n",
        "- ‚úÖ **Prompting** (M√≥dulo 8): Engenharia avan√ßada\n",
        "- ‚úÖ **Avalia√ß√£o** (M√≥dulo 9): M√©tricas de qualidade\n",
        "- ‚úÖ **Guardrails** (M√≥dulo 10): Seguran√ßa autom√°tica\n",
        "- ‚úÖ **Limita√ß√µes** (M√≥dulo 11): Tratamento de edge cases\n",
        "\n",
        "**Dica do Pedro:** Voc√™ n√£o s√≥ aprendeu a teoria - construiu um sistema que pode ser usado na vida real! Isso √© o que faz a diferen√ßa no mercado! üöÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualiza√ß√£o final - Mapa mental do que foi constru√≠do\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.patches import FancyBboxPatch, Circle\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16, 12))\n",
        "\n",
        "# Centro - Nosso Projeto\n",
        "center = Circle((8, 6), 1.5, facecolor='gold', edgecolor='black', linewidth=3)\n",
        "ax.add_patch(center)\n",
        "ax.text(8, 6, 'ASSISTENTE\\nDE AN√ÅLISE\\nDE DADOS', ha='center', va='center', \n",
        "        fontsize=12, fontweight='bold')\n",
        "\n",
        "# Componentes principais\n",
        "components = {\n",
        "    'Tokeniza√ß√£o\\nInteligente': (3, 9, 'lightblue', 'M√≥dulo 4'),\n",
        "    'Sistema de\\nPrompts': (13, 9, 'lightgreen', 'M√≥dulo 8'),\n",
        "    'Guardrails\\nSeguran√ßa': (3, 3, 'orange', 'M√≥dulo 10'),\n",
        "    'Avalia√ß√£o\\nQualidade': (13, 3, 'lightcoral', 'M√≥dulo 9'),\n",
        "    'An√°lise\\nSemantica': (2, 6, 'lightyellow', 'M√≥dulo 5'),\n",
        "    'Melhoria\\nCont√≠nua': (14, 6, 'lightpink', 'Avan√ßado')\n",
        "}\n",
        "\n",
        "# Desenhando componentes\n",
        "for name, (x, y, color, module) in components.items():\n",
        "    # Caixa principal\n",
        "    box = FancyBboxPatch((x-1.2, y-0.8), 2.4, 1.6, \n",
        "                        boxstyle=\"round,pad=0.2\", \n",
        "                        facecolor=color, \n",
        "                        edgecolor='black',\n",
        "                        linewidth=2)\n",
        "    ax.add_patch(box)\n",
        "    ax.text(x, y+0.2, name, ha='center', va='center', fontsize=10, fontweight='bold')\n",
        "    ax.text(x, y-0.4, f'({module})', ha='center', va='center', fontsize=8, style='italic')\n",
        "    \n",
        "    # Linha conectando ao centro\n",
        "    ax.plot([x, 8], [y, 6], 'k--', alpha=0.5, linewidth=2)\n",
        "\n",
        "# Funcionalidades implementadas\n",
        "features = [\n",
        "    \"‚úÖ An√°lise automatizada de datasets\",\n",
        "    \"‚úÖ Respostas estruturadas e contextuais\", \n",
        "    \"‚úÖ Sistema de seguran√ßa robusto\",\n",
        "    \"‚úÖ M√©tricas de qualidade autom√°ticas\",\n",
        "    \"‚úÖ Dashboard visual de performance\",\n",
        "    \"‚úÖ Feedback e melhoria cont√≠nua\",\n",
        "    \"‚úÖ Otimiza√ß√£o de custos (tokens)\",\n",
        "    \"‚úÖ Tratamento de edge cases\"\n",
        "]\n",
        "\n",
        "# Lista de funcionalidades\n",
        "for i, feature in enumerate(features):\n",
        "    ax.text(0.5, 11-i*0.4, feature, fontsize=10, va='center')\n",
        "\n",
        "# T√≠tulo e configura√ß√µes\n",
        "ax.set_xlim(0, 16)\n",
        "ax.set_ylim(0, 12)\n",
        "ax.set_title('üéä PROJETO FINAL COMPLETO - Sistema de An√°lise com LLMs', \n",
        "             fontsize=18, fontweight='bold', pad=20)\n",
        "ax.axis('off')\n",
        "\n",
        "# Legenda\n",
        "legend_elements = [\n",
        "    mpatches.Patch(color='gold', label='Core System'),\n",
        "    mpatches.Patch(color='lightblue', label='Tokeniza√ß√£o'),\n",
        "    mpatches.Patch(color='lightgreen', label='Prompting'),\n",
        "    mpatches.Patch(color='orange', label='Seguran√ßa'),\n",
        "    mpatches.Patch(color='lightcoral', label='Avalia√ß√£o'),\n",
        "    mpatches.Patch(color='lightpink', label='Melhoria Cont√≠nua')\n",
        "]\n",
        "ax.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(0.98, 0.98))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Estat√≠sticas finais\n",
        "print(\"üéâ PROJETO FINAL CONCLU√çDO COM SUCESSO!\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"üìä Linhas de c√≥digo: ~500+\")\n",
        "print(f\"üß© M√≥dulos integrados: 6/11\")\n",
        "print(f\"‚ö° Funcionalidades: {len(features)}\")\n",
        "print(f\"üèÜ N√≠vel: Profissional\")\n",
        "print(\"\\nüí° PR√ìXIMOS PASSOS:\")\n",
        "print(\"- Implementar interface web (Streamlit/Flask)\")\n",
        "print(\"- Adicionar suporte a m√∫ltiplos tipos de arquivo\")\n",
        "print(\"- Integrar com APIs de dados externos\")\n",
        "print(\"- Implementar cache inteligente\")\n",
        "print(\"- Adicionar autentica√ß√£o e multi-tenancy\")\n",
        "print(\"\\nüöÄ Voc√™ est√° pronto para o M√≥dulo 13 - T√≥picos Avan√ßados!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Prepara√ß√£o para o M√≥dulo 13\n",
        "\n",
        "Voc√™ acabou de completar um projeto incr√≠vel! Mas nossa jornada ainda n√£o acabou. No pr√≥ximo e √∫ltimo m√≥dulo, vamos explorar t√≥picos avan√ßados como:\n",
        "\n",
        "### üîÆ **O Que Vem Por A√≠:**\n",
        "- **Fine-tuning** de modelos para casos espec√≠ficos\n",
        "- **RAG (Retrieval-Augmented Generation)** para conhecimento externo\n",
        "- **Agents** aut√¥nomos que executam tarefas complexas\n",
        "- **Multimodalidade** (texto + imagem + √°udio)\n",
        "- **Otimiza√ß√µes avan√ßadas** para produ√ß√£o\n",
        "- **Tend√™ncias futuras** em LLMs\n",
        "\n",
        "### üéì **Reflex√£o Final:**\n",
        "Olhe para tr√°s e veja o quanto voc√™ evoluiu! Voc√™:\n",
        "- ‚úÖ Entendeu a arquitetura Transformer\n",
        "- ‚úÖ Dominou tokeniza√ß√£o e embeddings  \n",
        "- ‚úÖ Aplicou engenharia de prompts avan√ßada\n",
        "- ‚úÖ Implementou sistemas de seguran√ßa\n",
        "- ‚úÖ Criou m√©tricas de avalia√ß√£o\n",
        "- ‚úÖ Construiu um projeto completo e funcional\n",
        "\n",
        "**Isso n√£o √© pouca coisa!** Voc√™ est√° no caminho certo para se tornar um expert em LLMs! üåü\n",
        "\n",
        "**Dica do Pedro:** Pratique o que aprendeu, experimente com seus pr√≥prios dados e n√£o tenha medo de errar - √© errando que se aprende! Nos vemos no √∫ltimo m√≥dulo para fechar com chave de ouro! üîë‚ú®"
      ]
    }
  ]
}